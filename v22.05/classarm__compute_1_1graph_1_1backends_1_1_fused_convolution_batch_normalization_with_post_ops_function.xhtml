<!-- HTML header for doxygen 1.8.15-->
<!-- Remember to use version doxygen 1.8.15 +-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="robots" content="NOINDEX, NOFOLLOW" /> <!-- Prevent indexing by search engines -->
<title>Compute Library: FusedConvolutionBatchNormalizationWithPostOpsFunction&lt; TargetInfo, FusedLayerTypes &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <img alt="Compute Library" src="https://raw.githubusercontent.com/ARM-software/ComputeLibrary/gh-pages/ACL_logo.png" style="max-width: 100%;margin-top: 15px;margin-left: 10px"/>
  <td style="padding-left: 0.5em;">
   <div id="projectname">
   &#160;<span id="projectnumber">22.05</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a>  </div>
  <div class="headertitle">
<div class="title">FusedConvolutionBatchNormalizationWithPostOpsFunction&lt; TargetInfo, FusedLayerTypes &gt; Class Template Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Wrapper function to first apply {NE, CL}BatchNormalizationLayer on the weights and then run {NE, CL}ConvolutionLayer with the modified weights.  
 <a href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml">FusedConvolutionBatchNormalizationWithPostOpsFunction.h</a>&gt;</code></p>
<div class="dynheader">
Collaboration diagram for FusedConvolutionBatchNormalizationWithPostOpsFunction&lt; TargetInfo, FusedLayerTypes &gt;:</div>
<div class="dyncontent">
<div class="center"><iframe scrolling="no" frameborder="0" src="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function__coll__graph.svg" width="278" height="142"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe>
</div>
<center><span class="legend">[<a target="top" href="graph_legend.xhtml">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:a4ae2727819a8e5fb0b0d9087e7ebd5ca"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> = typename TargetInfo::TensorType</td></tr>
<tr class="separator:a4ae2727819a8e5fb0b0d9087e7ebd5ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a991b6faefbee1cf7b9cf77647c30a6ec"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a991b6faefbee1cf7b9cf77647c30a6ec">TensorConcreteType</a> = typename TargetInfo::TensorConcreteType</td></tr>
<tr class="separator:a991b6faefbee1cf7b9cf77647c30a6ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a30652844483f05901974f5909a673600"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a30652844483f05901974f5909a673600">FusedConvolutionBatchNormalizationWithPostOpsFunction</a> (std::shared_ptr&lt; <a class="el" href="classarm__compute_1_1_i_memory_manager.xhtml">IMemoryManager</a> &gt; memory_manager=nullptr)</td></tr>
<tr class="separator:a30652844483f05901974f5909a673600"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abee799ee71c86496b8f454ce93ae2d27"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#abee799ee71c86496b8f454ce93ae2d27">configure</a> (<a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *input, <a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *weights, <a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *<a class="el" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>, <a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *output, const <a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *mean, const <a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *var, const <a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *beta, const <a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *gamma, float epsilon, const <a class="el" href="classarm__compute_1_1_pad_stride_info.xhtml">PadStrideInfo</a> &amp;conv_info, unsigned int num_groups, bool fast_math, const <a class="el" href="classarm__compute_1_1experimental_1_1_post_op_list.xhtml">arm_compute::experimental::PostOpList</a>&lt; <a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *&gt; &amp;post_ops=<a class="el" href="classarm__compute_1_1experimental_1_1_post_op_list.xhtml">experimental::PostOpList</a>&lt; <a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *&gt; {})</td></tr>
<tr class="memdesc:abee799ee71c86496b8f454ce93ae2d27"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the input and output tensors.  <a href="#abee799ee71c86496b8f454ce93ae2d27">More...</a><br /></td></tr>
<tr class="separator:abee799ee71c86496b8f454ce93ae2d27"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a13a43e6d814de94978c515cb084873b1"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a13a43e6d814de94978c515cb084873b1">run</a> ()</td></tr>
<tr class="memdesc:a13a43e6d814de94978c515cb084873b1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Run the kernels contained in the function.  <a href="#a13a43e6d814de94978c515cb084873b1">More...</a><br /></td></tr>
<tr class="separator:a13a43e6d814de94978c515cb084873b1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1825b40ca3bc3a1ba67fdb58fac5015c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a1825b40ca3bc3a1ba67fdb58fac5015c">prepare</a> ()</td></tr>
<tr class="memdesc:a1825b40ca3bc3a1ba67fdb58fac5015c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prepare the function for executing.  <a href="#a1825b40ca3bc3a1ba67fdb58fac5015c">More...</a><br /></td></tr>
<tr class="separator:a1825b40ca3bc3a1ba67fdb58fac5015c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classarm__compute_1_1_i_function"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classarm__compute_1_1_i_function')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classarm__compute_1_1_i_function.xhtml">IFunction</a></td></tr>
<tr class="memitem:ab921ecc3f3f6ae2b4bd61f3e1998d8c4 inherit pub_methods_classarm__compute_1_1_i_function"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_function.xhtml#ab921ecc3f3f6ae2b4bd61f3e1998d8c4">~IFunction</a> ()=default</td></tr>
<tr class="memdesc:ab921ecc3f3f6ae2b4bd61f3e1998d8c4 inherit pub_methods_classarm__compute_1_1_i_function"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destructor.  <a href="classarm__compute_1_1_i_function.xhtml#ab921ecc3f3f6ae2b4bd61f3e1998d8c4">More...</a><br /></td></tr>
<tr class="separator:ab921ecc3f3f6ae2b4bd61f3e1998d8c4 inherit pub_methods_classarm__compute_1_1_i_function"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;typename TargetInfo, typename FusedLayerTypes&gt;<br />
class arm_compute::graph::backends::FusedConvolutionBatchNormalizationWithPostOpsFunction&lt; TargetInfo, FusedLayerTypes &gt;</h3>

<p>Wrapper function to first apply {NE, CL}BatchNormalizationLayer on the weights and then run {NE, CL}ConvolutionLayer with the modified weights. </p>

<p class="definition">Definition at line <a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml#l00040">40</a> of file <a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml">FusedConvolutionBatchNormalizationWithPostOpsFunction.h</a>.</p>
</div><h2 class="groupheader">Member Typedef Documentation</h2>
<a id="a991b6faefbee1cf7b9cf77647c30a6ec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a991b6faefbee1cf7b9cf77647c30a6ec">&#9670;&nbsp;</a></span>TensorConcreteType</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a991b6faefbee1cf7b9cf77647c30a6ec">TensorConcreteType</a> =  typename TargetInfo::TensorConcreteType</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml#l00044">44</a> of file <a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml">FusedConvolutionBatchNormalizationWithPostOpsFunction.h</a>.</p>

</div>
</div>
<a id="a4ae2727819a8e5fb0b0d9087e7ebd5ca"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4ae2727819a8e5fb0b0d9087e7ebd5ca">&#9670;&nbsp;</a></span>TensorType</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> =  typename TargetInfo::TensorType</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml#l00043">43</a> of file <a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml">FusedConvolutionBatchNormalizationWithPostOpsFunction.h</a>.</p>

</div>
</div>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a30652844483f05901974f5909a673600"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a30652844483f05901974f5909a673600">&#9670;&nbsp;</a></span>FusedConvolutionBatchNormalizationWithPostOpsFunction()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml">FusedConvolutionBatchNormalizationWithPostOpsFunction</a> </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classarm__compute_1_1_i_memory_manager.xhtml">IMemoryManager</a> &gt;&#160;</td>
          <td class="paramname"><em>memory_manager</em> = <code>nullptr</code></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml#l00046">46</a> of file <a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml">FusedConvolutionBatchNormalizationWithPostOpsFunction.h</a>.</p>
<div class="fragment"><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;        : _conv_layer(memory_manager), _fused_batch_norm_layer(), _fused_bias(), _is_prepared(<span class="keyword">false</span>)</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;    {</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;    }</div></div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="abee799ee71c86496b8f454ce93ae2d27"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abee799ee71c86496b8f454ce93ae2d27">&#9670;&nbsp;</a></span>configure()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void configure </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *&#160;</td>
          <td class="paramname"><em>mean</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *&#160;</td>
          <td class="paramname"><em>var</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_pad_stride_info.xhtml">PadStrideInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>conv_info</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned int&#160;</td>
          <td class="paramname"><em>num_groups</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>fast_math</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1experimental_1_1_post_op_list.xhtml">arm_compute::experimental::PostOpList</a>&lt; <a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *&gt; &amp;&#160;</td>
          <td class="paramname"><em>post_ops</em> = <code><a class="el" href="classarm__compute_1_1experimental_1_1_post_op_list.xhtml">experimental::PostOpList</a>&lt;<a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a>&#160;*&gt;&#160;{}</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Set the input and output tensors. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">input</td><td>Source tensor. 3 lower dimensions represent a single input [width, height, IFM], while every optional dimension from 4 and above represent a batch of inputs. Data types supported: QASYMM8/F16/F32. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">weights</td><td>Weights tensor. Weights are 4D tensor with dimensions [kernel_x, kernel_y, IFM, OFM]. Data type supported: Same as <code>input</code>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>Biases tensor. Shared biases supported. Biases are 1D tensor with dimensions [OFM]. Data type supported: Should match <code>input</code> data type. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output</td><td>Destination tensor. 3 lower dimensions represent a single output [width, height, OFM], while the rest represent batch of outputs. Data types supported: Same as <code>input</code>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">mean</td><td>Mean values tensor. 1 dimension with size equal to the feature maps [FM]. Data types supported: Same as <code>input</code> </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">var</td><td>Variance values tensor. 1 dimension with size equal to the feature maps [FM]. Data types supported: Same as <code>input</code> </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">beta</td><td>Beta values tensor info. 1 dimension with size equal to the feature maps [FM]. If not provided, default value for beta is 0. Data types supported: Same as <code>input</code> </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">gamma</td><td>Gamma values tensor info. 1 dimension with size equal to the feature maps [FM]. If not provided, default value for gamma is 1. Data types supported: Same as <code>input</code> </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">epsilon</td><td>Small value to avoid division with zero. Default value is 0.001f. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">conv_info</td><td>Contains padding and stride information described in <a class="el" href="classarm__compute_1_1_pad_stride_info.xhtml">PadStrideInfo</a>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_groups</td><td>Number of groups when performing a grouped convolution. num_groups != 1 is only supported for NCHW data layout </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">fast_math</td><td>Enable fast math computation. In case this flag were set, the function could dispatch the fastest implementation available which may introduce a drop of accuracy as well. Default is false </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_ops</td><td>A sequence of post operations that are performed after the main operation. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml#l00073">73</a> of file <a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml">FusedConvolutionBatchNormalizationWithPostOpsFunction.h</a>.</p>

<p class="reference">References <a class="el" href="working__space_8hpp_source.xhtml#l00292">bias</a>, <a class="el" href="_n_e_o_n_2_im2_col_8cpp_source.xhtml#l00152">arm_compute::test::validation::has_bias</a>, <a class="el" href="_c_l_2_convolution_layer_8cpp_source.xhtml#l00410">arm_compute::test::validation::post_ops</a>, and <a class="el" href="_saturate_cast_8h_source.xhtml#l00057">arm_compute::utils::cast::U</a>.</p>
<div class="fragment"><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;                                                                                                                          {})</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;    {</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;        <span class="comment">// We don&#39;t run any validate, as we assume that the layers have been already validated</span></div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;        <span class="keyword">const</span> <span class="keywordtype">bool</span>        <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a9aeced5a5128f60a31ea3e327a45ee21">has_bias</a> = (<a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a> != <span class="keyword">nullptr</span>);</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;        <span class="keyword">const</span> <a class="code" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">TensorType</a> *bias_to_use;</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;        <span class="comment">// We check if the layer has a bias. If yes, use it in-place. If not, we need to create one</span></div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;        <span class="comment">// as batch normalization might end up with a bias != 0</span></div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;        <span class="keywordflow">if</span>(has_bias)</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;        {</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;            _fused_batch_norm_layer.configure(weights, mean, var, <span class="keyword">nullptr</span>, <span class="keyword">nullptr</span>, <a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>, beta, gamma, <a class="code" href="namespacearm__compute_1_1quantization.xhtml#a552dc3787d7ea1675f3e4e8993501d58">epsilon</a>);</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;            bias_to_use = <a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>;</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;        }</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;        <span class="keywordflow">else</span></div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;        {</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;            _fused_batch_norm_layer.configure(weights, mean, var, <span class="keyword">nullptr</span>, &amp;_fused_bias, <span class="keyword">nullptr</span>, beta, gamma, <a class="code" href="namespacearm__compute_1_1quantization.xhtml#a552dc3787d7ea1675f3e4e8993501d58">epsilon</a>);</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;            bias_to_use = &amp;_fused_bias;</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;        }</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;        ActivationLayerInfo fused_act = ActivationLayerInfo(); <span class="comment">// Passing an empty ActivationLayerInfo.</span></div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;        _conv_layer.configure(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>, weights, bias_to_use, output, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a00525ff582f16038a1d3819aa44a23a3">conv_info</a>, WeightsInfo(), Size2D(1U, 1U), fused_act, fast_math, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a2270b3e1d20651d2d8341c858c890830">num_groups</a>, post_ops);</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;        <span class="keywordflow">if</span>(!has_bias)</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;        {</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;            _fused_bias.allocator()-&gt;allocate();</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;        }</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;    }</div><div class="ttc" id="namespacearm__compute_1_1test_1_1validation_xhtml_a00525ff582f16038a1d3819aa44a23a3"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#a00525ff582f16038a1d3819aa44a23a3">arm_compute::test::validation::conv_info</a></div><div class="ttdeci">const auto conv_info</div><div class="ttdef"><b>Definition:</b> <a href="_c_l_2_convolution_layer_8cpp_source.xhtml#l00404">ConvolutionLayer.cpp:404</a></div></div>
<div class="ttc" id="namespacearm__compute_1_1test_1_1validation_xhtml_a8fcf2ddd9a1d58b1b280f5c0aed71845"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">arm_compute::test::validation::input</a></div><div class="ttdeci">auto input</div><div class="ttdef"><b>Definition:</b> <a href="_c_l_2_l_s_t_m_layer_quantized_8cpp_source.xhtml#l00486">LSTMLayerQuantized.cpp:486</a></div></div>
<div class="ttc" id="namespacearm__compute_1_1test_1_1validation_xhtml_a2270b3e1d20651d2d8341c858c890830"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#a2270b3e1d20651d2d8341c858c890830">arm_compute::test::validation::num_groups</a></div><div class="ttdeci">const unsigned int num_groups</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_o_n_2_im2_col_8cpp_source.xhtml#l00153">Im2Col.cpp:153</a></div></div>
<div class="ttc" id="namespacearm__compute_1_1test_1_1validation_xhtml_a9aeced5a5128f60a31ea3e327a45ee21"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#a9aeced5a5128f60a31ea3e327a45ee21">arm_compute::test::validation::has_bias</a></div><div class="ttdeci">const bool has_bias</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_o_n_2_im2_col_8cpp_source.xhtml#l00152">Im2Col.cpp:152</a></div></div>
<div class="ttc" id="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function_xhtml_a4ae2727819a8e5fb0b0d9087e7ebd5ca"><div class="ttname"><a href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a4ae2727819a8e5fb0b0d9087e7ebd5ca">arm_compute::graph::backends::FusedConvolutionBatchNormalizationWithPostOpsFunction::TensorType</a></div><div class="ttdeci">typename TargetInfo::TensorType TensorType</div><div class="ttdef"><b>Definition:</b> <a href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml#l00043">FusedConvolutionBatchNormalizationWithPostOpsFunction.h:43</a></div></div>
<div class="ttc" id="namespacearm__compute_1_1quantization_xhtml_a552dc3787d7ea1675f3e4e8993501d58"><div class="ttname"><a href="namespacearm__compute_1_1quantization.xhtml#a552dc3787d7ea1675f3e4e8993501d58">arm_compute::quantization::epsilon</a></div><div class="ttdeci">constexpr float epsilon</div><div class="ttdef"><b>Definition:</b> <a href="_asymm_helpers_8cpp_source.xhtml#l00037">AsymmHelpers.cpp:37</a></div></div>
<div class="ttc" id="working__space_8hpp_xhtml_a1fb7b822a92dd3ab6e7ab15c67b0ff9e"><div class="ttname"><a href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a></div><div class="ttdeci">const int32_t * bias</div><div class="ttdef"><b>Definition:</b> <a href="working__space_8hpp_source.xhtml#l00292">working_space.hpp:292</a></div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a1825b40ca3bc3a1ba67fdb58fac5015c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1825b40ca3bc3a1ba67fdb58fac5015c">&#9670;&nbsp;</a></span>prepare()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void prepare </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Prepare the function for executing. </p>
<p>Any one off pre-processing step required by the function is handled here</p>
<dl class="section note"><dt>Note</dt><dd>Prepare stage might not need all the function's buffers' backing memory to be available in order to execute </dd></dl>

<p>Reimplemented from <a class="el" href="classarm__compute_1_1_i_function.xhtml#a820f7291c24155a2980512fae45aac26">IFunction</a>.</p>

<p class="definition">Definition at line <a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml#l00117">117</a> of file <a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml">FusedConvolutionBatchNormalizationWithPostOpsFunction.h</a>.</p>

<p class="reference">References <a class="el" href="namespacearm__compute_1_1graph.xhtml#acac9cbaeea226ed297804c012dc12b16aa252659b59a03bc61e5ec827ab4448b7">arm_compute::graph::ConvolutionLayer</a>.</p>

<p class="reference">Referenced by <a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml#l00111">FusedConvolutionBatchNormalizationWithPostOpsFunction&lt; TargetInfo, FusedLayerTypes &gt;::run()</a>.</p>
<div class="fragment"><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;    {</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;        <span class="keywordflow">if</span>(!_is_prepared)</div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;        {</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;            _fused_batch_norm_layer.run();</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;            _is_prepared = <span class="keyword">true</span>;</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;        }</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;    }</div></div><!-- fragment -->
</div>
</div>
<a id="a13a43e6d814de94978c515cb084873b1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a13a43e6d814de94978c515cb084873b1">&#9670;&nbsp;</a></span>run()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void run </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Run the kernels contained in the function. </p>
<p>For CPU kernels:</p><ul>
<li>Multi-threading is used for the kernels which are parallelisable.</li>
<li>By default std::thread::hardware_concurrency() threads are used.</li>
</ul>
<dl class="section note"><dt>Note</dt><dd><a class="el" href="classarm__compute_1_1_c_p_p_scheduler.xhtml#ae64eebaa07f4d2da6cc2ba538c3cb095">CPPScheduler::set_num_threads()</a> can be used to manually set the number of threads</dd></dl>
<p>For OpenCL kernels:</p><ul>
<li>All the kernels are enqueued on the queue associated with <a class="el" href="classarm__compute_1_1_c_l_scheduler.xhtml" title="Provides global access to a CL context and command queue. ">CLScheduler</a>.</li>
<li>The queue is then flushed.</li>
</ul>
<dl class="section note"><dt>Note</dt><dd>The function will not block until the kernels are executed. It is the user's responsibility to wait. </dd>
<dd>
Will call <a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a1825b40ca3bc3a1ba67fdb58fac5015c" title="Prepare the function for executing. ">prepare()</a> on first run if hasn't been done </dd></dl>

<p>Implements <a class="el" href="classarm__compute_1_1_i_function.xhtml#a18954417d3124a8095783ea13dc6d00b">IFunction</a>.</p>

<p class="definition">Definition at line <a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml#l00111">111</a> of file <a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml">FusedConvolutionBatchNormalizationWithPostOpsFunction.h</a>.</p>

<p class="reference">References <a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml#l00117">FusedConvolutionBatchNormalizationWithPostOpsFunction&lt; TargetInfo, FusedLayerTypes &gt;::prepare()</a>.</p>
<div class="fragment"><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;    {</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;        <a class="code" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a1825b40ca3bc3a1ba67fdb58fac5015c">prepare</a>();</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;        _conv_layer.run();</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;    }</div><div class="ttc" id="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function_xhtml_a1825b40ca3bc3a1ba67fdb58fac5015c"><div class="ttname"><a href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml#a1825b40ca3bc3a1ba67fdb58fac5015c">arm_compute::graph::backends::FusedConvolutionBatchNormalizationWithPostOpsFunction::prepare</a></div><div class="ttdeci">void prepare()</div><div class="ttdoc">Prepare the function for executing. </div><div class="ttdef"><b>Definition:</b> <a href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml#l00117">FusedConvolutionBatchNormalizationWithPostOpsFunction.h:117</a></div></div>
</div><!-- fragment -->
</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>arm_compute/graph/backends/<a class="el" href="_fused_convolution_batch_normalization_with_post_ops_function_8h_source.xhtml">FusedConvolutionBatchNormalizationWithPostOpsFunction.h</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacearm__compute.xhtml">arm_compute</a></li><li class="navelem"><a class="el" href="namespacearm__compute_1_1graph.xhtml">graph</a></li><li class="navelem"><a class="el" href="namespacearm__compute_1_1graph_1_1backends.xhtml">backends</a></li><li class="navelem"><a class="el" href="classarm__compute_1_1graph_1_1backends_1_1_fused_convolution_batch_normalization_with_post_ops_function.xhtml">FusedConvolutionBatchNormalizationWithPostOpsFunction</a></li>
    <li class="footer">Generated on Wed May 18 2022 13:42:35 for Compute Library by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
