///
/// Copyright (c) 2021 Arm Limited.
///
/// SPDX-License-Identifier: MIT
///
/// Permission is hereby granted, free of charge, to any person obtaining a copy
/// of this software and associated documentation files (the "Software"), to
/// deal in the Software without restriction, including without limitation the
/// rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
/// sell copies of the Software, and to permit persons to whom the Software is
/// furnished to do so, subject to the following conditions:
///
/// The above copyright notice and this permission notice shall be included in all
/// copies or substantial portions of the Software.
///
/// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
/// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
/// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
/// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
/// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
/// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
/// SOFTWARE.
///
namespace arm_compute
{
/**
@page operators_list Supported Operators

@tableofcontents

@section S9_1_operators_list Supported Operators

Compute Library supports operators that are listed in below table.

Compute Library supports a wide list of data-types, information can been directly found in the documentation of each kernel/function.
The main data-types that the Machine Learning functions support are the following:
  <ul>
    <li>BFLOAT16: 16-bit non-standard brain floating point
    <li>QASYMM8: 8-bit unsigned asymmetric quantized
    <li>QASYMM8_SIGNED: 8-bit signed asymmetric quantized
    <li>QSYMM8_PER_CHANNEL: 8-bit signed symmetric quantized (Used for the weights)
    <li>QSYMM8: 8-bit unsigned symmetric quantized
    <li>QSYMM16: 16-bit unsigned symmetric quantized
    <li>F32: 32-bit single precision floating point
    <li>F16: 16-bit half precision floating point
    <li>S32: 32-bit signed integer
    <li>U8: 8-bit unsigned char
    <li>All: include all above data types
  </ul>

Compute Library supports the following data layouts (fast changing dimension from right to left):
  <ul>
    <li>NHWC: The native layout of Compute Library that delivers the best performance where channels are in the fastest changing dimension
    <li>NCHW: Legacy layout where width is in the fastest changing dimension
    <li>All: include all above data layouts
  </ul>
where N = batches, C = channels, H = height, W = width

<table>
<caption id="multi_row"></caption>
<tr>
  <th>Function
  <th>Description
  <th>Equivalent Android NNAPI Op
  <th>Backends
  <th>Data Layouts
  <th>Data Types
<tr>
  <td rowspan="2">ActivationLayer
  <td rowspan="2" style="width:200px;"> Function to simulate an activation layer with the specified activation function.
  <td rowspan="2">
      <ul>
       <li>ANEURALNETWORKS_ELU
       <li>ANEURALNETWORKS_HARD_SWISH
       <li>ANEURALNETWORKS_LOGISTIC
       <li>ANEURALNETWORKS_RELU
       <li>ANEURALNETWORKS_RELU1
       <li>ANEURALNETWORKS_RELU6
       <li>ANEURALNETWORKS_TANH
      </ul>
  <td>NEActivationLayer
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>QASYMM8<td>QASYMM8
    <tr><td>QASYMM8_SIGNED<td>QASYMM8_SIGNED
    <tr><td>QSYMM16<td>QSYMM16
    <tr><td>F16<td>F16
    <tr><td>F32<td>F32
    </table>
<tr>
  <td>CLActivationLayer
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>QASYMM8<td>QASYMM8
    <tr><td>QASYMM8_SIGNED<td>QASYMM8_SIGNED
    <tr><td>QSYMM16<td>QSYMM16
    <tr><td>F16<td>F16
    <tr><td>F32<td>F32
    </table>
<tr>
  <td rowspan="2">ConcatenateLayer
  <td rowspan="2" style="width:200px;"> Function to concatenate tensors along a given axis.
  <td rowspan="2">
      <ul>
       <li>ANEURALNETWORKS_CONCATENATION
      </ul>
  <td>NEConcatenateLayer
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>QASYMM8<td>QASYMM8
    <tr><td>QASYMM8_SIGNED<td>QASYMM8_SIGNED
    <tr><td>F16<td>F16
    <tr><td>F32<td>F32
    </table>
<tr>
  <td>CLConcatenateLayer
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>QASYMM8<td>QASYMM8
    <tr><td>QASYMM8_SIGNED<td>QASYMM8_SIGNED
    <tr><td>F16<td>F16
    <tr><td>F32<td>F32
    </table>
<tr>
  <td rowspan="2">ConvertFullyConnectedWeights
  <td rowspan="2" style="width:200px;"> Function to tranpose the wieghts for the fully connected layer.
  <td rowspan="2">
      <ul>
       <li>None
      </ul>
  <td>NEConvertFullyConnectedWeights
  <td>
      <ul>
       <li>NHWC
       <li>NCHW
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>All<td>All
    </table>
<tr>
  <td>CLConvertFullyConnectedWeights
  <td>
      <ul>
       <li>NHWC
       <li>NCHW
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>All<td>All
    </table>
<tr>
  <td rowspan="2">Copy
  <td rowspan="2" style="width:200px;"> Function to copy a tensor.
  <td rowspan="2">
      <ul>
       <li>None
      </ul>
  <td>NECopy
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>All<td>All
    </table>
<tr>
  <td>CLCopy
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>All<td>All
    </table>
<tr>
  <td rowspan="2">DequantizationLayer
  <td rowspan="2" style="width:200px;"> Function to dequantize the values in a tensor
  <td rowspan="2">
      <ul>
       <li>ANEURALNETWORKS_DEQUANTIZE
      </ul>
  <td>NEDequantizationLayer
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>QASYMM8<td>F16
    <tr><td>QASYMM8<td>F32
    <tr><td>QASYMM8_SIGNED<td>F16
    <tr><td>QASYMM8_SIGNED<td>F32
    <tr><td>QSYMM8_PER_CHANNEL<td>F16
    <tr><td>QSYMM8_PER_CHANNEL<td>F32
    <tr><td>QSYMM8<td>F16
    <tr><td>QSYMM8<td>F32
    <tr><td>QSYMM16<td>F16
    <tr><td>QSYMM16<td>F32
    </table>
<tr>
  <td>CLDequantizationLayer
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>QASYMM8<td>F16
    <tr><td>QASYMM8<td>F32
    <tr><td>QASYMM8_SIGNED<td>F16
    <tr><td>QASYMM8_SIGNED<td>F32
    <tr><td>QSYMM8_PER_CHANNEL<td>F16
    <tr><td>QSYMM8_PER_CHANNEL<td>F32
    <tr><td>QSYMM8<td>F16
    <tr><td>QSYMM8<td>F32
    <tr><td>QSYMM16<td>F16
    <tr><td>QSYMM16<td>F32
    </table>
<tr>
  <td rowspan="2">DirectConvolutionLayer
  <td rowspan="2" style="width:200px;"> Function to
  <td rowspan="2">
      <ul>
       <li>ANEURALNETWORKS_CONV_2D
      </ul>
  <td>NEDirectConvolutionLayer
  <td>
      <ul>
       <li>NHWC
       <li>NCHW
      </ul>
  <td>
    <table>
    <tr><th>src0<th>src1<th>src2<th>dst
    <tr><td>F16<td>F16<td>F16<td>F16
    <tr><td>F32<td>F32<td>F32<td>F32
    </table>
<tr>
  <td>CLDirectConvolutionLayer
  <td>
      <ul>
       <li>NHWC
       <li>NCHW
      </ul>
  <td>
    <table>
    <tr><th>src0<th>src1<th>src2<th>dst
    <tr><td>F16<td>F16<td>F16<td>F16
    <tr><td>F32<td>F32<td>F32<td>F32
    <tr><td>QASYMM8<td>QASYMM8<td>S32<td>QASYMM8
    <tr><td>QASYMM8_SIGNED<td>QASYMM8_SIGNED<td>S32<td>QASYMM8_SIGNED
    </table>
<tr>
  <td rowspan="2">FFT1D
  <td rowspan="2" style="width:200px;"> Fast Fourier Transform 1D
  <td rowspan="2">
      <ul>
       <li>None
      </ul>
  <td>NEFFT1D
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>F32<td>F32
    </table>
<tr>
  <td>CLFFT1D
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>F32<td>F32
    <tr><td>F16<td>F16
    </table>
<tr>
  <td rowspan="2">FFT2D
  <td rowspan="2" style="width:200px;"> Fast Fourier Transform 2D
  <td rowspan="2">
      <ul>
       <li>None
      </ul>
  <td>NEFFT2D
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>F32<td>F32
    </table>
<tr>
  <td>CLFFT2D
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>F32<td>F32
    <tr><td>F16<td>F16
    </table>
<tr>
  <td rowspan="2">FFTConvolutionLayer
  <td rowspan="2" style="width:200px;"> Fast Fourier Transform Convolution
  <td rowspan="2">
      <ul>
       <li>ANEURALNETWORKS_CONV_2D
      </ul>
  <td>NEFFTConvolutionLayer
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>F32<td>F32
    </table>
<tr>
  <td>CLFFTConvolutionLayer
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>F32<td>F32
    <tr><td>F16<td>F16
    </table>
<tr>
  <td rowspan="2">Fill
  <td rowspan="2" style="width:200px;"> Set the values of a tensor with a given value
  <td rowspan="2">
      <ul>
       <li>ANEURALNETWORKS_FILL
      </ul>
  <td>NEFill
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>All<td>All
    </table>
<tr>
  <td>CLFill
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>All<td>All
    </table>
<tr>
  <td rowspan="2">Floor
  <td rowspan="2" style="width:200px;"> Round the value to the lowest number
  <td rowspan="2">
      <ul>
       <li>ANEURALNETWORKS_FLOOR
      </ul>
  <td>NEFloor
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>F32<td>F32
    <tr><td>F16<td>F16
    </table>
<tr>
  <td>CLFloor
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>F32<td>F32
    <tr><td>F16<td>F16
    </table>
<tr>
  <td rowspan="2">Permute
  <td rowspan="2" style="width:200px;"> Function to transpose an ND tensor.
  <td rowspan="2">
      <ul>
       <li>ANEURALNETWORKS_TRANSPOSE
      </ul>
  <td>NEPermute
  <td>
      <ul>
       <li>NHWC
       <li>NCHW
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>All<td>All
    </table>
<tr>
  <td>CLPermute
  <td>
      <ul>
       <li>NHWC
       <li>NCHW
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>All<td>All
    </table>
<tr>
  <td rowspan="2">PixelWiseMultiplication
  <td rowspan="2" style="width:200px;"> Function to performe a multiplication.
  <td rowspan="2">
      <ul>
       <li>ANEURALNETWORKS_MUL
      </ul>
  <td>NEPixelWiseMultiplication
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src0<th>src1<th>dst
    <tr><td>QASYMM8<td>QASYMM8<td>QASYMM8
    <tr><td>QASYMM8_SIGNED<td>QASYMM8_SIGNED<td>QASYMM8_SIGNED
    <tr><td>QSYMM16<td>QSYMM16<td>QASYMM16
    <tr><td>QSYMM16<td>QSYMM16<td>S32
    <tr><td>U8<td>U8<td>U8
    <tr><td>U8<td>U8<td>S16
    <tr><td>U8<td>S16<td>S16
    <tr><td>S16<td>U8<td>S16
    <tr><td>S16<td>S16<td>S16
    <tr><td>F16<td>F16<td>F16
    <tr><td>F32<td>S32<td>F32
    </table>
<tr>
  <td>CLPixelWiseMultiplication
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src0<th>src1<th>dst
    <tr><td>QASYMM8<td>QASYMM8<td>QASYMM8
    <tr><td>QASYMM8_SIGNED<td>QASYMM8_SIGNED<td>QASYMM8_SIGNED
    <tr><td>QSYMM16<td>QSYMM16<td>QASYMM16
    <tr><td>QSYMM16<td>QSYMM16<td>S32
    <tr><td>U8<td>U8<td>U8
    <tr><td>U8<td>U8<td>S16
    <tr><td>U8<td>S16<td>S16
    <tr><td>S16<td>U8<td>S16
    <tr><td>S16<td>S16<td>S16
    <tr><td>F16<td>F16<td>F16
    <tr><td>F32<td>S32<td>F32
    </table>
<tr>
  <td rowspan="2">PoolingLayer
  <td rowspan="2" style="width:200px;"> Function to performe pooling with the specified pooling operation.
  <td rowspan="2">
      <ul>
       <li>ANEURALNETWORKS_AVERAGE_POOL_2D
       <li>ANEURALNETWORKS_L2_POOL_2D
       <li>ANEURALNETWORKS_MAX_POOL_2D
      </ul>
  <td>NEPoolingLayer
  <td>
      <ul>
       <li>NHWC
       <li>NCHW
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>QASYMM8<td>QASYMM8
    <tr><td>QASYMM8_SIGNED<td>QASYMM8_SIGNED
    <tr><td>F16<td>F16
    <tr><td>F32<td>F32
    </table>
<tr>
  <td>CLPoolingLayer
  <td>
      <ul>
       <li>NHWC
       <li>NCHW
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>QASYMM8<td>QASYMM8
    <tr><td>QASYMM8_SIGNED<td>QASYMM8_SIGNED
    <tr><td>F16<td>F16
    <tr><td>F32<td>F32
    </table>
<tr>
  <td rowspan="2">PReluLayer
  <td rowspan="2" style="width:200px;"> Function to compute the activation layer with the PRELU activation function.
  <td rowspan="2">
      <ul>
       <li>ANEURALNETWORKS_PRELU
      </ul>
  <td>NEPReluLayer
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>QASYMM8<td>QASYMM8
    <tr><td>QASYMM8_SIGNED<td>QASYMM8_SIGNED
    <tr><td>F16<td>F16
    <tr><td>F32<td>F32
    </table>
<tr>
  <td>CLPReluLayer
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>QASYMM8<td>QASYMM8
    <tr><td>QASYMM8_SIGNED<td>QASYMM8_SIGNED
    <tr><td>F16<td>F16
    <tr><td>F32<td>F32
    </table>
<tr>
  <td rowspan="2">QuantizationLayer
  <td rowspan="2" style="width:200px;"> Function to perform quantization layer
  <td rowspan="2">
      <ul>
       <li>ANEURALNETWORKS_QUANTIZE
      </ul>
  <td>NEQuantizationLayer
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>QASYMM8<td>QASYMM8
    <tr><td>QASYMM8<td>QASYMM8_SIGNED
    <tr><td>QASYMM8<td>QASYMM16
    <tr><td>QASYMM8_SIGNED<td>QASYMM8
    <tr><td>QASYMM8_SIGNED<td>QASYMM8_SIGNED
    <tr><td>QASYMM8_SIGNED<td>QASYMM16
    <tr><td>F16<td>QASYMM8
    <tr><td>F16<td>QASYMM8_SIGNED
    <tr><td>F16<td>QASYMM16
    <tr><td>F32<td>QASYMM8
    <tr><td>F32<td>QASYMM8_SIGNED
    <tr><td>F32<td>QASYMM16
    </table>
<tr>
  <td>CLQuantizationLayer
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>QASYMM8<td>QASYMM8
    <tr><td>QASYMM8<td>QASYMM8_SIGNED
    <tr><td>QASYMM8<td>QASYMM16
    <tr><td>QASYMM8_SIGNED<td>QASYMM8
    <tr><td>QASYMM8_SIGNED<td>QASYMM8_SIGNED
    <tr><td>QASYMM8_SIGNED<td>QASYMM16
    <tr><td>F16<td>QASYMM8
    <tr><td>F16<td>QASYMM8_SIGNED
    <tr><td>F16<td>QASYMM16
    <tr><td>F32<td>QASYMM8
    <tr><td>F32<td>QASYMM8_SIGNED
    <tr><td>F32<td>QASYMM16
    </table>
<tr>
  <td rowspan="2">ReshapeLayer
  <td rowspan="2" style="width:200px;"> Fucntion to reshape a tensor
  <td rowspan="2">
      <ul>
       <li>ANEURALNETWORKS_RESHAPE
       <li>ANEURALNETWORKS_SQUEEZE
      </ul>
  <td>NEReshapeLayer
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>All<td>All
    </table>
<tr>
  <td>CLReshapeLayer
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>All<td>All
    </table>
<tr>
  <td rowspan="2">Scale
  <td rowspan="2" style="width:200px;"> Fucntion to perform resize a tensor using to interpolate: - Bilenear - Nearest neighbor
  <td rowspan="2">
      <ul>
       <li>ANEURALNETWORKS_RESIZE_BILINEAR
       <li>ANEURALNETWORKS_RESIZE_NEAREST_NEIGHBOR
      </ul>
  <td>NEScale
  <td>
      <ul>
       <li>NHWC
       <li>NCHW
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>QASYMM8<td>QASYMM8
    <tr><td>QASYMM8_SIGNED<td>QASYMM8_SIGNED
    <tr><td>F16<td>F16
    <tr><td>F32<td>F32
    <tr><td>U8<td>U8
    <tr><td>S16<td>S16
    </table>
<tr>
  <td>CLScale
  <td>
      <ul>
       <li>NHWC
       <li>NCHW
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>QASYMM8<td>QASYMM8
    <tr><td>QASYMM8_SIGNED<td>QASYMM8_SIGNED
    <tr><td>F16<td>F16
    <tr><td>F32<td>F32
    <tr><td>U8<td>U8
    <tr><td>S16<td>S16
    </table>
<tr>
  <td rowspan="2">Slice
  <td rowspan="2" style="width:200px;"> Function to perform tensor slicing.
  <td rowspan="2">
      <ul>
       <li>ANEURALNETWORKS_SLICE
      </ul>
  <td>NESlice
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>All<td>All
    </table>
<tr>
  <td>CLSlice
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>All<td>All
    </table>
<tr>
  <td rowspan="2">StridedSlice
  <td rowspan="2" style="width:200px;"> Function to extract a strided slice of a tensor.
  <td rowspan="2">
      <ul>
       <li>ANEURALNETWORKS_STRIDED_SLICE
      </ul>
  <td>NEStridedSlice
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>All<td>All
    </table>
<tr>
  <td>CLStridedSlice
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>All<td>All
    </table>
<tr>
  <td rowspan="2">Transpose
  <td rowspan="2" style="width:200px;"> Function to transpose an 2D tensor.
  <td rowspan="2">
      <ul>
       <li>ANEURALNETWORKS_TRANSPOSE
      </ul>
  <td>NETranspose
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>All<td>All
    </table>
<tr>
  <td>CLTranspose
  <td>
      <ul>
       <li>All
      </ul>
  <td>
    <table>
    <tr><th>src<th>dst
    <tr><td>All<td>All
    </table>
</table>

*/
} // namespace