<!-- HTML header for doxygen 1.8.15-->
<!-- Remember to use version doxygen 1.8.15 +-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="robots" content="NOINDEX, NOFOLLOW" /> <!-- Prevent indexing by search engines -->
<title>Compute Library: NEGEMMConvolutionLayer Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <img alt="Compute Library" src="https://raw.githubusercontent.com/ARM-software/ComputeLibrary/gh-pages/ACL_logo.png" style="max-width: 100%;margin-top: 15px;margin-left: 10px"/>
  <td style="padding-left: 0.5em;">
   <div id="projectname">
   &#160;<span id="projectnumber">23.05.1</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a>  </div>
  <div class="headertitle">
<div class="title">NEGEMMConvolutionLayer Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Basic function to compute the convolution layer.  
 <a href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_n_e_g_e_m_m_convolution_layer_8h_source.xhtml">NEGEMMConvolutionLayer.h</a>&gt;</code></p>
<div class="dynheader">
Collaboration diagram for NEGEMMConvolutionLayer:</div>
<div class="dyncontent">
<div class="center"><iframe scrolling="no" frameborder="0" src="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer__coll__graph.svg" width="207" height="112"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe>
</div>
<center><span class="legend">[<a target="top" href="graph_legend.xhtml">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a627cee3df543519d4a134291189a3b9e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#a627cee3df543519d4a134291189a3b9e">NEGEMMConvolutionLayer</a> (const std::shared_ptr&lt; <a class="el" href="classarm__compute_1_1_i_memory_manager.xhtml">IMemoryManager</a> &gt; &amp;memory_manager=nullptr, <a class="el" href="classarm__compute_1_1_i_weights_manager.xhtml">IWeightsManager</a> *weights_manager=nullptr)</td></tr>
<tr class="memdesc:a627cee3df543519d4a134291189a3b9e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor.  <a href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#a627cee3df543519d4a134291189a3b9e">More...</a><br /></td></tr>
<tr class="separator:a627cee3df543519d4a134291189a3b9e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4d64dcaa798d09b11067f19b3c48ebe"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#af4d64dcaa798d09b11067f19b3c48ebe">NEGEMMConvolutionLayer</a> (const <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a> &amp;)=delete</td></tr>
<tr class="memdesc:af4d64dcaa798d09b11067f19b3c48ebe"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prevent instances of this class from being copied (As this class contains pointers)  <a href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#af4d64dcaa798d09b11067f19b3c48ebe">More...</a><br /></td></tr>
<tr class="separator:af4d64dcaa798d09b11067f19b3c48ebe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0ca1d9eef7f625852f19f03912dc82b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#aa0ca1d9eef7f625852f19f03912dc82b">NEGEMMConvolutionLayer</a> (<a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a> &amp;&amp;)=delete</td></tr>
<tr class="memdesc:aa0ca1d9eef7f625852f19f03912dc82b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prevent instances of this class from being moved (As this class contains non movable objects)  <a href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#aa0ca1d9eef7f625852f19f03912dc82b">More...</a><br /></td></tr>
<tr class="separator:aa0ca1d9eef7f625852f19f03912dc82b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac13c7e80f7e9e6f1e2912ef50678c5c9"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#ac13c7e80f7e9e6f1e2912ef50678c5c9">operator=</a> (const <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a> &amp;)=delete</td></tr>
<tr class="memdesc:ac13c7e80f7e9e6f1e2912ef50678c5c9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prevent instances of this class from being copied (As this class contains pointers)  <a href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#ac13c7e80f7e9e6f1e2912ef50678c5c9">More...</a><br /></td></tr>
<tr class="separator:ac13c7e80f7e9e6f1e2912ef50678c5c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8acdec23e4476abdc73729d29bf5db70"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#a8acdec23e4476abdc73729d29bf5db70">operator=</a> (<a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a> &amp;&amp;)=delete</td></tr>
<tr class="memdesc:a8acdec23e4476abdc73729d29bf5db70"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prevent instances of this class from being moved (As this class contains non movable objects)  <a href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#a8acdec23e4476abdc73729d29bf5db70">More...</a><br /></td></tr>
<tr class="separator:a8acdec23e4476abdc73729d29bf5db70"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a266d82adb44b9059c7fa0ba5ecf4300a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#a266d82adb44b9059c7fa0ba5ecf4300a">~NEGEMMConvolutionLayer</a> ()</td></tr>
<tr class="memdesc:a266d82adb44b9059c7fa0ba5ecf4300a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Default destructor.  <a href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#a266d82adb44b9059c7fa0ba5ecf4300a">More...</a><br /></td></tr>
<tr class="separator:a266d82adb44b9059c7fa0ba5ecf4300a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9f0e9c2c6de4772d2f3c784b039d65fa"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#a9f0e9c2c6de4772d2f3c784b039d65fa">configure</a> (const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *input, const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *weights, const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *biases, <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *output, const <a class="el" href="classarm__compute_1_1_pad_stride_info.xhtml">PadStrideInfo</a> &amp;conv_info, const <a class="el" href="classarm__compute_1_1_weights_info.xhtml">WeightsInfo</a> &amp;weights_info=<a class="el" href="classarm__compute_1_1_weights_info.xhtml">WeightsInfo</a>(), const <a class="el" href="classarm__compute_1_1_size2_d.xhtml">Size2D</a> &amp;dilation=<a class="el" href="classarm__compute_1_1_size2_d.xhtml">Size2D</a>(1U, 1U), const <a class="el" href="classarm__compute_1_1_activation_layer_info.xhtml">ActivationLayerInfo</a> &amp;act_info=<a class="el" href="classarm__compute_1_1_activation_layer_info.xhtml">ActivationLayerInfo</a>(), bool enable_fast_math=false, unsigned int num_groups=1)</td></tr>
<tr class="memdesc:a9f0e9c2c6de4772d2f3c784b039d65fa"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the input and output tensors.  <a href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#a9f0e9c2c6de4772d2f3c784b039d65fa">More...</a><br /></td></tr>
<tr class="separator:a9f0e9c2c6de4772d2f3c784b039d65fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad1717410afd0be936c6213a63c8005fb"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#ad1717410afd0be936c6213a63c8005fb">run</a> () override</td></tr>
<tr class="memdesc:ad1717410afd0be936c6213a63c8005fb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Run the kernels contained in the function.  <a href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#ad1717410afd0be936c6213a63c8005fb">More...</a><br /></td></tr>
<tr class="separator:ad1717410afd0be936c6213a63c8005fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9b93ef660fc3c5b4b19d3fc7b891b77"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#aa9b93ef660fc3c5b4b19d3fc7b891b77">prepare</a> () override</td></tr>
<tr class="memdesc:aa9b93ef660fc3c5b4b19d3fc7b891b77"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prepare the function for executing.  <a href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#aa9b93ef660fc3c5b4b19d3fc7b891b77">More...</a><br /></td></tr>
<tr class="separator:aa9b93ef660fc3c5b4b19d3fc7b891b77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classarm__compute_1_1_i_function"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classarm__compute_1_1_i_function')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classarm__compute_1_1_i_function.xhtml">IFunction</a></td></tr>
<tr class="memitem:ab921ecc3f3f6ae2b4bd61f3e1998d8c4 inherit pub_methods_classarm__compute_1_1_i_function"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_function.xhtml#ab921ecc3f3f6ae2b4bd61f3e1998d8c4">~IFunction</a> ()=default</td></tr>
<tr class="memdesc:ab921ecc3f3f6ae2b4bd61f3e1998d8c4 inherit pub_methods_classarm__compute_1_1_i_function"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destructor.  <a href="classarm__compute_1_1_i_function.xhtml#ab921ecc3f3f6ae2b4bd61f3e1998d8c4">More...</a><br /></td></tr>
<tr class="separator:ab921ecc3f3f6ae2b4bd61f3e1998d8c4 inherit pub_methods_classarm__compute_1_1_i_function"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:a1a37ad594537835b39165a1369dd254c"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="classarm__compute_1_1_status.xhtml">Status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#a1a37ad594537835b39165a1369dd254c">validate</a> (const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *input, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *weights, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *biases, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *output, const <a class="el" href="classarm__compute_1_1_pad_stride_info.xhtml">PadStrideInfo</a> &amp;conv_info, const <a class="el" href="classarm__compute_1_1_weights_info.xhtml">WeightsInfo</a> &amp;weights_info=<a class="el" href="classarm__compute_1_1_weights_info.xhtml">WeightsInfo</a>(), const <a class="el" href="classarm__compute_1_1_size2_d.xhtml">Size2D</a> &amp;dilation=<a class="el" href="classarm__compute_1_1_size2_d.xhtml">Size2D</a>(1U, 1U), const <a class="el" href="classarm__compute_1_1_activation_layer_info.xhtml">ActivationLayerInfo</a> &amp;act_info=<a class="el" href="classarm__compute_1_1_activation_layer_info.xhtml">ActivationLayerInfo</a>(), bool enable_fast_math=false, unsigned int num_groups=1)</td></tr>
<tr class="memdesc:a1a37ad594537835b39165a1369dd254c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Static function to check if given info will lead to a valid configuration of <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a>.  <a href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#a1a37ad594537835b39165a1369dd254c">More...</a><br /></td></tr>
<tr class="separator:a1a37ad594537835b39165a1369dd254c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6aa14137d9d91a2416434db337870bb"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="classarm__compute_1_1_status.xhtml">Status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#ad6aa14137d9d91a2416434db337870bb">has_opt_impl</a> (<a class="el" href="namespacearm__compute.xhtml#a23ab0e5c6b5d13e084628686c4f282d5">arm_compute::WeightFormat</a> &amp;expected_weight_format, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *src, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *weights, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *biases, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *dst, const <a class="el" href="classarm__compute_1_1_pad_stride_info.xhtml">PadStrideInfo</a> &amp;conv_info, const <a class="el" href="classarm__compute_1_1_weights_info.xhtml">WeightsInfo</a> &amp;weights_info=<a class="el" href="classarm__compute_1_1_weights_info.xhtml">WeightsInfo</a>(), const <a class="el" href="classarm__compute_1_1_size2_d.xhtml">Size2D</a> &amp;dilation=<a class="el" href="classarm__compute_1_1_size2_d.xhtml">Size2D</a>(1U, 1U), const <a class="el" href="classarm__compute_1_1_activation_layer_info.xhtml">ActivationLayerInfo</a> &amp;act_info=<a class="el" href="classarm__compute_1_1_activation_layer_info.xhtml">ActivationLayerInfo</a>(), bool enable_fast_math=false)</td></tr>
<tr class="memdesc:ad6aa14137d9d91a2416434db337870bb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Static function to check if there is an optimized version of GEMM available for the input parameters.  <a href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#ad6aa14137d9d91a2416434db337870bb">More...</a><br /></td></tr>
<tr class="separator:ad6aa14137d9d91a2416434db337870bb"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Basic function to compute the convolution layer. </p>
<p>This function calls the following kernels/functions:</p>
<ol type="1">
<li><a class="el" href="classarm__compute_1_1cpu_1_1_cpu_gemm_conv2d.xhtml">cpu::CpuGemmConv2d</a> </li>
</ol>

<p class="definition">Definition at line <a class="el" href="_n_e_g_e_m_m_convolution_layer_8h_source.xhtml#l00047">47</a> of file <a class="el" href="_n_e_g_e_m_m_convolution_layer_8h_source.xhtml">NEGEMMConvolutionLayer.h</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a627cee3df543519d4a134291189a3b9e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a627cee3df543519d4a134291189a3b9e">&#9670;&nbsp;</a></span>NEGEMMConvolutionLayer() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a> </td>
          <td>(</td>
          <td class="paramtype">const std::shared_ptr&lt; <a class="el" href="classarm__compute_1_1_i_memory_manager.xhtml">IMemoryManager</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>memory_manager</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_i_weights_manager.xhtml">IWeightsManager</a> *&#160;</td>
          <td class="paramname"><em>weights_manager</em> = <code>nullptr</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructor. </p>

<p class="definition">Definition at line <a class="el" href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml#l00049">49</a> of file <a class="el" href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml">NEGEMMConvolutionLayer.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;    : _impl(std::make_unique&lt;Impl&gt;())</div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;{</div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;    _impl-&gt;weights_manager = weights_manager;</div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;    _impl-&gt;memory_group    = MemoryGroup(memory_manager);</div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;}</div>
</div><!-- fragment -->
</div>
</div>
<a id="af4d64dcaa798d09b11067f19b3c48ebe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af4d64dcaa798d09b11067f19b3c48ebe">&#9670;&nbsp;</a></span>NEGEMMConvolutionLayer() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a> </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a> &amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">delete</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Prevent instances of this class from being copied (As this class contains pointers) </p>

</div>
</div>
<a id="aa0ca1d9eef7f625852f19f03912dc82b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa0ca1d9eef7f625852f19f03912dc82b">&#9670;&nbsp;</a></span>NEGEMMConvolutionLayer() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a> </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a> &amp;&amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">delete</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Prevent instances of this class from being moved (As this class contains non movable objects) </p>

</div>
</div>
<a id="a266d82adb44b9059c7fa0ba5ecf4300a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a266d82adb44b9059c7fa0ba5ecf4300a">&#9670;&nbsp;</a></span>~NEGEMMConvolutionLayer()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">~<a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">default</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Default destructor. </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a9f0e9c2c6de4772d2f3c784b039d65fa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9f0e9c2c6de4772d2f3c784b039d65fa">&#9670;&nbsp;</a></span>configure()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void configure </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>biases</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_pad_stride_info.xhtml">PadStrideInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>conv_info</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_weights_info.xhtml">WeightsInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>weights_info</em> = <code><a class="el" href="classarm__compute_1_1_weights_info.xhtml">WeightsInfo</a>()</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_size2_d.xhtml">Size2D</a> &amp;&#160;</td>
          <td class="paramname"><em>dilation</em> = <code><a class="el" href="classarm__compute_1_1_size2_d.xhtml">Size2D</a>(1U,&#160;1U)</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_activation_layer_info.xhtml">ActivationLayerInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>act_info</em> = <code><a class="el" href="classarm__compute_1_1_activation_layer_info.xhtml">ActivationLayerInfo</a>()</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>enable_fast_math</em> = <code>false</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned int&#160;</td>
          <td class="paramname"><em>num_groups</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Set the input and output tensors. </p>
<p>Valid data layouts:</p><ul>
<li>NHWC</li>
<li>NCHW</li>
</ul>
<p>Valid data type configurations: </p><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">src0 </th><th class="markdownTableHeadLeft">src1 </th><th class="markdownTableHeadLeft">src2 </th><th class="markdownTableHeadLeft">dst  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">F16 </td><td class="markdownTableBodyLeft">F16 </td><td class="markdownTableBodyLeft">F16 </td><td class="markdownTableBodyLeft">F16  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">F32 </td><td class="markdownTableBodyLeft">F32 </td><td class="markdownTableBodyLeft">F32 </td><td class="markdownTableBodyLeft">F32  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">BFLOAT16 </td><td class="markdownTableBodyLeft">BFLOAT16 </td><td class="markdownTableBodyLeft">BFLOAT16 </td><td class="markdownTableBodyLeft">BFLOAT16  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">QASYMM8 </td><td class="markdownTableBodyLeft">QASYMM8 </td><td class="markdownTableBodyLeft">S32 </td><td class="markdownTableBodyLeft">QASYMM8  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">QASYMM8 </td><td class="markdownTableBodyLeft">QSYMM8_PER_CHANNEL </td><td class="markdownTableBodyLeft">S32 </td><td class="markdownTableBodyLeft">QASYMM8  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">QASYMM8_SIGNED </td><td class="markdownTableBodyLeft">QASYMM8_SIGNED </td><td class="markdownTableBodyLeft">S32 </td><td class="markdownTableBodyLeft">QASYMM8_SIGNED  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">QASYMM8_SIGNED </td><td class="markdownTableBodyLeft">QSYMM8_PER_CHANNEL </td><td class="markdownTableBodyLeft">S32 </td><td class="markdownTableBodyLeft">QASYMM8_SIGNED  </td></tr>
</table>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">input</td><td>Source tensor. 3 lower dimensions represent a single input [width, height, IFM], while every optional dimension from 4 and above represent a batch of inputs. Data types supported: QASYMM8/QASYMM8_SIGNED/BFLOAT16/F16/F32. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">weights</td><td>Weights tensor. Weights are 4D tensor with dimensions [kernel_x, kernel_y, IFM, OFM]. Data type supported: QASYMM8/QASYMM8_SIGNED/QSYMM8_PER_CHANNEL/BFLOAT16/F16/F32. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">biases</td><td>Biases tensor. Shared biases supported. Biases are 1D tensor with dimensions [OFM]. Data type supported: Should match <code>input</code> data type, except for input of QASYMM8/QASYMM8_SIGNED type where biases should be of S32 type. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output</td><td>Destination tensor. 3 lower dimensions represent a single output [width, height, OFM], while the rest represent batch of outputs. Data types supported: Same as <code>input</code>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">conv_info</td><td>Contains padding and stride information described in <a class="el" href="classarm__compute_1_1_pad_stride_info.xhtml">PadStrideInfo</a>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">weights_info</td><td>Specifies if the weights tensor has been reshaped with NEWeightsReshapeKernel. If this is not part of the fully connected layer the weights tensor has also been transposed with <a class="el" href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_transpose1x_w_kernel.xhtml" title="Kernel which transposes the elements of a matrix in chunks of 1xW, where W is equal to (16 / element ...">cpu::kernels::CpuGemmTranspose1xWKernel</a>. Data type supported: Same as <code>input</code>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation</td><td>(Optional) Dilation, in elements, across x and y. Defaults to (1, 1). </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_info</td><td>(Optional) Activation layer information in case of a fused activation. Only RELU, BOUNDED_RELU and LU_BOUNDED_RELU supported. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">enable_fast_math</td><td>(Optional) Enable fast math computation. In case this flag were set, the function could dispatch the fastest implementation available which may introduce a drop of accuracy as well. Default is false </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_groups</td><td>(Optional) Number of groups when performing a grouped convolution. num_groups != 1 is not supported </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml#l00057">57</a> of file <a class="el" href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml">NEGEMMConvolutionLayer.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;{</div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;    <a class="code" href="arm__compute_2core_2_validate_8h.xhtml#a921b705e9e3e0fe928928447869e62a5">ARM_COMPUTE_ERROR_ON_NULLPTR</a>(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>, weights, output);</div>
<div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160; </div>
<div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;    _impl-&gt;weights = weights;</div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;    _impl-&gt;op      = std::make_unique&lt;cpu::CpuGemmConv2d&gt;();</div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;    _impl-&gt;op-&gt;configure(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>-&gt;info(), weights-&gt;info(), (biases != <span class="keyword">nullptr</span> ? biases-&gt;info() : <span class="keyword">nullptr</span>), output-&gt;info(), <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a00525ff582f16038a1d3819aa44a23a3">conv_info</a>, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a7cb842ebfe255726066039853a4322f0">weights_info</a>, dilation, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a1f8aca235c095df227e7444f6b237eb1">act_info</a>, enable_fast_math, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a2270b3e1d20651d2d8341c858c890830">num_groups</a>);</div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160; </div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;    _impl-&gt;run_pack =</div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;    {</div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;        { <a class="code" href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828a135adba4335f0b231907ea8f61f9aff5">TensorType::ACL_SRC_0</a>, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a> },</div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;        { <a class="code" href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828a33d31c31e7afde56ed0070133d4568a0">TensorType::ACL_SRC_1</a>, weights },</div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;        { <a class="code" href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828a01cea947a24713975f86d0769bf8fad5">TensorType::ACL_SRC_2</a>, biases },</div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;        { <a class="code" href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828a6f62ab7395c218e03e9d2942309c13a2">TensorType::ACL_DST</a>, output }</div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;    };</div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;    _impl-&gt;aux_mem_req       = _impl-&gt;op-&gt;workspace();</div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;    _impl-&gt;workspace_tensors = manage_workspace&lt;Tensor&gt;(_impl-&gt;aux_mem_req, _impl-&gt;memory_group, _impl-&gt;run_pack, _impl-&gt;run_pack);</div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00055">arm_compute::ACL_DST</a>, <a class="el" href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00045">arm_compute::ACL_SRC_0</a>, <a class="el" href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00046">arm_compute::ACL_SRC_1</a>, <a class="el" href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00047">arm_compute::ACL_SRC_2</a>, <a class="el" href="_c_l_2_direct_convolution_layer_8cpp_source.xhtml#l00547">arm_compute::test::validation::act_info</a>, <a class="el" href="arm__compute_2core_2_validate_8h_source.xhtml#l00157">ARM_COMPUTE_ERROR_ON_NULLPTR</a>, <a class="el" href="_c_l_2_convolution_layer_8cpp_source.xhtml#l00407">arm_compute::test::validation::conv_info</a>, <a class="el" href="classarm__compute_1_1_i_tensor.xhtml#a0e95dc1e53c361348314873b168ae237">ITensor::info()</a>, <a class="el" href="_c_l_2_l_s_t_m_layer_quantized_8cpp_source.xhtml#l00486">arm_compute::test::validation::input</a>, <a class="el" href="_n_e_o_n_2_im2_col_8cpp_source.xhtml#l00153">arm_compute::test::validation::num_groups</a>, and <a class="el" href="_c_l_2_batch_normalization_layer_8cpp_source.xhtml#l00165">arm_compute::test::validation::weights_info</a>.</p>

</div>
</div>
<a id="ad6aa14137d9d91a2416434db337870bb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad6aa14137d9d91a2416434db337870bb">&#9670;&nbsp;</a></span>has_opt_impl()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_status.xhtml">Status</a> has_opt_impl </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="namespacearm__compute.xhtml#a23ab0e5c6b5d13e084628686c4f282d5">arm_compute::WeightFormat</a> &amp;&#160;</td>
          <td class="paramname"><em>expected_weight_format</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>src</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>biases</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>dst</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_pad_stride_info.xhtml">PadStrideInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>conv_info</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_weights_info.xhtml">WeightsInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>weights_info</em> = <code><a class="el" href="classarm__compute_1_1_weights_info.xhtml">WeightsInfo</a>()</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_size2_d.xhtml">Size2D</a> &amp;&#160;</td>
          <td class="paramname"><em>dilation</em> = <code><a class="el" href="classarm__compute_1_1_size2_d.xhtml">Size2D</a>(1U,&#160;1U)</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_activation_layer_info.xhtml">ActivationLayerInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>act_info</em> = <code><a class="el" href="classarm__compute_1_1_activation_layer_info.xhtml">ActivationLayerInfo</a>()</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>enable_fast_math</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Static function to check if there is an optimized version of GEMM available for the input parameters. </p>
<p>The method is intended to be used to find out the optimal memory layout to be used for the weights tensor when running variable weights execution.</p>
<p>The user can query the database of optimised kernels in <a class="el" href="namespacearm__gemm.xhtml">arm_gemm</a> by specifying one of the enumerations of <a class="el" href="namespacearm__compute.xhtml#a23ab0e5c6b5d13e084628686c4f282d5" title="Memory layouts for the weights tensor.">arm_compute::WeightFormat</a> in the weight_format field of the input parameter weights_info. In case of success, the method writes the expected format in the output parameter expected_weight_format. The expected_weight_format can than be used in the configure method of the class for retrieving the best optimal kernel.</p>
<p>Use case one - query for a specific format: </p><pre class="fragment">WeightInfo weights_info(..., arm_compute::WeightFormat::OHWIo4, ...); // Set the value of the input query.
if (NEGEMMConvolutionlayer::has_opt_impl(WeightFormat(), ...., weights_info, ...))
{
  auto conv = std::unique_ptr&lt;NEGEMMConvolutionlayer&gt;();
  conv-&gt;configure(..., weights_info, ...);  // uses the same WeightFormat the user wanted originally, OHWYo4.
  conv-&gt;run(...);
}
</pre><p>Use case two - query for any format that would be optimal for the GEMM to execute: </p><pre class="fragment">WeightInfo weights_info(..., arm_compute::WeightFormat::ANY, ...); // Set the value of the input query.
arm_compute::WeightFormat expected_wf;
if (NEGEMMConvolutionlayer::has_opt_impl(expected_wf, ...., weights_info, ...))
{
  auto conv = std::unique_ptr&lt;NEGEMMConvolutionlayer&gt;();
  // ... code to convert the layout of the weights tensor to the layout returned by has_opt_impl
  WeightInfo new_weights_info(..., expected_wf, ...); // Set the value of the WeightFormat returned by has_opt_impl.
  conv-&gt;configure(..., new_weights_info, ...);
  conv-&gt;run(...);
}
</pre><p>Notice that a GEMM configured with a WeightFormat other than UNSPECIFIED will run GEMM with variable weights mode.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[out]</td><td class="paramname">expected_weight_format</td><td>The <a class="el" href="namespacearm__compute.xhtml#a23ab0e5c6b5d13e084628686c4f282d5" title="Memory layouts for the weights tensor.">arm_compute::WeightFormat</a> expected by the kernel. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">src</td><td>Source tensor info. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">weights</td><td>Weights tensor info. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">biases</td><td>Biases tensor info. Shared biases supported. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dst</td><td>Destination tensor info. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">conv_info</td><td>Contains padding and stride information described in <a class="el" href="classarm__compute_1_1_pad_stride_info.xhtml">PadStrideInfo</a>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">weights_info</td><td>(optional) Specifies additional configuration parameters for the weights of the GEMM computation. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation</td><td>(Optional) Dilation, in elements, across x and y. Defaults to (1, 1). </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_info</td><td>(Optional) Activation layer information in case of a fused activation. Only RELU, BOUNDED_RELU and LU_BOUNDED_RELU supported. And no activation (i.e. Linear) which is the default value. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">enable_fast_math</td><td>(Optional) Enable fast math computation. In case this flag were set, the function could dispatch the fastest implementation</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a <a class="el" href="classarm__compute_1_1_status.xhtml" title="Status class.">Status</a> </dd></dl>

<p class="definition">Definition at line <a class="el" href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml#l00083">83</a> of file <a class="el" href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml">NEGEMMConvolutionLayer.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;{</div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classarm__compute_1_1cpu_1_1_cpu_gemm_conv2d.xhtml#ac762dddea5efe1c583eb3e6667126ddb">cpu::CpuGemmConv2d::has_opt_impl</a>(expected_weight_format, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a70879f7be69f6738d9f76339725c9532">src</a>, weights, biases, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#adbf67dcee294e673cf796f1ed8aeb6a4">dst</a>, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a00525ff582f16038a1d3819aa44a23a3">conv_info</a>, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a7cb842ebfe255726066039853a4322f0">weights_info</a>, dilation, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a1f8aca235c095df227e7444f6b237eb1">act_info</a>, enable_fast_math);</div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="_c_l_2_direct_convolution_layer_8cpp_source.xhtml#l00547">arm_compute::test::validation::act_info</a>, <a class="el" href="_c_l_2_convolution_layer_8cpp_source.xhtml#l00407">arm_compute::test::validation::conv_info</a>, <a class="el" href="_c_p_p_2_d_f_t_8cpp_source.xhtml#l00170">arm_compute::test::validation::dst</a>, <a class="el" href="_cpu_gemm_conv2d_8cpp_source.xhtml#l00398">CpuGemmConv2d::has_opt_impl()</a>, <a class="el" href="_c_p_p_2_d_f_t_8cpp_source.xhtml#l00155">arm_compute::test::validation::src</a>, and <a class="el" href="_c_l_2_batch_normalization_layer_8cpp_source.xhtml#l00165">arm_compute::test::validation::weights_info</a>.</p>

</div>
</div>
<a id="ac13c7e80f7e9e6f1e2912ef50678c5c9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac13c7e80f7e9e6f1e2912ef50678c5c9">&#9670;&nbsp;</a></span>operator=() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a>&amp; operator= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a> &amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">delete</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Prevent instances of this class from being copied (As this class contains pointers) </p>

</div>
</div>
<a id="a8acdec23e4476abdc73729d29bf5db70"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8acdec23e4476abdc73729d29bf5db70">&#9670;&nbsp;</a></span>operator=() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a>&amp; operator= </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a> &amp;&amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">delete</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Prevent instances of this class from being moved (As this class contains non movable objects) </p>

</div>
</div>
<a id="aa9b93ef660fc3c5b4b19d3fc7b891b77"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa9b93ef660fc3c5b4b19d3fc7b891b77">&#9670;&nbsp;</a></span>prepare()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void prepare </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Prepare the function for executing. </p>
<p>Any one off pre-processing step required by the function is handled here</p>
<dl class="section note"><dt>Note</dt><dd>Prepare stage might not need all the function's buffers' backing memory to be available in order to execute </dd></dl>

<p>Reimplemented from <a class="el" href="classarm__compute_1_1_i_function.xhtml#a820f7291c24155a2980512fae45aac26">IFunction</a>.</p>

<p class="definition">Definition at line <a class="el" href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml#l00097">97</a> of file <a class="el" href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml">NEGEMMConvolutionLayer.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;{</div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;    <span class="keywordflow">if</span>(!_impl-&gt;is_prepared)</div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;    {</div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;        _impl-&gt;op-&gt;prepare(_impl-&gt;run_pack);</div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160; </div>
<div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;        <span class="comment">// Release temporary tensors that are only used in prepare stage</span></div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;        release_temporaries&lt;Tensor&gt;(_impl-&gt;aux_mem_req, _impl-&gt;workspace_tensors);</div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;        _impl-&gt;is_prepared = <span class="keyword">true</span>;</div>
<div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;    }</div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml#l00090">NEGEMMConvolutionLayer::run()</a>.</p>

</div>
</div>
<a id="ad1717410afd0be936c6213a63c8005fb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad1717410afd0be936c6213a63c8005fb">&#9670;&nbsp;</a></span>run()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void run </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Run the kernels contained in the function. </p>
<p>For CPU kernels:</p><ul>
<li>Multi-threading is used for the kernels which are parallelisable.</li>
<li>By default std::thread::hardware_concurrency() threads are used.</li>
</ul>
<dl class="section note"><dt>Note</dt><dd><a class="el" href="classarm__compute_1_1_c_p_p_scheduler.xhtml#ae64eebaa07f4d2da6cc2ba538c3cb095">CPPScheduler::set_num_threads()</a> can be used to manually set the number of threads</dd></dl>
<p>For OpenCL kernels:</p><ul>
<li>All the kernels are enqueued on the queue associated with <a class="el" href="classarm__compute_1_1_c_l_scheduler.xhtml" title="Provides global access to a CL context and command queue.">CLScheduler</a>.</li>
<li>The queue is then flushed.</li>
</ul>
<dl class="section note"><dt>Note</dt><dd>The function will not block until the kernels are executed. It is the user's responsibility to wait. </dd>
<dd>
Will call <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#aa9b93ef660fc3c5b4b19d3fc7b891b77" title="Prepare the function for executing.">prepare()</a> on first run if hasn't been done </dd></dl>

<p>Implements <a class="el" href="classarm__compute_1_1_i_function.xhtml#a18954417d3124a8095783ea13dc6d00b">IFunction</a>.</p>

<p class="definition">Definition at line <a class="el" href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml#l00090">90</a> of file <a class="el" href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml">NEGEMMConvolutionLayer.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;{</div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;    <a class="code" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#aa9b93ef660fc3c5b4b19d3fc7b891b77">prepare</a>();</div>
<div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;    MemoryGroupResourceScope scope_mg(_impl-&gt;memory_group);</div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;    _impl-&gt;op-&gt;run(_impl-&gt;run_pack);</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml#l00097">NEGEMMConvolutionLayer::prepare()</a>.</p>

</div>
</div>
<a id="a1a37ad594537835b39165a1369dd254c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1a37ad594537835b39165a1369dd254c">&#9670;&nbsp;</a></span>validate()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_status.xhtml">Status</a> validate </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>biases</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_pad_stride_info.xhtml">PadStrideInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>conv_info</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_weights_info.xhtml">WeightsInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>weights_info</em> = <code><a class="el" href="classarm__compute_1_1_weights_info.xhtml">WeightsInfo</a>()</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_size2_d.xhtml">Size2D</a> &amp;&#160;</td>
          <td class="paramname"><em>dilation</em> = <code><a class="el" href="classarm__compute_1_1_size2_d.xhtml">Size2D</a>(1U,&#160;1U)</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_activation_layer_info.xhtml">ActivationLayerInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>act_info</em> = <code><a class="el" href="classarm__compute_1_1_activation_layer_info.xhtml">ActivationLayerInfo</a>()</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>enable_fast_math</em> = <code>false</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned int&#160;</td>
          <td class="paramname"><em>num_groups</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Static function to check if given info will lead to a valid configuration of <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">input</td><td>Source tensor info. 3 lower dimensions represent a single input [width, height, IFM], while every optional dimension from 4 and above represent a batch of inputs. Data types supported: QASYMM8/QASYMM8_SIGNED/BFLOAT16/F16/F32. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">weights</td><td>Weights tensor info. Weights are 4D tensor with dimensions [kernel_x, kernel_y, IFM, OFM]. Data type supported: QASYMM8/QASYMM8_SIGNED/QSYMM8_PER_CHANNEL/BFLOAT16/F16/F32. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">biases</td><td>Biases tensor info. Shared biases supported. Biases are 1D tensor with dimensions [OFM]. Data type supported: Should match <code>input</code> data type, except for input of QASYMM8/QASYMM8_SIGNED type where biases should be of S32 type. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">output</td><td>Destination tensor info. 3 lower dimensions represent a single output [width, height, OFM], while the rest represent batch of outputs. Data types supported: Same as <code>input</code>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">conv_info</td><td>Contains padding and stride information described in <a class="el" href="classarm__compute_1_1_pad_stride_info.xhtml">PadStrideInfo</a>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">weights_info</td><td>Specifies if the weights tensor has been reshaped with NEWeightsReshapeKernel. If this is not part of the fully connected layer the weights tensor has also been transposed with <a class="el" href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_transpose1x_w_kernel.xhtml" title="Kernel which transposes the elements of a matrix in chunks of 1xW, where W is equal to (16 / element ...">cpu::kernels::CpuGemmTranspose1xWKernel</a>. Data type supported: Same as <code>input</code>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation</td><td>(Optional) Dilation, in elements, across x and y. Defaults to (1, 1). </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_info</td><td>(Optional) Activation layer information in case of a fused activation. Only RELU, BOUNDED_RELU and LU_BOUNDED_RELU supported. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">enable_fast_math</td><td>(Optional) Enable fast math computation. In case this flag were set, the function could dispatch the fastest implementation available which may introduce a drop of accuracy as well. Default is false </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_groups</td><td>(Optional) Number of groups when performing a grouped convolution. num_groups != 1 is not supported</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a status </dd></dl>

<p class="definition">Definition at line <a class="el" href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml#l00077">77</a> of file <a class="el" href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml">NEGEMMConvolutionLayer.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;{</div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classarm__compute_1_1cpu_1_1_cpu_gemm_conv2d.xhtml#a6d4a3d570df9ced155edcbeef4cf865c">cpu::CpuGemmConv2d::validate</a>(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>, weights, biases, output, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a00525ff582f16038a1d3819aa44a23a3">conv_info</a>, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a7cb842ebfe255726066039853a4322f0">weights_info</a>, dilation, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a1f8aca235c095df227e7444f6b237eb1">act_info</a>, enable_fast_math, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a2270b3e1d20651d2d8341c858c890830">num_groups</a>);</div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="_c_l_2_direct_convolution_layer_8cpp_source.xhtml#l00547">arm_compute::test::validation::act_info</a>, <a class="el" href="_c_l_2_convolution_layer_8cpp_source.xhtml#l00407">arm_compute::test::validation::conv_info</a>, <a class="el" href="_c_l_2_l_s_t_m_layer_quantized_8cpp_source.xhtml#l00486">arm_compute::test::validation::input</a>, <a class="el" href="_n_e_o_n_2_im2_col_8cpp_source.xhtml#l00153">arm_compute::test::validation::num_groups</a>, <a class="el" href="_cpu_gemm_conv2d_8cpp_source.xhtml#l00430">CpuGemmConv2d::validate()</a>, and <a class="el" href="_c_l_2_batch_normalization_layer_8cpp_source.xhtml#l00165">arm_compute::test::validation::weights_info</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>arm_compute/runtime/NEON/functions/<a class="el" href="_n_e_g_e_m_m_convolution_layer_8h_source.xhtml">NEGEMMConvolutionLayer.h</a></li>
<li>src/runtime/NEON/functions/<a class="el" href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml">NEGEMMConvolutionLayer.cpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<div class="ttc" id="anamespacearm__compute_1_1test_1_1validation_xhtml_a70879f7be69f6738d9f76339725c9532"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#a70879f7be69f6738d9f76339725c9532">arm_compute::test::validation::src</a></div><div class="ttdeci">SimpleTensor&lt; float &gt; src</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_p_2_d_f_t_8cpp_source.xhtml#l00155">DFT.cpp:155</a></div></div>
<div class="ttc" id="anamespacearm__compute_1_1test_1_1validation_xhtml_a7cb842ebfe255726066039853a4322f0"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#a7cb842ebfe255726066039853a4322f0">arm_compute::test::validation::weights_info</a></div><div class="ttdeci">weights_info</div><div class="ttdef"><b>Definition:</b> <a href="_c_l_2_batch_normalization_layer_8cpp_source.xhtml#l00165">BatchNormalizationLayer.cpp:165</a></div></div>
<div class="ttc" id="anamespacearm__compute_1_1test_1_1validation_xhtml_adbf67dcee294e673cf796f1ed8aeb6a4"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#adbf67dcee294e673cf796f1ed8aeb6a4">arm_compute::test::validation::dst</a></div><div class="ttdeci">auto dst</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_p_2_d_f_t_8cpp_source.xhtml#l00170">DFT.cpp:170</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_a08e287b5f0197ce8c7c84dde6db24828a135adba4335f0b231907ea8f61f9aff5"><div class="ttname"><a href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828a135adba4335f0b231907ea8f61f9aff5">arm_compute::ACL_SRC_0</a></div><div class="ttdeci">@ ACL_SRC_0</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00045">Types.h:45</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_a08e287b5f0197ce8c7c84dde6db24828a33d31c31e7afde56ed0070133d4568a0"><div class="ttname"><a href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828a33d31c31e7afde56ed0070133d4568a0">arm_compute::ACL_SRC_1</a></div><div class="ttdeci">@ ACL_SRC_1</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00046">Types.h:46</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_a08e287b5f0197ce8c7c84dde6db24828a01cea947a24713975f86d0769bf8fad5"><div class="ttname"><a href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828a01cea947a24713975f86d0769bf8fad5">arm_compute::ACL_SRC_2</a></div><div class="ttdeci">@ ACL_SRC_2</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00047">Types.h:47</a></div></div>
<div class="ttc" id="anamespacearm__compute_1_1test_1_1validation_xhtml_a1f8aca235c095df227e7444f6b237eb1"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#a1f8aca235c095df227e7444f6b237eb1">arm_compute::test::validation::act_info</a></div><div class="ttdeci">act_info</div><div class="ttdef"><b>Definition:</b> <a href="_c_l_2_direct_convolution_layer_8cpp_source.xhtml#l00547">DirectConvolutionLayer.cpp:547</a></div></div>
<div class="ttc" id="aarm__compute_2core_2_validate_8h_xhtml_a921b705e9e3e0fe928928447869e62a5"><div class="ttname"><a href="arm__compute_2core_2_validate_8h.xhtml#a921b705e9e3e0fe928928447869e62a5">ARM_COMPUTE_ERROR_ON_NULLPTR</a></div><div class="ttdeci">#define ARM_COMPUTE_ERROR_ON_NULLPTR(...)</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2_validate_8h_source.xhtml#l00157">Validate.h:157</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_a08e287b5f0197ce8c7c84dde6db24828a6f62ab7395c218e03e9d2942309c13a2"><div class="ttname"><a href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828a6f62ab7395c218e03e9d2942309c13a2">arm_compute::ACL_DST</a></div><div class="ttdeci">@ ACL_DST</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00055">Types.h:55</a></div></div>
<div class="ttc" id="anamespacearm__compute_1_1test_1_1validation_xhtml_a2270b3e1d20651d2d8341c858c890830"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#a2270b3e1d20651d2d8341c858c890830">arm_compute::test::validation::num_groups</a></div><div class="ttdeci">const unsigned int num_groups</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_o_n_2_im2_col_8cpp_source.xhtml#l00153">Im2Col.cpp:153</a></div></div>
<div class="ttc" id="anamespacearm__compute_1_1test_1_1validation_xhtml_a00525ff582f16038a1d3819aa44a23a3"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#a00525ff582f16038a1d3819aa44a23a3">arm_compute::test::validation::conv_info</a></div><div class="ttdeci">const auto conv_info</div><div class="ttdef"><b>Definition:</b> <a href="_c_l_2_convolution_layer_8cpp_source.xhtml#l00407">ConvolutionLayer.cpp:407</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_g_e_m_m_convolution_layer_xhtml_aa9b93ef660fc3c5b4b19d3fc7b891b77"><div class="ttname"><a href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml#aa9b93ef660fc3c5b4b19d3fc7b891b77">arm_compute::NEGEMMConvolutionLayer::prepare</a></div><div class="ttdeci">void prepare() override</div><div class="ttdoc">Prepare the function for executing.</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml#l00097">NEGEMMConvolutionLayer.cpp:97</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1cpu_1_1_cpu_gemm_conv2d_xhtml_ac762dddea5efe1c583eb3e6667126ddb"><div class="ttname"><a href="classarm__compute_1_1cpu_1_1_cpu_gemm_conv2d.xhtml#ac762dddea5efe1c583eb3e6667126ddb">arm_compute::cpu::CpuGemmConv2d::has_opt_impl</a></div><div class="ttdeci">static Status has_opt_impl(arm_compute::WeightFormat &amp;expected_weight_format, const ITensorInfo *src, const ITensorInfo *weights, const ITensorInfo *biases, const ITensorInfo *output, const PadStrideInfo &amp;conv_info, const WeightsInfo &amp;weights_info=WeightsInfo(), const Size2D &amp;dilation=Size2D(1U, 1U), const ActivationLayerInfo &amp;act_info=ActivationLayerInfo(), const bool enable_fast_math=false)</div><div class="ttdoc">Indicates whether or not there is an optimal assembly implementation that can be used to process the ...</div><div class="ttdef"><b>Definition:</b> <a href="_cpu_gemm_conv2d_8cpp_source.xhtml#l00398">CpuGemmConv2d.cpp:398</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1cpu_1_1_cpu_gemm_conv2d_xhtml_a6d4a3d570df9ced155edcbeef4cf865c"><div class="ttname"><a href="classarm__compute_1_1cpu_1_1_cpu_gemm_conv2d.xhtml#a6d4a3d570df9ced155edcbeef4cf865c">arm_compute::cpu::CpuGemmConv2d::validate</a></div><div class="ttdeci">static Status validate(const ITensorInfo *src, const ITensorInfo *weights, const ITensorInfo *biases, const ITensorInfo *output, const PadStrideInfo &amp;conv_info, const WeightsInfo &amp;weights_info=WeightsInfo(), const Size2D &amp;dilation=Size2D(1U, 1U), const ActivationLayerInfo &amp;act_info=ActivationLayerInfo(), bool enable_fast_math=false, unsigned int num_groups=1)</div><div class="ttdoc">Static function to check if given info will lead to a valid configuration.</div><div class="ttdef"><b>Definition:</b> <a href="_cpu_gemm_conv2d_8cpp_source.xhtml#l00430">CpuGemmConv2d.cpp:430</a></div></div>
<div class="ttc" id="anamespacearm__compute_1_1test_1_1validation_xhtml_a8fcf2ddd9a1d58b1b280f5c0aed71845"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">arm_compute::test::validation::input</a></div><div class="ttdeci">auto input</div><div class="ttdef"><b>Definition:</b> <a href="_c_l_2_l_s_t_m_layer_quantized_8cpp_source.xhtml#l00486">LSTMLayerQuantized.cpp:486</a></div></div>
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacearm__compute.xhtml">arm_compute</a></li><li class="navelem"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_convolution_layer.xhtml">NEGEMMConvolutionLayer</a></li>
    <li class="footer">Generated on Wed Jul 5 2023 11:29:26 for Compute Library by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.17 </li>
  </ul>
</div>
</body>
</html>
