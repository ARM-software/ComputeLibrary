<!-- HTML header for doxygen 1.8.15-->
<!-- Remember to use version doxygen 1.8.15 +-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.15"/>
<meta name="robots" content="NOINDEX, NOFOLLOW" /> <!-- Prevent indexing by search engines -->
<title>Compute Library: NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPoint Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async="async" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <img alt="Compute Library" src="https://raw.githubusercontent.com/ARM-software/ComputeLibrary/gh-pages/ACL_logo.png" style="max-width: 100%;margin-top: 15px;margin-left: 10px"/>
  <td style="padding-left: 0.5em;">
   <div id="projectname">
   &#160;<span id="projectnumber">19.02</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.15 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('classarm__compute_1_1_n_e_g_e_m_m_lowp_quantize_down_int32_to_uint8_scale_by_fixed_point.xhtml','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a>  </div>
  <div class="headertitle">
<div class="title">NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPoint Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Basic function to execute <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_quantize_down_int32_to_uint8_scale_by_fixed_point.xhtml" title="Basic function to execute NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPoint on NEON.">NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPoint</a> on NEON.  
 <a href="classarm__compute_1_1_n_e_g_e_m_m_lowp_quantize_down_int32_to_uint8_scale_by_fixed_point.xhtml#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_n_e_g_e_m_m_lowp_output_stage_8h_source.xhtml">NEGEMMLowpOutputStage.h</a>&gt;</code></p>
<div class="dynheader">
Collaboration diagram for NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPoint:</div>
<div class="dyncontent">
<div class="center"><iframe scrolling="no" frameborder="0" src="classarm__compute_1_1_n_e_g_e_m_m_lowp_quantize_down_int32_to_uint8_scale_by_fixed_point__coll__graph.svg" width="247" height="202"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe>
</div>
<center><span class="legend">[<a target="top" href="graph_legend.xhtml">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a888c69fe3d880ac8001eb92ab74cffb7"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_quantize_down_int32_to_uint8_scale_by_fixed_point.xhtml#a888c69fe3d880ac8001eb92ab74cffb7">configure</a> (const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *input, const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *bias, <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *output, int result_fixedpoint_multiplier, int result_shift, int result_offset_after_shift, int min=0, int max=0)</td></tr>
<tr class="memdesc:a888c69fe3d880ac8001eb92ab74cffb7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initialise the kernel's inputs, output.  <a href="#a888c69fe3d880ac8001eb92ab74cffb7">More...</a><br /></td></tr>
<tr class="separator:a888c69fe3d880ac8001eb92ab74cffb7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classarm__compute_1_1_i_n_e_simple_function_no_border"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classarm__compute_1_1_i_n_e_simple_function_no_border')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classarm__compute_1_1_i_n_e_simple_function_no_border.xhtml">INESimpleFunctionNoBorder</a></td></tr>
<tr class="memitem:a0e0883eaf5a047ad7a5eb791dfe3a7f5 inherit pub_methods_classarm__compute_1_1_i_n_e_simple_function_no_border"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_n_e_simple_function_no_border.xhtml#a0e0883eaf5a047ad7a5eb791dfe3a7f5">INESimpleFunctionNoBorder</a> ()</td></tr>
<tr class="memdesc:a0e0883eaf5a047ad7a5eb791dfe3a7f5 inherit pub_methods_classarm__compute_1_1_i_n_e_simple_function_no_border"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor.  <a href="classarm__compute_1_1_i_n_e_simple_function_no_border.xhtml#a0e0883eaf5a047ad7a5eb791dfe3a7f5">More...</a><br /></td></tr>
<tr class="separator:a0e0883eaf5a047ad7a5eb791dfe3a7f5 inherit pub_methods_classarm__compute_1_1_i_n_e_simple_function_no_border"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92fe532c342ae2b07956a65520c05362 inherit pub_methods_classarm__compute_1_1_i_n_e_simple_function_no_border"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_n_e_simple_function_no_border.xhtml#a92fe532c342ae2b07956a65520c05362">run</a> () override final</td></tr>
<tr class="memdesc:a92fe532c342ae2b07956a65520c05362 inherit pub_methods_classarm__compute_1_1_i_n_e_simple_function_no_border"><td class="mdescLeft">&#160;</td><td class="mdescRight">Run the kernels contained in the function.  <a href="classarm__compute_1_1_i_n_e_simple_function_no_border.xhtml#a92fe532c342ae2b07956a65520c05362">More...</a><br /></td></tr>
<tr class="separator:a92fe532c342ae2b07956a65520c05362 inherit pub_methods_classarm__compute_1_1_i_n_e_simple_function_no_border"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classarm__compute_1_1_i_function"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classarm__compute_1_1_i_function')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classarm__compute_1_1_i_function.xhtml">IFunction</a></td></tr>
<tr class="memitem:ab921ecc3f3f6ae2b4bd61f3e1998d8c4 inherit pub_methods_classarm__compute_1_1_i_function"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_function.xhtml#ab921ecc3f3f6ae2b4bd61f3e1998d8c4">~IFunction</a> ()=default</td></tr>
<tr class="memdesc:ab921ecc3f3f6ae2b4bd61f3e1998d8c4 inherit pub_methods_classarm__compute_1_1_i_function"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destructor.  <a href="classarm__compute_1_1_i_function.xhtml#ab921ecc3f3f6ae2b4bd61f3e1998d8c4">More...</a><br /></td></tr>
<tr class="separator:ab921ecc3f3f6ae2b4bd61f3e1998d8c4 inherit pub_methods_classarm__compute_1_1_i_function"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a820f7291c24155a2980512fae45aac26 inherit pub_methods_classarm__compute_1_1_i_function"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_function.xhtml#a820f7291c24155a2980512fae45aac26">prepare</a> ()</td></tr>
<tr class="memdesc:a820f7291c24155a2980512fae45aac26 inherit pub_methods_classarm__compute_1_1_i_function"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prepare the function for executing.  <a href="classarm__compute_1_1_i_function.xhtml#a820f7291c24155a2980512fae45aac26">More...</a><br /></td></tr>
<tr class="separator:a820f7291c24155a2980512fae45aac26 inherit pub_methods_classarm__compute_1_1_i_function"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:aee63e7671cf04d15be2da1b83d90e61b"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="classarm__compute_1_1_status.xhtml">Status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_quantize_down_int32_to_uint8_scale_by_fixed_point.xhtml#aee63e7671cf04d15be2da1b83d90e61b">validate</a> (const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *input, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *bias, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *output, int min=0, int max=0)</td></tr>
<tr class="memdesc:aee63e7671cf04d15be2da1b83d90e61b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Static function to check if given info will lead to a valid configuration of <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_quantize_down_int32_to_uint8_scale_by_fixed_point.xhtml">NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPoint</a>.  <a href="#aee63e7671cf04d15be2da1b83d90e61b">More...</a><br /></td></tr>
<tr class="separator:aee63e7671cf04d15be2da1b83d90e61b"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Basic function to execute <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_quantize_down_int32_to_uint8_scale_by_fixed_point.xhtml" title="Basic function to execute NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPoint on NEON.">NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPoint</a> on NEON. </p>
<p><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_quantize_down_int32_to_uint8_scale_by_fixed_point.xhtml" title="Basic function to execute NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPoint on NEON.">NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPoint</a> depends on 3 parameters:</p>
<p>result_fixedpoint_multiplier, result_shift, result_offset_after_shift</p>
<p>The final result is:</p>
<p>(FixedPointMul(input[i][k], result_fixedpoint_multiplier) &gt;&gt; result_shift) + result_offset_after_shift</p>
<p>where FixedPointMul(x, y) is the nearest integer to the following mathematical expression, evaluated without overflow or intermediate rounding:</p>
<p>(x * y) / 2^31</p>
<p>For more information: <a href="https://github.com/google/gemmlowp/blob/master/public/output_stages.h#L68">https://github.com/google/gemmlowp/blob/master/public/output_stages.h#L68</a></p>
<p>In case the bias tensor is provided, the final result is:</p>
<p>((FixedPointMul(input[i][k] + bias[k], result_fixedpoint_multiplier)) &gt;&gt; result_shift) + result_offset_after_shift</p>
<p>This function calls the following NEON kernels:</p>
<ol type="1">
<li><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_quantize_down_int32_to_uint8_scale_by_fixed_point_kernel.xhtml">NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPointKernel</a></li>
</ol>
<dl class="section note"><dt>Note</dt><dd>The function accepts also 2 optional input arguments (min and max) which can be used to implement "rectified linear unit" activation functions after the result is shifted right by result_shift </dd></dl>

<p class="definition">Definition at line <a class="el" href="_n_e_g_e_m_m_lowp_output_stage_8h_source.xhtml#l00119">119</a> of file <a class="el" href="_n_e_g_e_m_m_lowp_output_stage_8h_source.xhtml">NEGEMMLowpOutputStage.h</a>.</p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a888c69fe3d880ac8001eb92ab74cffb7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a888c69fe3d880ac8001eb92ab74cffb7">&#9670;&nbsp;</a></span>configure()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void configure </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>result_fixedpoint_multiplier</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>result_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>result_offset_after_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>min</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>max</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Initialise the kernel's inputs, output. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">input</td><td>Input tensor. Data type supported: S32 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>Biases tensor. Only shared biases supported and it can be a nullptr if the biases addition is not required. Biases are 1D tensor with dimensions [OFM]. Data type supported: Same as <code>input</code>. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output</td><td>Output tensor. Data type supported: Data type supported: QASYMM8 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">result_fixedpoint_multiplier</td><td>Fixed point value to be multiplied to each element of the input matrix when once the result_offset has been add </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">result_shift</td><td>Number of bits to shift right the result after the fixed point multiplication </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">result_offset_after_shift</td><td>Offset to be applied to result before converting it back to QASYMM8 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">min</td><td>(Optional) Min value used to saturate down the output result before converting back to QASYMM8 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">max</td><td>(Optional) Max value used to saturate up the output result before converting back to QASYMM8, Along with <code>min</code>, this value can be used to implement "rectified linear unit" activation functions </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="_n_e_g_e_m_m_lowp_output_stage_8cpp_source.xhtml#l00045">45</a> of file <a class="el" href="_n_e_g_e_m_m_lowp_output_stage_8cpp_source.xhtml">NEGEMMLowpOutputStage.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;{</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;    <span class="keyword">auto</span> k = arm_compute::support::cpp14::make_unique&lt;NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPointKernel&gt;();</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;    k-&gt;configure(input, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a3a77be8aebd8e00522b32061d46ccdbd">bias</a>, output, result_fixedpoint_multiplier, result_shift, result_offset_after_shift, min, max);</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;    _kernel = std::move(k);</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;}</div><div class="ttc" id="namespacearm__compute_1_1test_1_1validation_xhtml_a3a77be8aebd8e00522b32061d46ccdbd"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#a3a77be8aebd8e00522b32061d46ccdbd">arm_compute::test::validation::bias</a></div><div class="ttdeci">CLTensor bias</div><div class="ttdef"><b>Definition:</b> <a href="validation_2_c_l_2_convolution_layer_8cpp_source.xhtml#l00181">ConvolutionLayer.cpp:181</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="validation_2_c_l_2_convolution_layer_8cpp_source.xhtml#l00181">arm_compute::test::validation::bias</a>.</p>

<p class="reference">Referenced by <a class="el" href="_n_e_fully_connected_layer_8cpp_source.xhtml#l00139">NEFullyConnectedLayer::configure()</a>, and <a class="el" href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml#l00173">NEGEMMConvolutionLayer::configure()</a>.</p>

</div>
</div>
<a id="aee63e7671cf04d15be2da1b83d90e61b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee63e7671cf04d15be2da1b83d90e61b">&#9670;&nbsp;</a></span>validate()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_status.xhtml">Status</a> validate </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>min</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>max</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Static function to check if given info will lead to a valid configuration of <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_quantize_down_int32_to_uint8_scale_by_fixed_point.xhtml">NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPoint</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">input</td><td>Input tensor. It is the output of <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_matrix_multiply_core.xhtml">NEGEMMLowpMatrixMultiplyCore</a> function. Data type supported: S32 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>Biases tensor. Only shared biases supported and it can be a nullptr if the addition of biases is not required. Biases are 1D tensor with dimensions [OFM]. Data type supported: Same as <code>input</code>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">output</td><td>Output tensor. Data type supported: Data type supported: QASYMM8 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">min</td><td>(Optional) Min value used to saturate down the output result before converting back to QASYMM8 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">max</td><td>(Optional) Max value used to saturate up the output result before converting back to QASYMM8, Along with <code>min</code>, this value can be used to implement "rectified linear unit" activation functions</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a status </dd></dl>

<p class="definition">Definition at line <a class="el" href="_n_e_g_e_m_m_lowp_output_stage_8cpp_source.xhtml#l00053">53</a> of file <a class="el" href="_n_e_g_e_m_m_lowp_output_stage_8cpp_source.xhtml">NEGEMMLowpOutputStage.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;{</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_quantize_down_int32_to_uint8_scale_by_fixed_point_kernel.xhtml#aee63e7671cf04d15be2da1b83d90e61b">NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPointKernel::validate</a>(input, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a3a77be8aebd8e00522b32061d46ccdbd">bias</a>, output, min, max);</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;}</div><div class="ttc" id="classarm__compute_1_1_n_e_g_e_m_m_lowp_quantize_down_int32_to_uint8_scale_by_fixed_point_kernel_xhtml_aee63e7671cf04d15be2da1b83d90e61b"><div class="ttname"><a href="classarm__compute_1_1_n_e_g_e_m_m_lowp_quantize_down_int32_to_uint8_scale_by_fixed_point_kernel.xhtml#aee63e7671cf04d15be2da1b83d90e61b">arm_compute::NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPointKernel::validate</a></div><div class="ttdeci">static Status validate(const ITensorInfo *input, const ITensorInfo *bias, const ITensorInfo *output, int min=0, int max=0)</div><div class="ttdoc">Static function to check if given info will lead to a valid configuration of NEGEMMLowpQuantizeDownIn...</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_g_e_m_m_lowp_quantize_down_int32_to_uint8_scale_by_fixed_point_kernel_8cpp_source.xhtml#l00264">NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPointKernel.cpp:264</a></div></div>
<div class="ttc" id="namespacearm__compute_1_1test_1_1validation_xhtml_a3a77be8aebd8e00522b32061d46ccdbd"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#a3a77be8aebd8e00522b32061d46ccdbd">arm_compute::test::validation::bias</a></div><div class="ttdeci">CLTensor bias</div><div class="ttdef"><b>Definition:</b> <a href="validation_2_c_l_2_convolution_layer_8cpp_source.xhtml#l00181">ConvolutionLayer.cpp:181</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="validation_2_c_l_2_convolution_layer_8cpp_source.xhtml#l00181">arm_compute::test::validation::bias</a>, and <a class="el" href="_n_e_g_e_m_m_lowp_quantize_down_int32_to_uint8_scale_by_fixed_point_kernel_8cpp_source.xhtml#l00264">NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPointKernel::validate()</a>.</p>

<p class="reference">Referenced by <a class="el" href="_n_e_fully_connected_layer_8cpp_source.xhtml#l00240">NEFullyConnectedLayer::validate()</a>, and <a class="el" href="_n_e_g_e_m_m_convolution_layer_8cpp_source.xhtml#l00377">NEGEMMConvolutionLayer::validate()</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>arm_compute/runtime/NEON/functions/<a class="el" href="_n_e_g_e_m_m_lowp_output_stage_8h_source.xhtml">NEGEMMLowpOutputStage.h</a></li>
<li>src/runtime/NEON/functions/<a class="el" href="_n_e_g_e_m_m_lowp_output_stage_8cpp_source.xhtml">NEGEMMLowpOutputStage.cpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacearm__compute.xhtml">arm_compute</a></li><li class="navelem"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_quantize_down_int32_to_uint8_scale_by_fixed_point.xhtml">NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPoint</a></li>
    <li class="footer">Generated on Thu Feb 28 2019 12:25:03 for Compute Library by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.15 </li>
  </ul>
</div>
</body>
</html>
