<!-- HTML header for doxygen 1.8.15-->
<!-- Remember to use version doxygen 1.8.15 +-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="robots" content="NOINDEX, NOFOLLOW" /> <!-- Prevent indexing by search engines -->
<title>Compute Library: CpuGemmLowpOffsetContributionOutputStageKernel Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <img alt="Compute Library" src="https://raw.githubusercontent.com/ARM-software/ComputeLibrary/gh-pages/ACL_logo.png" style="max-width: 100%;margin-top: 15px;margin-left: 10px"/>
  <td style="padding-left: 0.5em;">
   <div id="projectname">
   &#160;<span id="projectnumber">23.08</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a>  </div>
  <div class="headertitle">
<div class="title">CpuGemmLowpOffsetContributionOutputStageKernel Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p><a class="el" href="classarm__compute_1_1_kernel.xhtml" title="Kernel class.">Kernel</a> used to add the offset contribution and perform the output stage after <a class="el" href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_matrix_multiply_kernel.xhtml">CpuGemmLowpMatrixMultiplyKernel</a>.  
 <a href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_cpu_gemm_lowp_offset_contribution_output_stage_kernel_8h_source.xhtml">CpuGemmLowpOffsetContributionOutputStageKernel.h</a>&gt;</code></p>
<div class="dynheader">
Collaboration diagram for CpuGemmLowpOffsetContributionOutputStageKernel:</div>
<div class="dyncontent">
<div class="center"><iframe scrolling="no" frameborder="0" src="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel__coll__graph.svg" width="443" height="399"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe>
</div>
<center><span class="legend">[<a target="top" href="graph_legend.xhtml">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a2175504d49a6b1c0bd1b0c71e9beb611"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml#a2175504d49a6b1c0bd1b0c71e9beb611">CpuGemmLowpOffsetContributionOutputStageKernel</a> ()=default</td></tr>
<tr class="memdesc:a2175504d49a6b1c0bd1b0c71e9beb611"><td class="mdescLeft">&#160;</td><td class="mdescRight">Default constructor.  <a href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml#a2175504d49a6b1c0bd1b0c71e9beb611">More...</a><br /></td></tr>
<tr class="separator:a2175504d49a6b1c0bd1b0c71e9beb611"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a256480fd1cda77ab674176246be70c90"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml#a256480fd1cda77ab674176246be70c90">ARM_COMPUTE_DISALLOW_COPY_ALLOW_MOVE</a> (<a class="el" href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml">CpuGemmLowpOffsetContributionOutputStageKernel</a>)</td></tr>
<tr class="separator:a256480fd1cda77ab674176246be70c90"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ac9415f2263fd8faf18482908122b61"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml#a5ac9415f2263fd8faf18482908122b61">configure</a> (const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *mm_result, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *vector_sum_col, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *vector_sum_row, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *<a class="el" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>, <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *dst, int32_t k, int32_t a_offset, int32_t b_offset, <a class="el" href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml">GEMMLowpOutputStageInfo</a> <a class="el" href="working__space_8hpp.xhtml#aa2b9b52a4827eeb41f97f92a3781eee8">output_stage</a>)</td></tr>
<tr class="memdesc:a5ac9415f2263fd8faf18482908122b61"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initialise the kernel inputs and output.  <a href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml#a5ac9415f2263fd8faf18482908122b61">More...</a><br /></td></tr>
<tr class="separator:a5ac9415f2263fd8faf18482908122b61"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a883429dd6cf828bfdd64b255afc458da"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml#a883429dd6cf828bfdd64b255afc458da">run_op</a> (<a class="el" href="classarm__compute_1_1_i_tensor_pack.xhtml">ITensorPack</a> &amp;tensors, const <a class="el" href="classarm__compute_1_1_window.xhtml">Window</a> &amp;<a class="el" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">window</a>, const <a class="el" href="structarm__compute_1_1_thread_info.xhtml">ThreadInfo</a> &amp;info) override</td></tr>
<tr class="memdesc:a883429dd6cf828bfdd64b255afc458da"><td class="mdescLeft">&#160;</td><td class="mdescRight">Execute the kernel on the passed window.  <a href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml#a883429dd6cf828bfdd64b255afc458da">More...</a><br /></td></tr>
<tr class="separator:a883429dd6cf828bfdd64b255afc458da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef1a10d4d6422ca58d53d8414d5954bd"><td class="memItemLeft" align="right" valign="top">const char *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml#aef1a10d4d6422ca58d53d8414d5954bd">name</a> () const override</td></tr>
<tr class="memdesc:aef1a10d4d6422ca58d53d8414d5954bd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Name of the kernel.  <a href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml#aef1a10d4d6422ca58d53d8414d5954bd">More...</a><br /></td></tr>
<tr class="separator:aef1a10d4d6422ca58d53d8414d5954bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classarm__compute_1_1_i_c_p_p_kernel')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classarm__compute_1_1_i_c_p_p_kernel.xhtml">ICPPKernel</a></td></tr>
<tr class="memitem:a033d17a97e07cea7fe83eefcf23540f6 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#a033d17a97e07cea7fe83eefcf23540f6">~ICPPKernel</a> ()=default</td></tr>
<tr class="memdesc:a033d17a97e07cea7fe83eefcf23540f6 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">Default destructor.  <a href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#a033d17a97e07cea7fe83eefcf23540f6">More...</a><br /></td></tr>
<tr class="separator:a033d17a97e07cea7fe83eefcf23540f6 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6586f7a2dd64942f59b8c408643a0ea inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#ad6586f7a2dd64942f59b8c408643a0ea">run</a> (const <a class="el" href="classarm__compute_1_1_window.xhtml">Window</a> &amp;<a class="el" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">window</a>, const <a class="el" href="structarm__compute_1_1_thread_info.xhtml">ThreadInfo</a> &amp;info)</td></tr>
<tr class="memdesc:ad6586f7a2dd64942f59b8c408643a0ea inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">Execute the kernel on the passed window.  <a href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#ad6586f7a2dd64942f59b8c408643a0ea">More...</a><br /></td></tr>
<tr class="separator:ad6586f7a2dd64942f59b8c408643a0ea inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92fc66203d7affe26cbe70194a154895 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#a92fc66203d7affe26cbe70194a154895">run_nd</a> (const <a class="el" href="classarm__compute_1_1_window.xhtml">Window</a> &amp;<a class="el" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">window</a>, const <a class="el" href="structarm__compute_1_1_thread_info.xhtml">ThreadInfo</a> &amp;info, const <a class="el" href="classarm__compute_1_1_window.xhtml">Window</a> &amp;thread_locator)</td></tr>
<tr class="memdesc:a92fc66203d7affe26cbe70194a154895 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">legacy compatibility layer for implemantions which do not support thread_locator In these cases we simply narrow the interface down the legacy version  <a href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#a92fc66203d7affe26cbe70194a154895">More...</a><br /></td></tr>
<tr class="separator:a92fc66203d7affe26cbe70194a154895 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3aa853ba2ae719bcb7ed1ccbe3c33286 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="memItemLeft" align="right" valign="top">virtual size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#a3aa853ba2ae719bcb7ed1ccbe3c33286">get_mws</a> (const <a class="el" href="classarm__compute_1_1_c_p_u_info.xhtml">CPUInfo</a> &amp;platform, size_t thread_count) const</td></tr>
<tr class="memdesc:a3aa853ba2ae719bcb7ed1ccbe3c33286 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return minimum workload size of the relevant kernel.  <a href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#a3aa853ba2ae719bcb7ed1ccbe3c33286">More...</a><br /></td></tr>
<tr class="separator:a3aa853ba2ae719bcb7ed1ccbe3c33286 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classarm__compute_1_1_i_kernel"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classarm__compute_1_1_i_kernel')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classarm__compute_1_1_i_kernel.xhtml">IKernel</a></td></tr>
<tr class="memitem:a7250cb8cbaa4104a93a2d77155085507 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_kernel.xhtml#a7250cb8cbaa4104a93a2d77155085507">IKernel</a> ()</td></tr>
<tr class="memdesc:a7250cb8cbaa4104a93a2d77155085507 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor.  <a href="classarm__compute_1_1_i_kernel.xhtml#a7250cb8cbaa4104a93a2d77155085507">More...</a><br /></td></tr>
<tr class="separator:a7250cb8cbaa4104a93a2d77155085507 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a341b60d15a5e12a5b8f3825194dd3b12 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_kernel.xhtml#a341b60d15a5e12a5b8f3825194dd3b12">~IKernel</a> ()=default</td></tr>
<tr class="memdesc:a341b60d15a5e12a5b8f3825194dd3b12 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destructor.  <a href="classarm__compute_1_1_i_kernel.xhtml#a341b60d15a5e12a5b8f3825194dd3b12">More...</a><br /></td></tr>
<tr class="separator:a341b60d15a5e12a5b8f3825194dd3b12 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0466ee6ce6552c87595f0e88e73eeb1b inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_kernel.xhtml#a0466ee6ce6552c87595f0e88e73eeb1b">is_parallelisable</a> () const</td></tr>
<tr class="memdesc:a0466ee6ce6552c87595f0e88e73eeb1b inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">Indicates whether or not the kernel is parallelisable.  <a href="classarm__compute_1_1_i_kernel.xhtml#a0466ee6ce6552c87595f0e88e73eeb1b">More...</a><br /></td></tr>
<tr class="separator:a0466ee6ce6552c87595f0e88e73eeb1b inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4b3a97ba5dded504a2f2261c078493dd inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="structarm__compute_1_1_border_size.xhtml">BorderSize</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_kernel.xhtml#a4b3a97ba5dded504a2f2261c078493dd">border_size</a> () const</td></tr>
<tr class="memdesc:a4b3a97ba5dded504a2f2261c078493dd inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">The size of the border for that kernel.  <a href="classarm__compute_1_1_i_kernel.xhtml#a4b3a97ba5dded504a2f2261c078493dd">More...</a><br /></td></tr>
<tr class="separator:a4b3a97ba5dded504a2f2261c078493dd inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad34a46f53686c12a5c5e717cc9617fb6 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classarm__compute_1_1_window.xhtml">Window</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">window</a> () const</td></tr>
<tr class="memdesc:ad34a46f53686c12a5c5e717cc9617fb6 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">The maximum window the kernel can be executed on.  <a href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">More...</a><br /></td></tr>
<tr class="separator:ad34a46f53686c12a5c5e717cc9617fb6 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32ab3ad0302912c7da52204042727a44 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_kernel.xhtml#a32ab3ad0302912c7da52204042727a44">is_window_configured</a> () const</td></tr>
<tr class="memdesc:a32ab3ad0302912c7da52204042727a44 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function to check if the embedded window of this kernel has been configured.  <a href="classarm__compute_1_1_i_kernel.xhtml#a32ab3ad0302912c7da52204042727a44">More...</a><br /></td></tr>
<tr class="separator:a32ab3ad0302912c7da52204042727a44 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:af476aae8f71beb1507ae5edf879fb4db"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="classarm__compute_1_1_status.xhtml">Status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml#af476aae8f71beb1507ae5edf879fb4db">validate</a> (const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *mm_result, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *vector_sum_col, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *vector_sum_row, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *<a class="el" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *dst, int32_t a_offset, int32_t b_offset, <a class="el" href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml">GEMMLowpOutputStageInfo</a> <a class="el" href="working__space_8hpp.xhtml#aa2b9b52a4827eeb41f97f92a3781eee8">output_stage</a>)</td></tr>
<tr class="memdesc:af476aae8f71beb1507ae5edf879fb4db"><td class="mdescLeft">&#160;</td><td class="mdescRight">Static function to check if given info will lead to a valid configuration.  <a href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml#af476aae8f71beb1507ae5edf879fb4db">More...</a><br /></td></tr>
<tr class="separator:af476aae8f71beb1507ae5edf879fb4db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_static_methods_classarm__compute_1_1cpu_1_1_i_cpu_kernel"><td colspan="2" onclick="javascript:toggleInherit('pub_static_methods_classarm__compute_1_1cpu_1_1_i_cpu_kernel')"><img src="closed.png" alt="-"/>&#160;Static Public Member Functions inherited from <a class="el" href="classarm__compute_1_1cpu_1_1_i_cpu_kernel.xhtml">ICpuKernel&lt; CpuGemmLowpOffsetContributionOutputStageKernel &gt;</a></td></tr>
<tr class="memitem:a1c57e942b23eab1974697c3378bee0d8 inherit pub_static_methods_classarm__compute_1_1cpu_1_1_i_cpu_kernel"><td class="memItemLeft" align="right" valign="top">static const auto *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1cpu_1_1_i_cpu_kernel.xhtml#a1c57e942b23eab1974697c3378bee0d8">get_implementation</a> (const SelectorType &amp;selector, <a class="el" href="namespacearm__compute_1_1cpu.xhtml#afa3ebf7e0ea95c0c9cadb30c62bad67a">KernelSelectionType</a> selection_type=KernelSelectionType::Supported)</td></tr>
<tr class="memdesc:a1c57e942b23eab1974697c3378bee0d8 inherit pub_static_methods_classarm__compute_1_1cpu_1_1_i_cpu_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">Micro-kernel selector.  <a href="classarm__compute_1_1cpu_1_1_i_cpu_kernel.xhtml#a1c57e942b23eab1974697c3378bee0d8">More...</a><br /></td></tr>
<tr class="separator:a1c57e942b23eab1974697c3378bee0d8 inherit pub_static_methods_classarm__compute_1_1cpu_1_1_i_cpu_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="inherited"></a>
Additional Inherited Members</h2></td></tr>
<tr class="inherit_header pub_static_attribs_classarm__compute_1_1_i_c_p_p_kernel"><td colspan="2" onclick="javascript:toggleInherit('pub_static_attribs_classarm__compute_1_1_i_c_p_p_kernel')"><img src="closed.png" alt="-"/>&#160;Static Public Attributes inherited from <a class="el" href="classarm__compute_1_1_i_c_p_p_kernel.xhtml">ICPPKernel</a></td></tr>
<tr class="memitem:ad6dda2ca87714e265e1521607c2fa7d0 inherit pub_static_attribs_classarm__compute_1_1_i_c_p_p_kernel"><td class="memItemLeft" align="right" valign="top">static constexpr size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#ad6dda2ca87714e265e1521607c2fa7d0">default_mws</a> = 1</td></tr>
<tr class="separator:ad6dda2ca87714e265e1521607c2fa7d0 inherit pub_static_attribs_classarm__compute_1_1_i_c_p_p_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p><a class="el" href="classarm__compute_1_1_kernel.xhtml" title="Kernel class.">Kernel</a> used to add the offset contribution and perform the output stage after <a class="el" href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_matrix_multiply_kernel.xhtml">CpuGemmLowpMatrixMultiplyKernel</a>. </p>
<p>The computation is performed in-place</p>
<p>This kernel takes a final int32 accumulator value (the output of <a class="el" href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_matrix_multiply_kernel.xhtml">CpuGemmLowpMatrixMultiplyKernel</a>), and adds to it the offset contribution of matrix A and matrix B in-place.</p>
<p>The output stage can perform either QuantizeDownInt32ToUint8Scale or QuantizeDownInt32ToUint8ScaleByFixedPoint for Uint8. The output stage can perform either QuantizeDownInt32ToInt8Scale or QuantizeDownInt32ToInt8ScaleByFixedPoint for Int8.</p>
<p>For QuantizeDownInt32ToUint8Scale/QuantizeDownInt32ToInt8Scale the final result is:</p>
<p>((mm_result'[i][k] + result_offset) * result_mult_int) &gt;&gt; result_shift</p>
<p>For QuantizeDownInt32ToUint8ScaleByFixedPoint/QuantizeDownInt32ToInt8ScaleByFixedPoint the final result is:</p>
<p>(FixedPointMul(mm_result'[i][k], result_fixedpoint_multiplier) &gt;&gt; result_shift) + result_offset_after_shift</p>
<p>where FixedPointMul(x, y) is the nearest integer to the following mathematical expression, evaluated without overflow or intermediate rounding:</p>
<p>(x * y) / 2^31</p>
<p>and mm_result'[i][k] = mm_result[i][k] + (vector_sum_col[k] * a_offset) + (vector_sum_row[i] * b_offset) + (a_offset * b_offset * k) </p>

<p class="definition">Definition at line <a class="el" href="_cpu_gemm_lowp_offset_contribution_output_stage_kernel_8h_source.xhtml#l00066">66</a> of file <a class="el" href="_cpu_gemm_lowp_offset_contribution_output_stage_kernel_8h_source.xhtml">CpuGemmLowpOffsetContributionOutputStageKernel.h</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a2175504d49a6b1c0bd1b0c71e9beb611"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2175504d49a6b1c0bd1b0c71e9beb611">&#9670;&nbsp;</a></span>CpuGemmLowpOffsetContributionOutputStageKernel()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml">CpuGemmLowpOffsetContributionOutputStageKernel</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">default</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Default constructor. </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a256480fd1cda77ab674176246be70c90"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a256480fd1cda77ab674176246be70c90">&#9670;&nbsp;</a></span>ARM_COMPUTE_DISALLOW_COPY_ALLOW_MOVE()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">ARM_COMPUTE_DISALLOW_COPY_ALLOW_MOVE </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml">CpuGemmLowpOffsetContributionOutputStageKernel</a>&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5ac9415f2263fd8faf18482908122b61"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5ac9415f2263fd8faf18482908122b61">&#9670;&nbsp;</a></span>configure()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void configure </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>mm_result</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>vector_sum_col</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>vector_sum_row</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>dst</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>k</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>a_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>b_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml">GEMMLowpOutputStageInfo</a>&#160;</td>
          <td class="paramname"><em>output_stage</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Initialise the kernel inputs and output. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">mm_result</td><td>Input tensor info containing the result of <a class="el" href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_matrix_multiply_kernel.xhtml">CpuGemmLowpMatrixMultiplyKernel</a>. Data type supported: S32 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">vector_sum_col</td><td>Input row-vector tensor info of sums of all the entries in each column of matrix B. Can be a 1D or 2D tensor, in case of 2D, y dim is the batch dimension Note: vector_sum_col can be a nullptr in case a_offset = 0. Data type supported: same as <code>mm_result</code> </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">vector_sum_row</td><td>Input row-vector tensor info of sums of all the entries in each row of matrix A. Can be a 1D or 2D tensor, in case of 2D, y dim is the batch dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>Biases tensor info. Only shared biases supported and it can be a nullptr if the addition of biases is not required. Biases are 1D tensor with dimensions [OFM]. Data type supported: Same as <code>mm_result</code>. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">dst</td><td>Output tensor info containing the final quantized result. Data type supported: QASYMM8/QASYMM8_SIGNED </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">k</td><td>Number of matrix A columns or Matrix B rows </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">a_offset</td><td>Offset to be added to each element of the matrix A. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">b_offset</td><td>Offset to be added to each element of the matrix B. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">output_stage</td><td>GEMMLowp output stage info, providing the type of quantization and the necessary parameters. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="_cpu_gemm_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml#l00855">855</a> of file <a class="el" href="_cpu_gemm_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml">CpuGemmLowpOffsetContributionOutputStageKernel.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00859"></a><span class="lineno">  859</span>&#160;{</div>
<div class="line"><a name="l00860"></a><span class="lineno">  860</span>&#160;    <a class="code" href="_error_8h.xhtml#a6dc630a6ae9cc063b3924bcea8dee9d6">ARM_COMPUTE_UNUSED</a>(vector_sum_row, <a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>);</div>
<div class="line"><a name="l00861"></a><span class="lineno">  861</span>&#160;    <span class="comment">// Perform validate step</span></div>
<div class="line"><a name="l00862"></a><span class="lineno">  862</span>&#160;    <a class="code" href="arm__compute_2core_2_validate_8h.xhtml#a921b705e9e3e0fe928928447869e62a5">ARM_COMPUTE_ERROR_ON_NULLPTR</a>(mm_result, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#adbf67dcee294e673cf796f1ed8aeb6a4">dst</a>);</div>
<div class="line"><a name="l00863"></a><span class="lineno">  863</span>&#160;    <a class="code" href="_error_8h.xhtml#a938dcd406ce611ef5345ad2531cdb948">ARM_COMPUTE_ERROR_THROW_ON</a>(<a class="code" href="namespacearm__compute_1_1cpu_1_1kernels.xhtml#acf9ea6633274730cd08b8b8fab3a6fe6">validate_arguments</a>(mm_result, vector_sum_col, vector_sum_row, <a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#adbf67dcee294e673cf796f1ed8aeb6a4">dst</a>, a_offset, b_offset, <a class="code" href="working__space_8hpp.xhtml#aa2b9b52a4827eeb41f97f92a3781eee8">output_stage</a>));</div>
<div class="line"><a name="l00864"></a><span class="lineno">  864</span>&#160; </div>
<div class="line"><a name="l00865"></a><span class="lineno">  865</span>&#160;    _a_offset     = a_offset;</div>
<div class="line"><a name="l00866"></a><span class="lineno">  866</span>&#160;    _b_offset     = b_offset;</div>
<div class="line"><a name="l00867"></a><span class="lineno">  867</span>&#160;    _k_offset     = a_offset * b_offset * <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a73aa59d7b088082ec257a1c65edbf1d0">k</a>;</div>
<div class="line"><a name="l00868"></a><span class="lineno">  868</span>&#160;    _output_stage = <a class="code" href="working__space_8hpp.xhtml#aa2b9b52a4827eeb41f97f92a3781eee8">output_stage</a>;</div>
<div class="line"><a name="l00869"></a><span class="lineno">  869</span>&#160; </div>
<div class="line"><a name="l00870"></a><span class="lineno">  870</span>&#160;    <span class="comment">// If a_offset == 0, vector_sum_col can be a nullptr</span></div>
<div class="line"><a name="l00871"></a><span class="lineno">  871</span>&#160;    <span class="keywordflow">if</span>(a_offset != 0)</div>
<div class="line"><a name="l00872"></a><span class="lineno">  872</span>&#160;    {</div>
<div class="line"><a name="l00873"></a><span class="lineno">  873</span>&#160;        <span class="comment">// Check if vector_sum_col_shape should be slidden or not</span></div>
<div class="line"><a name="l00874"></a><span class="lineno">  874</span>&#160;        <span class="comment">// Don&#39;t slide vector_sum_col_shape along the y dimension if vector_sum_col_shape has just 1 dimension and vector_sum_row_shape more than 1</span></div>
<div class="line"><a name="l00875"></a><span class="lineno">  875</span>&#160;        <span class="comment">// This scenario can happen when the the matrix multiplication is used to perform a convolution operation</span></div>
<div class="line"><a name="l00876"></a><span class="lineno">  876</span>&#160;        _is_vector_sum_col_batched = vector_sum_col-&gt;tensor_shape().num_dimensions() &gt; 1;</div>
<div class="line"><a name="l00877"></a><span class="lineno">  877</span>&#160;    }</div>
<div class="line"><a name="l00878"></a><span class="lineno">  878</span>&#160; </div>
<div class="line"><a name="l00879"></a><span class="lineno">  879</span>&#160;    <span class="comment">// Output auto inizialitation if not yet initialized</span></div>
<div class="line"><a name="l00880"></a><span class="lineno">  880</span>&#160;    <a class="code" href="namespacearm__compute.xhtml#a37c28ce239ce7092298245ce59694917">auto_init_if_empty</a>(*<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#adbf67dcee294e673cf796f1ed8aeb6a4">dst</a>, mm_result-&gt;clone()-&gt;set_data_type(<a class="code" href="namespacearm__compute.xhtml#ad8ed01ff3ff33333d8e19db4d2818bb6af14462d71aa842202c3e4b272c7ec924">DataType::QASYMM8</a>));</div>
<div class="line"><a name="l00881"></a><span class="lineno">  881</span>&#160; </div>
<div class="line"><a name="l00882"></a><span class="lineno">  882</span>&#160;    <span class="comment">// Configure kernel window</span></div>
<div class="line"><a name="l00883"></a><span class="lineno">  883</span>&#160;    Window win = <a class="code" href="namespacearm__compute.xhtml#aa84c2eae36ca4b68fa36c226df6f94e7">calculate_max_window</a>(*mm_result, Steps());</div>
<div class="line"><a name="l00884"></a><span class="lineno">  884</span>&#160; </div>
<div class="line"><a name="l00885"></a><span class="lineno">  885</span>&#160;    <span class="comment">// Note: This kernel performs 16 elements per iteration.</span></div>
<div class="line"><a name="l00886"></a><span class="lineno">  886</span>&#160;    <span class="comment">// However, since we use a left-over for loop, we cannot have any read or write out of memory</span></div>
<div class="line"><a name="l00887"></a><span class="lineno">  887</span>&#160;    <span class="comment">// For this reason num_elems_processed_per_iteration is 1 and so update_window_and_padding() can be skipped</span></div>
<div class="line"><a name="l00888"></a><span class="lineno">  888</span>&#160;    ICpuKernel::configure(win);</div>
<div class="line"><a name="l00889"></a><span class="lineno">  889</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="arm__compute_2core_2_validate_8h_source.xhtml#l00161">ARM_COMPUTE_ERROR_ON_NULLPTR</a>, <a class="el" href="_error_8h_source.xhtml#l00456">ARM_COMPUTE_ERROR_THROW_ON</a>, <a class="el" href="_error_8h_source.xhtml#l00152">ARM_COMPUTE_UNUSED</a>, <a class="el" href="_auto_configuration_8h_source.xhtml#l00043">arm_compute::auto_init_if_empty()</a>, <a class="el" href="working__space_8hpp_source.xhtml#l00322">bias</a>, <a class="el" href="_window_helpers_8cpp_source.xhtml#l00028">arm_compute::calculate_max_window()</a>, <a class="el" href="classarm__compute_1_1misc_1_1_i_cloneable.xhtml#a4d10e5012a872e7f78f2b539b673049d">ICloneable&lt; T &gt;::clone()</a>, <a class="el" href="_c_p_p_2_d_f_t_8cpp_source.xhtml#l00170">arm_compute::test::validation::dst</a>, <a class="el" href="_g_e_m_m_matrix_multiply_native_8cpp_source.xhtml#l00361">arm_compute::test::validation::k</a>, <a class="el" href="_dimensions_8h_source.xhtml#l00143">Dimensions&lt; T &gt;::num_dimensions()</a>, <a class="el" href="working__space_8hpp_source.xhtml#l00107">output_stage</a>, <a class="el" href="namespacearm__compute.xhtml#ad8ed01ff3ff33333d8e19db4d2818bb6af14462d71aa842202c3e4b272c7ec924">arm_compute::QASYMM8</a>, <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml#a7c66505457d00ece3aa4b34cab80757d">ITensorInfo::tensor_shape()</a>, and <a class="el" href="_cpu_direct_conv2d_kernel_8cpp_source.xhtml#l00060">arm_compute::cpu::kernels::validate_arguments()</a>.</p>

</div>
</div>
<a id="aef1a10d4d6422ca58d53d8414d5954bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aef1a10d4d6422ca58d53d8414d5954bd">&#9670;&nbsp;</a></span>name()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const char * name </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Name of the kernel. </p>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="classarm__compute_1_1_kernel.xhtml" title="Kernel class.">Kernel</a> name </dd></dl>

<p>Implements <a class="el" href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#a1a30ad8f276a2310571c36239554831a">ICPPKernel</a>.</p>

<p class="definition">Definition at line <a class="el" href="_cpu_gemm_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml#l00953">953</a> of file <a class="el" href="_cpu_gemm_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml">CpuGemmLowpOffsetContributionOutputStageKernel.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00954"></a><span class="lineno">  954</span>&#160;{</div>
<div class="line"><a name="l00955"></a><span class="lineno">  955</span>&#160;    <span class="keywordflow">return</span> <span class="stringliteral">&quot;CpuGemmLowpOffsetContributionOutputStageKernel&quot;</span>;</div>
<div class="line"><a name="l00956"></a><span class="lineno">  956</span>&#160;}</div>
</div><!-- fragment -->
</div>
</div>
<a id="a883429dd6cf828bfdd64b255afc458da"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a883429dd6cf828bfdd64b255afc458da">&#9670;&nbsp;</a></span>run_op()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void run_op </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_i_tensor_pack.xhtml">ITensorPack</a> &amp;&#160;</td>
          <td class="paramname"><em>tensors</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_window.xhtml">Window</a> &amp;&#160;</td>
          <td class="paramname"><em>window</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structarm__compute_1_1_thread_info.xhtml">ThreadInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>info</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Execute the kernel on the passed window. </p>
<dl class="section warning"><dt>Warning</dt><dd>If <a class="el" href="classarm__compute_1_1_i_kernel.xhtml#a0466ee6ce6552c87595f0e88e73eeb1b" title="Indicates whether or not the kernel is parallelisable.">is_parallelisable()</a> returns false then the passed window must be equal to <a class="el" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6" title="The maximum window the kernel can be executed on.">window()</a></dd></dl>
<dl class="section note"><dt>Note</dt><dd>The window has to be a region within the window returned by the <a class="el" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6" title="The maximum window the kernel can be executed on.">window()</a> method</dd>
<dd>
The width of the window has to be a multiple of <a class="el" href="_cl_im2_col_kernel_8cpp.xhtml#a4e45c1f5e4280813a78a77dda71d8799">num_elems_processed_per_iteration()</a>.</dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">tensors</td><td>A vector containing the tensors to operate on. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">window</td><td>Region on which to execute the kernel. (Must be a region of the window returned by <a class="el" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6" title="The maximum window the kernel can be executed on.">window()</a>) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">info</td><td>Info about executing thread and CPU. </td></tr>
  </table>
  </dd>
</dl>

<p>Reimplemented from <a class="el" href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#a6b8ef149ef3b6ca5e548473916f95cd6">ICPPKernel</a>.</p>

<p class="definition">Definition at line <a class="el" href="_cpu_gemm_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml#l00900">900</a> of file <a class="el" href="_cpu_gemm_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml">CpuGemmLowpOffsetContributionOutputStageKernel.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00901"></a><span class="lineno">  901</span>&#160;{</div>
<div class="line"><a name="l00902"></a><span class="lineno">  902</span>&#160;    <a class="code" href="_error_8h.xhtml#a6dc630a6ae9cc063b3924bcea8dee9d6">ARM_COMPUTE_UNUSED</a>(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#ac57b92957968088a392021cac1d2076b">info</a>);</div>
<div class="line"><a name="l00903"></a><span class="lineno">  903</span>&#160;    <a class="code" href="arm__compute_2core_2_validate_8h.xhtml#a1b35b0d258183cf9ef36adf684d0b88c">ARM_COMPUTE_ERROR_ON_UNCONFIGURED_KERNEL</a>(<span class="keyword">this</span>);</div>
<div class="line"><a name="l00904"></a><span class="lineno">  904</span>&#160;    <a class="code" href="arm__compute_2core_2_validate_8h.xhtml#a6eb9ce82815fe429250189da7592ba75">ARM_COMPUTE_ERROR_ON_INVALID_SUBWINDOW</a>(<a class="code" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">ICpuKernel::window</a>(), <a class="code" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">window</a>);</div>
<div class="line"><a name="l00905"></a><span class="lineno">  905</span>&#160; </div>
<div class="line"><a name="l00906"></a><span class="lineno">  906</span>&#160;    <span class="keyword">auto</span> mm_result      = tensors.get_const_tensor(<a class="code" href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828a135adba4335f0b231907ea8f61f9aff5">TensorType::ACL_SRC_0</a>);</div>
<div class="line"><a name="l00907"></a><span class="lineno">  907</span>&#160;    <span class="keyword">auto</span> vector_sum_col = tensors.get_const_tensor(<a class="code" href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828a33d31c31e7afde56ed0070133d4568a0">TensorType::ACL_SRC_1</a>);</div>
<div class="line"><a name="l00908"></a><span class="lineno">  908</span>&#160;    <span class="keyword">auto</span> vector_sum_row = tensors.get_const_tensor(<a class="code" href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828a01cea947a24713975f86d0769bf8fad5">TensorType::ACL_SRC_2</a>);</div>
<div class="line"><a name="l00909"></a><span class="lineno">  909</span>&#160;    <span class="keyword">auto</span> <a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>           = tensors.get_const_tensor(<a class="code" href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828ae4ed430701598bfaba04ee2dea5f0b0a">TensorType::ACL_SRC_3</a>);</div>
<div class="line"><a name="l00910"></a><span class="lineno">  910</span>&#160;    <span class="keyword">auto</span> <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#adbf67dcee294e673cf796f1ed8aeb6a4">dst</a>            = tensors.get_tensor(<a class="code" href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828a6f62ab7395c218e03e9d2942309c13a2">TensorType::ACL_DST</a>);</div>
<div class="line"><a name="l00911"></a><span class="lineno">  911</span>&#160; </div>
<div class="line"><a name="l00912"></a><span class="lineno">  912</span>&#160;    PixelValue type_min{};</div>
<div class="line"><a name="l00913"></a><span class="lineno">  913</span>&#160;    PixelValue type_max{};</div>
<div class="line"><a name="l00914"></a><span class="lineno">  914</span>&#160;    std::tie(type_min, type_max) = <a class="code" href="namespacearm__compute.xhtml#ae69217acf0f0b5d4de030a09ad50a0bc">get_min_max</a>(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#adbf67dcee294e673cf796f1ed8aeb6a4">dst</a>-&gt;info()-&gt;data_type());</div>
<div class="line"><a name="l00915"></a><span class="lineno">  915</span>&#160;    int32_t type_min_int = type_min.get&lt;int32_t&gt;();</div>
<div class="line"><a name="l00916"></a><span class="lineno">  916</span>&#160;    int32_t type_max_int = type_max.get&lt;int32_t&gt;();</div>
<div class="line"><a name="l00917"></a><span class="lineno">  917</span>&#160; </div>
<div class="line"><a name="l00918"></a><span class="lineno">  918</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> reinterpret_as_3d = vector_sum_row != <span class="keyword">nullptr</span></div>
<div class="line"><a name="l00919"></a><span class="lineno">  919</span>&#160;                                   &amp;&amp; mm_result-&gt;info()-&gt;num_dimensions() &gt; 1</div>
<div class="line"><a name="l00920"></a><span class="lineno">  920</span>&#160;                                   &amp;&amp; mm_result-&gt;info()-&gt;tensor_shape().y() != vector_sum_row-&gt;info()-&gt;tensor_shape().x();</div>
<div class="line"><a name="l00921"></a><span class="lineno">  921</span>&#160; </div>
<div class="line"><a name="l00922"></a><span class="lineno">  922</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> is_bounded_relu = !(_output_stage.<a class="code" href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml#a155d27c75f14a82a74e5039c9657c8eb">gemmlowp_min_bound</a> &lt;= type_min_int &amp;&amp; _output_stage.<a class="code" href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml#a6db94040329f1dedcd348ec7de072e2a">gemmlowp_max_bound</a> &gt;= type_max_int);</div>
<div class="line"><a name="l00923"></a><span class="lineno">  923</span>&#160; </div>
<div class="line"><a name="l00924"></a><span class="lineno">  924</span>&#160;    <span class="comment">// Check if we need to perform fixed point requantization</span></div>
<div class="line"><a name="l00925"></a><span class="lineno">  925</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> is_fixed_point = _output_stage.<a class="code" href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml#a6e019ad85979fd73c74f97e5483faf35">type</a> != <a class="code" href="namespacearm__compute.xhtml#a5558e2cc22f7f4771653d992c8ad8864a079e2ddc95b344b5cb0188bed9a80d8b">GEMMLowpOutputStageType::QUANTIZE_DOWN</a>;</div>
<div class="line"><a name="l00926"></a><span class="lineno">  926</span>&#160; </div>
<div class="line"><a name="l00927"></a><span class="lineno">  927</span>&#160;    <span class="comment">// Check if symmetric per-channel execution</span></div>
<div class="line"><a name="l00928"></a><span class="lineno">  928</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> is_signed = <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#adbf67dcee294e673cf796f1ed8aeb6a4">dst</a>-&gt;info()-&gt;data_type() == <a class="code" href="namespacearm__compute.xhtml#ad8ed01ff3ff33333d8e19db4d2818bb6a329f5d0c4b0c80e3474951d2c4435dd9">DataType::QASYMM8_SIGNED</a>;</div>
<div class="line"><a name="l00929"></a><span class="lineno">  929</span>&#160; </div>
<div class="line"><a name="l00930"></a><span class="lineno">  930</span>&#160;    <span class="comment">// Check if symmetric per-channel execution</span></div>
<div class="line"><a name="l00931"></a><span class="lineno">  931</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> is_symm = _output_stage.<a class="code" href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml#a94e1801be6c3d9d6645c694d7e280cda">is_quantized_per_channel</a>;</div>
<div class="line"><a name="l00932"></a><span class="lineno">  932</span>&#160; </div>
<div class="line"><a name="l00933"></a><span class="lineno">  933</span>&#160;    <span class="keywordflow">if</span>(is_symm)</div>
<div class="line"><a name="l00934"></a><span class="lineno">  934</span>&#160;    {</div>
<div class="line"><a name="l00935"></a><span class="lineno">  935</span>&#160;        run_offset_contribution_output_stage_symm(<a class="code" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">window</a>, mm_result, vector_sum_col, vector_sum_row, <a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#adbf67dcee294e673cf796f1ed8aeb6a4">dst</a>, _a_offset, _b_offset, _k_offset, _is_vector_sum_col_batched, _output_stage,</div>
<div class="line"><a name="l00936"></a><span class="lineno">  936</span>&#160;                                                  reinterpret_as_3d, is_bounded_relu, is_fixed_point);</div>
<div class="line"><a name="l00937"></a><span class="lineno">  937</span>&#160;    }</div>
<div class="line"><a name="l00938"></a><span class="lineno">  938</span>&#160;    <span class="keywordflow">else</span></div>
<div class="line"><a name="l00939"></a><span class="lineno">  939</span>&#160;    {</div>
<div class="line"><a name="l00940"></a><span class="lineno">  940</span>&#160;        <span class="keywordflow">if</span>(is_signed)</div>
<div class="line"><a name="l00941"></a><span class="lineno">  941</span>&#160;        {</div>
<div class="line"><a name="l00942"></a><span class="lineno">  942</span>&#160;            run_offset_contribution_output_stage&lt;int8_t&gt;(<a class="code" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">window</a>, mm_result, vector_sum_col, vector_sum_row, <a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#adbf67dcee294e673cf796f1ed8aeb6a4">dst</a>, _a_offset, _b_offset, _k_offset, _is_vector_sum_col_batched, _output_stage,</div>
<div class="line"><a name="l00943"></a><span class="lineno">  943</span>&#160;                                                         reinterpret_as_3d, is_bounded_relu, is_fixed_point);</div>
<div class="line"><a name="l00944"></a><span class="lineno">  944</span>&#160;        }</div>
<div class="line"><a name="l00945"></a><span class="lineno">  945</span>&#160;        <span class="keywordflow">else</span></div>
<div class="line"><a name="l00946"></a><span class="lineno">  946</span>&#160;        {</div>
<div class="line"><a name="l00947"></a><span class="lineno">  947</span>&#160;            run_offset_contribution_output_stage&lt;uint8_t&gt;(<a class="code" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">window</a>, mm_result, vector_sum_col, vector_sum_row, <a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#adbf67dcee294e673cf796f1ed8aeb6a4">dst</a>, _a_offset, _b_offset, _k_offset, _is_vector_sum_col_batched, _output_stage,</div>
<div class="line"><a name="l00948"></a><span class="lineno">  948</span>&#160;                                                          reinterpret_as_3d, is_bounded_relu, is_fixed_point);</div>
<div class="line"><a name="l00949"></a><span class="lineno">  949</span>&#160;        }</div>
<div class="line"><a name="l00950"></a><span class="lineno">  950</span>&#160;    }</div>
<div class="line"><a name="l00951"></a><span class="lineno">  951</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00055">arm_compute::ACL_DST</a>, <a class="el" href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00045">arm_compute::ACL_SRC_0</a>, <a class="el" href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00046">arm_compute::ACL_SRC_1</a>, <a class="el" href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00047">arm_compute::ACL_SRC_2</a>, <a class="el" href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00048">arm_compute::ACL_SRC_3</a>, <a class="el" href="arm__compute_2core_2_validate_8h_source.xhtml#l00205">ARM_COMPUTE_ERROR_ON_INVALID_SUBWINDOW</a>, <a class="el" href="arm__compute_2core_2_validate_8h_source.xhtml#l01004">ARM_COMPUTE_ERROR_ON_UNCONFIGURED_KERNEL</a>, <a class="el" href="_error_8h_source.xhtml#l00152">ARM_COMPUTE_UNUSED</a>, <a class="el" href="working__space_8hpp_source.xhtml#l00322">bias</a>, <a class="el" href="_c_p_p_2_d_f_t_8cpp_source.xhtml#l00170">arm_compute::test::validation::dst</a>, <a class="el" href="_g_e_m_m_info_8h_source.xhtml#l00052">GEMMLowpOutputStageInfo::gemmlowp_max_bound</a>, <a class="el" href="_g_e_m_m_info_8h_source.xhtml#l00051">GEMMLowpOutputStageInfo::gemmlowp_min_bound</a>, <a class="el" href="_i_tensor_pack_8cpp_source.xhtml#l00054">ITensorPack::get_const_tensor()</a>, <a class="el" href="_data_type_utils_8h_source.xhtml#l00195">arm_compute::get_min_max()</a>, <a class="el" href="_i_tensor_pack_8cpp_source.xhtml#l00064">ITensorPack::get_tensor()</a>, <a class="el" href="namespacearm__compute_1_1test_1_1validation.xhtml#ac57b92957968088a392021cac1d2076b">arm_compute::test::validation::info</a>, <a class="el" href="_g_e_m_m_info_8h_source.xhtml#l00056">GEMMLowpOutputStageInfo::is_quantized_per_channel</a>, <a class="el" href="namespacearm__compute.xhtml#ad8ed01ff3ff33333d8e19db4d2818bb6a329f5d0c4b0c80e3474951d2c4435dd9">arm_compute::QASYMM8_SIGNED</a>, <a class="el" href="namespacearm__compute.xhtml#a5558e2cc22f7f4771653d992c8ad8864a079e2ddc95b344b5cb0188bed9a80d8b">arm_compute::QUANTIZE_DOWN</a>, <a class="el" href="_g_e_m_m_info_8h_source.xhtml#l00047">GEMMLowpOutputStageInfo::type</a>, and <a class="el" href="_i_kernel_8cpp_source.xhtml#l00028">IKernel::window()</a>.</p>

</div>
</div>
<a id="af476aae8f71beb1507ae5edf879fb4db"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af476aae8f71beb1507ae5edf879fb4db">&#9670;&nbsp;</a></span>validate()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_status.xhtml">Status</a> validate </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>mm_result</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>vector_sum_col</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>vector_sum_row</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>dst</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>a_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>b_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml">GEMMLowpOutputStageInfo</a>&#160;</td>
          <td class="paramname"><em>output_stage</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Static function to check if given info will lead to a valid configuration. </p>
<p>Similar to <a class="el" href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml#a5ac9415f2263fd8faf18482908122b61" title="Initialise the kernel inputs and output.">CpuGemmLowpOffsetContributionOutputStageKernel::configure()</a></p>
<dl class="section return"><dt>Returns</dt><dd>a status </dd></dl>

<p class="definition">Definition at line <a class="el" href="_cpu_gemm_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml#l00891">891</a> of file <a class="el" href="_cpu_gemm_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml">CpuGemmLowpOffsetContributionOutputStageKernel.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00894"></a><span class="lineno">  894</span>&#160;{</div>
<div class="line"><a name="l00895"></a><span class="lineno">  895</span>&#160;    <a class="code" href="arm__compute_2core_2_validate_8h.xhtml#a921b705e9e3e0fe928928447869e62a5">ARM_COMPUTE_ERROR_ON_NULLPTR</a>(mm_result, output);</div>
<div class="line"><a name="l00896"></a><span class="lineno">  896</span>&#160;    <a class="code" href="_error_8h.xhtml#a8a1e1c105f0bdaf37db408c7cfcb77a4">ARM_COMPUTE_RETURN_ON_ERROR</a>(<a class="code" href="namespacearm__compute_1_1cpu_1_1kernels.xhtml#acf9ea6633274730cd08b8b8fab3a6fe6">validate_arguments</a>(mm_result, vector_sum_col, vector_sum_row, <a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>, output, a_offset, b_offset, <a class="code" href="working__space_8hpp.xhtml#aa2b9b52a4827eeb41f97f92a3781eee8">output_stage</a>));</div>
<div class="line"><a name="l00897"></a><span class="lineno">  897</span>&#160;    <span class="keywordflow">return</span> Status{};</div>
<div class="line"><a name="l00898"></a><span class="lineno">  898</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="arm__compute_2core_2_validate_8h_source.xhtml#l00161">ARM_COMPUTE_ERROR_ON_NULLPTR</a>, <a class="el" href="_error_8h_source.xhtml#l00204">ARM_COMPUTE_RETURN_ON_ERROR</a>, <a class="el" href="working__space_8hpp_source.xhtml#l00322">bias</a>, <a class="el" href="working__space_8hpp_source.xhtml#l00107">output_stage</a>, and <a class="el" href="_cpu_direct_conv2d_kernel_8cpp_source.xhtml#l00060">arm_compute::cpu::kernels::validate_arguments()</a>.</p>

<p class="reference">Referenced by <a class="el" href="_cpu_gemm_lowp_matrix_multiply_core_8cpp_source.xhtml#l00311">CpuGemmLowpMatrixMultiplyCore::validate()</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>src/cpu/kernels/<a class="el" href="_cpu_gemm_lowp_offset_contribution_output_stage_kernel_8h_source.xhtml">CpuGemmLowpOffsetContributionOutputStageKernel.h</a></li>
<li>src/cpu/kernels/<a class="el" href="_cpu_gemm_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml">CpuGemmLowpOffsetContributionOutputStageKernel.cpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<div class="ttc" id="anamespacearm__compute_xhtml_aa84c2eae36ca4b68fa36c226df6f94e7"><div class="ttname"><a href="namespacearm__compute.xhtml#aa84c2eae36ca4b68fa36c226df6f94e7">arm_compute::calculate_max_window</a></div><div class="ttdeci">Window calculate_max_window(const ValidRegion &amp;valid_region, const Steps &amp;steps, bool skip_border, BorderSize border_size)</div><div class="ttdef"><b>Definition:</b> <a href="_window_helpers_8cpp_source.xhtml#l00028">WindowHelpers.cpp:28</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_ad8ed01ff3ff33333d8e19db4d2818bb6af14462d71aa842202c3e4b272c7ec924"><div class="ttname"><a href="namespacearm__compute.xhtml#ad8ed01ff3ff33333d8e19db4d2818bb6af14462d71aa842202c3e4b272c7ec924">arm_compute::DataType::QASYMM8</a></div><div class="ttdeci">@ QASYMM8</div><div class="ttdoc">quantized, asymmetric fixed-point 8-bit number unsigned</div></div>
<div class="ttc" id="anamespacearm__compute_1_1test_1_1validation_xhtml_adbf67dcee294e673cf796f1ed8aeb6a4"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#adbf67dcee294e673cf796f1ed8aeb6a4">arm_compute::test::validation::dst</a></div><div class="ttdeci">auto dst</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_p_2_d_f_t_8cpp_source.xhtml#l00170">DFT.cpp:170</a></div></div>
<div class="ttc" id="anamespacearm__compute_1_1cpu_1_1kernels_xhtml_acf9ea6633274730cd08b8b8fab3a6fe6"><div class="ttname"><a href="namespacearm__compute_1_1cpu_1_1kernels.xhtml#acf9ea6633274730cd08b8b8fab3a6fe6">arm_compute::cpu::kernels::validate_arguments</a></div><div class="ttdeci">Status validate_arguments(const ITensorInfo *src, const ITensorInfo *weights, const ITensorInfo *dst, const PadStrideInfo &amp;conv_info)</div><div class="ttdef"><b>Definition:</b> <a href="_cpu_direct_conv2d_kernel_8cpp_source.xhtml#l00060">CpuDirectConv2dKernel.cpp:60</a></div></div>
<div class="ttc" id="astructarm__compute_1_1_g_e_m_m_lowp_output_stage_info_xhtml_a6e019ad85979fd73c74f97e5483faf35"><div class="ttname"><a href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml#a6e019ad85979fd73c74f97e5483faf35">arm_compute::GEMMLowpOutputStageInfo::type</a></div><div class="ttdeci">GEMMLowpOutputStageType type</div><div class="ttdoc">GEMMLowp output stage type.</div><div class="ttdef"><b>Definition:</b> <a href="_g_e_m_m_info_8h_source.xhtml#l00047">GEMMInfo.h:47</a></div></div>
<div class="ttc" id="aarm__compute_2core_2_validate_8h_xhtml_a1b35b0d258183cf9ef36adf684d0b88c"><div class="ttname"><a href="arm__compute_2core_2_validate_8h.xhtml#a1b35b0d258183cf9ef36adf684d0b88c">ARM_COMPUTE_ERROR_ON_UNCONFIGURED_KERNEL</a></div><div class="ttdeci">#define ARM_COMPUTE_ERROR_ON_UNCONFIGURED_KERNEL(k)</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2_validate_8h_source.xhtml#l01004">Validate.h:1004</a></div></div>
<div class="ttc" id="astructarm__compute_1_1_g_e_m_m_lowp_output_stage_info_xhtml_a94e1801be6c3d9d6645c694d7e280cda"><div class="ttname"><a href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml#a94e1801be6c3d9d6645c694d7e280cda">arm_compute::GEMMLowpOutputStageInfo::is_quantized_per_channel</a></div><div class="ttdeci">bool is_quantized_per_channel</div><div class="ttdoc">GEMMLowp quantized per-channel flag.</div><div class="ttdef"><b>Definition:</b> <a href="_g_e_m_m_info_8h_source.xhtml#l00056">GEMMInfo.h:56</a></div></div>
<div class="ttc" id="anamespacearm__compute_1_1test_1_1validation_xhtml_a73aa59d7b088082ec257a1c65edbf1d0"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#a73aa59d7b088082ec257a1c65edbf1d0">arm_compute::test::validation::k</a></div><div class="ttdeci">const unsigned int k</div><div class="ttdef"><b>Definition:</b> <a href="_g_e_m_m_matrix_multiply_native_8cpp_source.xhtml#l00361">GEMMMatrixMultiplyNative.cpp:361</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_a08e287b5f0197ce8c7c84dde6db24828ae4ed430701598bfaba04ee2dea5f0b0a"><div class="ttname"><a href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828ae4ed430701598bfaba04ee2dea5f0b0a">arm_compute::ACL_SRC_3</a></div><div class="ttdeci">@ ACL_SRC_3</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00048">Types.h:48</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_a08e287b5f0197ce8c7c84dde6db24828a135adba4335f0b231907ea8f61f9aff5"><div class="ttname"><a href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828a135adba4335f0b231907ea8f61f9aff5">arm_compute::ACL_SRC_0</a></div><div class="ttdeci">@ ACL_SRC_0</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00045">Types.h:45</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_a08e287b5f0197ce8c7c84dde6db24828a33d31c31e7afde56ed0070133d4568a0"><div class="ttname"><a href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828a33d31c31e7afde56ed0070133d4568a0">arm_compute::ACL_SRC_1</a></div><div class="ttdeci">@ ACL_SRC_1</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00046">Types.h:46</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_a08e287b5f0197ce8c7c84dde6db24828a01cea947a24713975f86d0769bf8fad5"><div class="ttname"><a href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828a01cea947a24713975f86d0769bf8fad5">arm_compute::ACL_SRC_2</a></div><div class="ttdeci">@ ACL_SRC_2</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00047">Types.h:47</a></div></div>
<div class="ttc" id="astructarm__compute_1_1_g_e_m_m_lowp_output_stage_info_xhtml_a6db94040329f1dedcd348ec7de072e2a"><div class="ttname"><a href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml#a6db94040329f1dedcd348ec7de072e2a">arm_compute::GEMMLowpOutputStageInfo::gemmlowp_max_bound</a></div><div class="ttdeci">int32_t gemmlowp_max_bound</div><div class="ttdoc">GEMMLowp max value used to saturate down the output result before converting back to QASYMM8.</div><div class="ttdef"><b>Definition:</b> <a href="_g_e_m_m_info_8h_source.xhtml#l00052">GEMMInfo.h:52</a></div></div>
<div class="ttc" id="a_error_8h_xhtml_a8a1e1c105f0bdaf37db408c7cfcb77a4"><div class="ttname"><a href="_error_8h.xhtml#a8a1e1c105f0bdaf37db408c7cfcb77a4">ARM_COMPUTE_RETURN_ON_ERROR</a></div><div class="ttdeci">#define ARM_COMPUTE_RETURN_ON_ERROR(status)</div><div class="ttdoc">Checks if a status contains an error and returns it.</div><div class="ttdef"><b>Definition:</b> <a href="_error_8h_source.xhtml#l00204">Error.h:204</a></div></div>
<div class="ttc" id="aworking__space_8hpp_xhtml_aa2b9b52a4827eeb41f97f92a3781eee8"><div class="ttname"><a href="working__space_8hpp.xhtml#aa2b9b52a4827eeb41f97f92a3781eee8">output_stage</a></div><div class="ttdeci">const OutputStage &amp; output_stage</div><div class="ttdef"><b>Definition:</b> <a href="working__space_8hpp_source.xhtml#l00107">working_space.hpp:107</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_a5558e2cc22f7f4771653d992c8ad8864a079e2ddc95b344b5cb0188bed9a80d8b"><div class="ttname"><a href="namespacearm__compute.xhtml#a5558e2cc22f7f4771653d992c8ad8864a079e2ddc95b344b5cb0188bed9a80d8b">arm_compute::GEMMLowpOutputStageType::QUANTIZE_DOWN</a></div><div class="ttdeci">@ QUANTIZE_DOWN</div><div class="ttdoc">Quantize using an integer multiplication.</div></div>
<div class="ttc" id="aarm__compute_2core_2_validate_8h_xhtml_a921b705e9e3e0fe928928447869e62a5"><div class="ttname"><a href="arm__compute_2core_2_validate_8h.xhtml#a921b705e9e3e0fe928928447869e62a5">ARM_COMPUTE_ERROR_ON_NULLPTR</a></div><div class="ttdeci">#define ARM_COMPUTE_ERROR_ON_NULLPTR(...)</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2_validate_8h_source.xhtml#l00161">Validate.h:161</a></div></div>
<div class="ttc" id="a_error_8h_xhtml_a938dcd406ce611ef5345ad2531cdb948"><div class="ttname"><a href="_error_8h.xhtml#a938dcd406ce611ef5345ad2531cdb948">ARM_COMPUTE_ERROR_THROW_ON</a></div><div class="ttdeci">#define ARM_COMPUTE_ERROR_THROW_ON(status)</div><div class="ttdef"><b>Definition:</b> <a href="_error_8h_source.xhtml#l00456">Error.h:456</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_a08e287b5f0197ce8c7c84dde6db24828a6f62ab7395c218e03e9d2942309c13a2"><div class="ttname"><a href="namespacearm__compute.xhtml#a08e287b5f0197ce8c7c84dde6db24828a6f62ab7395c218e03e9d2942309c13a2">arm_compute::ACL_DST</a></div><div class="ttdeci">@ ACL_DST</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2experimental_2_types_8h_source.xhtml#l00055">Types.h:55</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_a37c28ce239ce7092298245ce59694917"><div class="ttname"><a href="namespacearm__compute.xhtml#a37c28ce239ce7092298245ce59694917">arm_compute::auto_init_if_empty</a></div><div class="ttdeci">bool auto_init_if_empty(ITensorInfo &amp;info, const TensorShape &amp;shape, int num_channels, DataType data_type, QuantizationInfo quantization_info=QuantizationInfo())</div><div class="ttdoc">Auto initialize the tensor info (shape, number of channels and data type) if the current assignment i...</div><div class="ttdef"><b>Definition:</b> <a href="_auto_configuration_8h_source.xhtml#l00043">AutoConfiguration.h:43</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_ad8ed01ff3ff33333d8e19db4d2818bb6a329f5d0c4b0c80e3474951d2c4435dd9"><div class="ttname"><a href="namespacearm__compute.xhtml#ad8ed01ff3ff33333d8e19db4d2818bb6a329f5d0c4b0c80e3474951d2c4435dd9">arm_compute::DataType::QASYMM8_SIGNED</a></div><div class="ttdeci">@ QASYMM8_SIGNED</div><div class="ttdoc">quantized, asymmetric fixed-point 8-bit number signed</div></div>
<div class="ttc" id="aarm__compute_2core_2_validate_8h_xhtml_a6eb9ce82815fe429250189da7592ba75"><div class="ttname"><a href="arm__compute_2core_2_validate_8h.xhtml#a6eb9ce82815fe429250189da7592ba75">ARM_COMPUTE_ERROR_ON_INVALID_SUBWINDOW</a></div><div class="ttdeci">#define ARM_COMPUTE_ERROR_ON_INVALID_SUBWINDOW(f, s)</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2_validate_8h_source.xhtml#l00205">Validate.h:205</a></div></div>
<div class="ttc" id="aworking__space_8hpp_xhtml_a1fb7b822a92dd3ab6e7ab15c67b0ff9e"><div class="ttname"><a href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a></div><div class="ttdeci">const int32_t * bias</div><div class="ttdef"><b>Definition:</b> <a href="working__space_8hpp_source.xhtml#l00322">working_space.hpp:322</a></div></div>
<div class="ttc" id="a_error_8h_xhtml_a6dc630a6ae9cc063b3924bcea8dee9d6"><div class="ttname"><a href="_error_8h.xhtml#a6dc630a6ae9cc063b3924bcea8dee9d6">ARM_COMPUTE_UNUSED</a></div><div class="ttdeci">#define ARM_COMPUTE_UNUSED(...)</div><div class="ttdoc">To avoid unused variables warnings.</div><div class="ttdef"><b>Definition:</b> <a href="_error_8h_source.xhtml#l00152">Error.h:152</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_i_kernel_xhtml_ad34a46f53686c12a5c5e717cc9617fb6"><div class="ttname"><a href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">arm_compute::IKernel::window</a></div><div class="ttdeci">const Window &amp; window() const</div><div class="ttdoc">The maximum window the kernel can be executed on.</div><div class="ttdef"><b>Definition:</b> <a href="_i_kernel_8cpp_source.xhtml#l00028">IKernel.cpp:28</a></div></div>
<div class="ttc" id="astructarm__compute_1_1_g_e_m_m_lowp_output_stage_info_xhtml_a155d27c75f14a82a74e5039c9657c8eb"><div class="ttname"><a href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml#a155d27c75f14a82a74e5039c9657c8eb">arm_compute::GEMMLowpOutputStageInfo::gemmlowp_min_bound</a></div><div class="ttdeci">int32_t gemmlowp_min_bound</div><div class="ttdoc">GEMMLowp min value used to saturate down the output result before converting back to QASYMM8.</div><div class="ttdef"><b>Definition:</b> <a href="_g_e_m_m_info_8h_source.xhtml#l00051">GEMMInfo.h:51</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_ae69217acf0f0b5d4de030a09ad50a0bc"><div class="ttname"><a href="namespacearm__compute.xhtml#ae69217acf0f0b5d4de030a09ad50a0bc">arm_compute::get_min_max</a></div><div class="ttdeci">std::tuple&lt; PixelValue, PixelValue &gt; get_min_max(DataType dt)</div><div class="ttdoc">Compute the mininum and maximum values a data type can take.</div><div class="ttdef"><b>Definition:</b> <a href="_data_type_utils_8h_source.xhtml#l00195">DataTypeUtils.h:195</a></div></div>
<div class="ttc" id="anamespacearm__compute_1_1test_1_1validation_xhtml_ac57b92957968088a392021cac1d2076b"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#ac57b92957968088a392021cac1d2076b">arm_compute::test::validation::info</a></div><div class="ttdeci">ScaleKernelInfo info(interpolation_policy, default_border_mode, PixelValue(), sampling_policy, false)</div></div>
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacearm__compute.xhtml">arm_compute</a></li><li class="navelem"><a class="el" href="namespacearm__compute_1_1cpu.xhtml">cpu</a></li><li class="navelem"><a class="el" href="namespacearm__compute_1_1cpu_1_1kernels.xhtml">kernels</a></li><li class="navelem"><a class="el" href="classarm__compute_1_1cpu_1_1kernels_1_1_cpu_gemm_lowp_offset_contribution_output_stage_kernel.xhtml">CpuGemmLowpOffsetContributionOutputStageKernel</a></li>
    <li class="footer">Generated on Wed Aug 23 2023 13:07:23 for Compute Library by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.17 </li>
  </ul>
</div>
</body>
</html>
