<!-- HTML header for doxygen 1.8.15-->
<!-- Remember to use version doxygen 1.8.15 +-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="robots" content="NOINDEX, NOFOLLOW" /> <!-- Prevent indexing by search engines -->
<title>Compute Library: arm_compute::opencl::kernels Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <img alt="Compute Library" src="https://raw.githubusercontent.com/ARM-software/ComputeLibrary/gh-pages/ACL_logo.png" style="max-width: 100%;margin-top: 15px;margin-left: 10px"/>
  <td style="padding-left: 0.5em;">
   <div id="projectname">
   &#160;<span id="projectnumber">24.02</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('namespacearm__compute_1_1opencl_1_1kernels.xhtml',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#namespaces">Namespaces</a> &#124;
<a href="#nested-classes">Data Structures</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">arm_compute::opencl::kernels Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="namespaces"></a>
Namespaces</h2></td></tr>
<tr class="memitem:namespacearm__compute_1_1opencl_1_1kernels_1_1gemm"><td class="memItemLeft" align="right" valign="top"> &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacearm__compute_1_1opencl_1_1kernels_1_1gemm.xhtml">gemm</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Data Structures</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_activation_kernel.xhtml">ClActivationKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the activation kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_activation_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_arithmetic_kernel.xhtml">ClArithmeticKernel</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_batch_concatenate_kernel.xhtml">ClBatchConcatenateKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the batch concatenate kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_batch_concatenate_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_cast_kernel.xhtml">ClCastKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Casts a given tensor to a new type.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_cast_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_col2_im_kernel.xhtml">ClCol2ImKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the col2im reshaping kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_col2_im_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_complex_mul_kernel.xhtml">ClComplexMulKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the complex pixelwise multiplication kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_complex_mul_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_convert_fully_connected_weights_kernel.xhtml">ClConvertFullyConnectedWeightsKernel</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_copy_kernel.xhtml">ClCopyKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel to perform a copy between two tensors.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_copy_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_crop_kernel.xhtml">ClCropKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel to perform a copy between two tensors.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_crop_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_depth_concatenate_kernel.xhtml">ClDepthConcatenateKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the depth concatenate kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_depth_concatenate_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_dequantize_kernel.xhtml">ClDequantizeKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the dequantization layer kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_dequantize_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_direct_conv2d_kernel.xhtml">ClDirectConv2dKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the direct convolution kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_direct_conv2d_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_direct_conv3d_kernel.xhtml">ClDirectConv3dKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the direct convolution 3d kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_direct_conv3d_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_elementwise_kernel.xhtml">ClElementwiseKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for an element-wise operation kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_elementwise_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_element_wise_unary_kernel.xhtml">ClElementWiseUnaryKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the elementwise unary operator.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_element_wise_unary_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_fill_kernel.xhtml">ClFillKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for filling the planes of a tensor.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_fill_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_floor_kernel.xhtml">ClFloorKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel to perform a floor operation.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_floor_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_matrix_a_reduction_kernel.xhtml">ClGemmLowpMatrixAReductionKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel used to compute the row-vectors of sums of all the entries in each row of Matrix A.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_matrix_a_reduction_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_matrix_b_reduction_kernel.xhtml">ClGemmLowpMatrixBReductionKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel used to compute the row-vectors of sums of all the entries in each column of Matrix B.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_matrix_b_reduction_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_matrix_multiply_native_kernel.xhtml">ClGemmLowpMatrixMultiplyNativeKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel to multiply matrices with QASYMM8/QASYMM8_SIGNED data type.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_matrix_multiply_native_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_matrix_multiply_reshaped_kernel.xhtml">ClGemmLowpMatrixMultiplyReshapedKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel to multiply matrices when both the input matrices LHS (src0) and RHS (src1) have been reshaped.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_matrix_multiply_reshaped_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_matrix_multiply_reshaped_only_rhs_kernel.xhtml">ClGemmLowpMatrixMultiplyReshapedOnlyRhsKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel to multiply matrices with QASYMM8 data type when only the input matrix RHS (src1) has been reshaped.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_matrix_multiply_reshaped_only_rhs_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_matrix_multiply_reshaped_only_rhs_m_m_u_l_kernel.xhtml">ClGemmLowpMatrixMultiplyReshapedOnlyRhsMMULKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel to multiply matrices with QASYMM8/QASYMM8_SIGNED data types when only the input matrix RHS (src1) has been reshaped using the MMUL instruction.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_matrix_multiply_reshaped_only_rhs_m_m_u_l_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_offset_contribution_kernel.xhtml">ClGemmLowpOffsetContributionKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel used to add the offset contribution after the matrix multiplication.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_offset_contribution_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_offset_contribution_output_stage_kernel.xhtml">ClGemmLowpOffsetContributionOutputStageKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel used to add the offset contribution after the matrix multiplication and perform the output stage.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_offset_contribution_output_stage_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_quantize_down_int32_scale_by_fixed_point_kernel.xhtml">ClGemmLowpQuantizeDownInt32ScaleByFixedPointKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel used to quantize down the int32 accumulator values of GEMMLowp to QASYMM8/QASYMM8_SIGNED/QSYMM16.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_quantize_down_int32_scale_by_fixed_point_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_quantize_down_int32_scale_by_float_kernel.xhtml">ClGemmLowpQuantizeDownInt32ScaleByFloatKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel used to quantize down the int32 accumulator values of GEMMLowp to QASYMM8/QASYMM8_SIGNED.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_quantize_down_int32_scale_by_float_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_quantize_down_int32_scale_kernel.xhtml">ClGemmLowpQuantizeDownInt32ScaleKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel used to quantize down the int32 accumulator values of GEMMLowp to QASYMM8/QASYMM8_SIGNED.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_lowp_quantize_down_int32_scale_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_matrix_multiply_native_kernel.xhtml">ClGemmMatrixMultiplyNativeKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel to multiply matrices when neither of the input matrices have been reshaped.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_matrix_multiply_native_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_matrix_multiply_reshaped_kernel.xhtml">ClGemmMatrixMultiplyReshapedKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel to multiply matrices when both the input matrices LHS (src0) and RHS (src1) have been reshaped.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_matrix_multiply_reshaped_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_matrix_multiply_reshaped_only_rhs_kernel.xhtml">ClGemmMatrixMultiplyReshapedOnlyRhsKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel to multiply matrices when only the input matrix RHS (src1) has been reshaped.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_matrix_multiply_reshaped_only_rhs_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_matrix_multiply_reshaped_only_rhs_m_m_u_l_kernel.xhtml">ClGemmMatrixMultiplyReshapedOnlyRhsMMULKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel to multiply matrices using MMUL when only the input matrix RHS (src1) has been reshaped.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_matrix_multiply_reshaped_only_rhs_m_m_u_l_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_reshape_lhs_matrix_kernel.xhtml">ClGemmReshapeLhsMatrixKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel to reshape the LHS matrix when performing the matrix multiplication.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_reshape_lhs_matrix_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_reshape_rhs_matrix_kernel.xhtml">ClGemmReshapeRhsMatrixKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel to reshape the RHS matrix when performing the matrix multiplication In particular, this kernel splits the src matrix in blocks of size K0xN0 and stores each one in the dst matrix unrolling the values.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_gemm_reshape_rhs_matrix_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_height_concatenate_kernel.xhtml">ClHeightConcatenateKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the height concatenate kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_height_concatenate_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_im2_col_kernel.xhtml">ClIm2ColKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the im2col reshape kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_im2_col_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_indirect_conv2d_address_precalculation_kernel.xhtml">ClIndirectConv2dAddressPrecalculationKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the direct convolution kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_indirect_conv2d_address_precalculation_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_indirect_conv2d_kernel.xhtml">ClIndirectConv2dKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the indirect convolution kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_indirect_conv2d_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_logical_binary_kernel.xhtml">ClLogicalBinaryKernel</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_mat_mul_lowp_native_kernel.xhtml">ClMatMulLowpNativeKernel</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_mat_mul_lowp_native_m_m_u_l_kernel.xhtml">ClMatMulLowpNativeMMULKernel</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_mat_mul_native_kernel.xhtml">ClMatMulNativeKernel</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_mat_mul_native_m_m_u_l_kernel.xhtml">ClMatMulNativeMMULKernel</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_mul_kernel.xhtml">ClMulKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the pixelwise multiplication kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_mul_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_permute_kernel.xhtml">ClPermuteKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel to perform tensor permutation.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_permute_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_pool2d_kernel.xhtml">ClPool2dKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the pooling layer kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_pool2d_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_pool3d_kernel.xhtml">ClPool3dKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the pooling layer kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_pool3d_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_quantize_kernel.xhtml">ClQuantizeKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the quantization layer kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_quantize_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_reshape_kernel.xhtml">ClReshapeKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the kernel to perform tensor reshaping.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_reshape_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_saturated_arithmetic_kernel.xhtml">ClSaturatedArithmeticKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Addition operation.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_saturated_arithmetic_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_scale_kernel.xhtml">ClScaleKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the scale kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_scale_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_softmax_kernel.xhtml">ClSoftmaxKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">The CL kernel that performs softmax function.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_softmax_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_transposed_convolution_kernel.xhtml">ClTransposedConvolutionKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel for transposed convolution.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_transposed_convolution_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_transpose_kernel.xhtml">ClTransposeKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel to transpose a tensor.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_transpose_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_weights_reshape_kernel.xhtml">ClWeightsReshapeKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel to perform reshaping on the weights used by convolution and locally connected layer.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_weights_reshape_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_width_concatenate2_tensors_kernel.xhtml">ClWidthConcatenate2TensorsKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the width concatenate kernel of 2 tensors.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_width_concatenate2_tensors_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_width_concatenate4_tensors_kernel.xhtml">ClWidthConcatenate4TensorsKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the width concatenate kernel of 4 tensors.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_width_concatenate4_tensors_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_width_concatenate_kernel.xhtml">ClWidthConcatenateKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the width concatenate kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_width_concatenate_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_winograd_filter_transform_kernel.xhtml">ClWinogradFilterTransformKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the Winograd filter transform kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_winograd_filter_transform_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_winograd_input_transform_kernel.xhtml">ClWinogradInputTransformKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">OpenCL kernel to perform Winograd input transform.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_winograd_input_transform_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_winograd_output_transform_kernel.xhtml">ClWinogradOutputTransformKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface for the Winograd output transform kernel.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_cl_winograd_output_transform_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1opencl_1_1kernels_1_1_i_cl_gemm_lowp_reduction_kernel.xhtml">IClGemmLowpReductionKernel</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Common interface for all OpenCL reduction kernels.  <a href="classarm__compute_1_1opencl_1_1kernels_1_1_i_cl_gemm_lowp_reduction_kernel.xhtml#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a70ae61bf70b513d888cbe71d69ef3829"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classarm__compute_1_1_status.xhtml">Status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacearm__compute_1_1opencl_1_1kernels.xhtml#a70ae61bf70b513d888cbe71d69ef3829">validate_matmul_input_shapes</a> (const <a class="el" href="classarm__compute_1_1_tensor_shape.xhtml">TensorShape</a> &amp;lhs_shape, const <a class="el" href="classarm__compute_1_1_tensor_shape.xhtml">TensorShape</a> &amp;rhs_shape, const <a class="el" href="structarm__compute_1_1_mat_mul_kernel_info.xhtml">MatMulKernelInfo</a> &amp;matmul_kernel_info)</td></tr>
<tr class="memdesc:a70ae61bf70b513d888cbe71d69ef3829"><td class="mdescLeft">&#160;</td><td class="mdescRight">Validate the input shapes of Matmul operation.  <a href="namespacearm__compute_1_1opencl_1_1kernels.xhtml#a70ae61bf70b513d888cbe71d69ef3829">More...</a><br /></td></tr>
<tr class="separator:a70ae61bf70b513d888cbe71d69ef3829"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af0069d1938b4ae83d5ef6bd8ea98a5be"><td class="memItemLeft" align="right" valign="top">std::pair&lt; <a class="el" href="classarm__compute_1_1_status.xhtml">Status</a>, <a class="el" href="classarm__compute_1_1_window.xhtml">Window</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacearm__compute_1_1opencl_1_1kernels.xhtml#af0069d1938b4ae83d5ef6bd8ea98a5be">validate_and_configure_window_for_mmul_kernels</a> (const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *lhs, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *rhs, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *dst, const <a class="el" href="structarm__compute_1_1_mat_mul_kernel_info.xhtml">MatMulKernelInfo</a> &amp;matmul_kernel_info, int mmul_m0, int mmul_n0)</td></tr>
<tr class="memdesc:af0069d1938b4ae83d5ef6bd8ea98a5be"><td class="mdescLeft">&#160;</td><td class="mdescRight">Validate and configure window for Matmul MMUL kernels.  <a href="namespacearm__compute_1_1opencl_1_1kernels.xhtml#af0069d1938b4ae83d5ef6bd8ea98a5be">More...</a><br /></td></tr>
<tr class="separator:af0069d1938b4ae83d5ef6bd8ea98a5be"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="af0069d1938b4ae83d5ef6bd8ea98a5be"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af0069d1938b4ae83d5ef6bd8ea98a5be">&#9670;&nbsp;</a></span>validate_and_configure_window_for_mmul_kernels()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::pair&lt; <a class="el" href="classarm__compute_1_1_status.xhtml">Status</a>, <a class="el" href="classarm__compute_1_1_window.xhtml">Window</a> &gt; validate_and_configure_window_for_mmul_kernels </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>lhs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>rhs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>dst</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structarm__compute_1_1_mat_mul_kernel_info.xhtml">MatMulKernelInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>matmul_kernel_info</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mmul_m0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mmul_n0</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Validate and configure window for Matmul MMUL kernels. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">lhs</td><td>Lhs tensor info </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhs</td><td>Rhs tensor info </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dst</td><td>Dst tensor info </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">matmul_kernel_info</td><td>Matmul kernel info </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">mmul_m0</td><td>Number of rows in the MMUL block </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">mmul_n0</td><td>Number of columns in the MMUL block</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a pair of <a class="el" href="classarm__compute_1_1_status.xhtml" title="Status class.">Status</a> and <a class="el" href="classarm__compute_1_1_window.xhtml" title="Describe a multidimensional execution window.">Window</a> object </dd></dl>

<p class="definition">Definition at line <a class="el" href="_mat_mul_kernel_helpers_8cpp_source.xhtml#l00059">59</a> of file <a class="el" href="_mat_mul_kernel_helpers_8cpp_source.xhtml">MatMulKernelHelpers.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;{</div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;    <a class="code" href="_error_8h.xhtml#a6dc630a6ae9cc063b3924bcea8dee9d6">ARM_COMPUTE_UNUSED</a>(lhs, rhs);</div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160; </div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;    <span class="keyword">const</span> Window win = <a class="code" href="namespacearm__compute.xhtml#aa84c2eae36ca4b68fa36c226df6f94e7">calculate_max_window</a>(*<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#adbf67dcee294e673cf796f1ed8aeb6a4">dst</a>, Steps(1, 1));</div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160; </div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;    <span class="comment">// Collapse along the Z direction</span></div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;    <span class="comment">// This collapse needs to be here in order to tune the Z dimension of LWS</span></div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;    Window collapsed = win.collapse(win, Window::DimZ);</div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160; </div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;    <span class="comment">// Reconfigure window size, one arm_matrix_multiply call needs 16 threads to finish.</span></div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;    Window::Dimension x_dimension = collapsed.x();</div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;    Window::Dimension y_dimension = collapsed.y();</div>
<div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160; </div>
<div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">int</span> m = <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#adbf67dcee294e673cf796f1ed8aeb6a4">dst</a>-&gt;dimension(1);</div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">int</span> n = <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#adbf67dcee294e673cf796f1ed8aeb6a4">dst</a>-&gt;dimension(0);</div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160; </div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">int</span> m0 = std::min(matmul_kernel_info.m0, m);</div>
<div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">int</span> n0 = <a class="code" href="namespacearm__compute.xhtml#a7be62dcb9603165af78bca6f2ca8ec15">adjust_vec_size</a>(matmul_kernel_info.n0, n);</div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160; </div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;    <span class="comment">// Make M and N multiple of M0 and N0 respectively</span></div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> ceil_to_multiple_n_n0 = <a class="code" href="namespacearm__compute.xhtml#ab237a0a375cf382d52b61653248d3d4a">ceil_to_multiple</a>(n, n0);</div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> ceil_to_multiple_m_m0 = <a class="code" href="namespacearm__compute.xhtml#ab237a0a375cf382d52b61653248d3d4a">ceil_to_multiple</a>(m, m0);</div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160; </div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;    <span class="comment">// Divide M and N by M0 and N0 respectively</span></div>
<div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> n_div_n0 = ceil_to_multiple_n_n0 / n0;</div>
<div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> m_div_m0 = ceil_to_multiple_m_m0 / m0;</div>
<div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160; </div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;    <span class="comment">// Make n_div_n0 and m_div_m0 multiple of mmul_n0 and mmul_m0 respectively</span></div>
<div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> ceil_to_multiple_n_div_n0_mmul_n0 = <a class="code" href="namespacearm__compute.xhtml#ab237a0a375cf382d52b61653248d3d4a">ceil_to_multiple</a>(n_div_n0, mmul_n0);</div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> ceil_to_multiple_m_div_m0_mmul_m0 = <a class="code" href="namespacearm__compute.xhtml#ab237a0a375cf382d52b61653248d3d4a">ceil_to_multiple</a>(m_div_m0, mmul_m0);</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160; </div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;    <span class="comment">// Ensure x_dimension is multiple of MMUL block size (mmul_m0 * mmul_n0)</span></div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;    x_dimension.set_end(ceil_to_multiple_n_div_n0_mmul_n0 * mmul_m0);</div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;    y_dimension.set_end(ceil_to_multiple_m_div_m0_mmul_m0 / mmul_m0);</div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160; </div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;    collapsed.set(Window::DimX, x_dimension);</div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;    collapsed.set(Window::DimY, y_dimension);</div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160; </div>
<div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;    <span class="keywordflow">return</span> std::make_pair(Status{}, collapsed);</div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="_adjust_vec_size_8h_source.xhtml#l00038">arm_compute::adjust_vec_size()</a>, <a class="el" href="_error_8h_source.xhtml#l00151">ARM_COMPUTE_UNUSED</a>, <a class="el" href="_window_helpers_8cpp_source.xhtml#l00029">arm_compute::calculate_max_window()</a>, <a class="el" href="arm__compute_2core_2utils_2math_2_math_8h_source.xhtml#l00050">arm_compute::ceil_to_multiple()</a>, <a class="el" href="_window_8inl_source.xhtml#l00125">Window::collapse()</a>, <a class="el" href="_window_8h_source.xhtml#l00043">Window::DimX</a>, <a class="el" href="_window_8h_source.xhtml#l00045">Window::DimY</a>, <a class="el" href="_window_8h_source.xhtml#l00047">Window::DimZ</a>, <a class="el" href="_c_p_p_2_d_f_t_8cpp_source.xhtml#l00170">arm_compute::test::validation::dst</a>, <a class="el" href="_kernel_descriptors_8h_source.xhtml#l00247">MatMulKernelInfo::m0</a>, <a class="el" href="_kernel_descriptors_8h_source.xhtml#l00248">MatMulKernelInfo::n0</a>, <a class="el" href="_window_8inl_source.xhtml#l00053">Window::set()</a>, <a class="el" href="_window_8h_source.xhtml#l00122">Window::Dimension::set_end()</a>, <a class="el" href="_window_8h_source.xhtml#l00158">Window::x()</a>, and <a class="el" href="_window_8h_source.xhtml#l00167">Window::y()</a>.</p>

<p class="reference">Referenced by <a class="el" href="_cl_mat_mul_lowp_native_m_m_u_l_kernel_8cpp_source.xhtml#l00134">ClMatMulLowpNativeMMULKernel::configure()</a>, and <a class="el" href="_cl_mat_mul_native_m_m_u_l_kernel_8cpp_source.xhtml#l00125">ClMatMulNativeMMULKernel::configure()</a>.</p>

</div>
</div>
<a id="a70ae61bf70b513d888cbe71d69ef3829"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a70ae61bf70b513d888cbe71d69ef3829">&#9670;&nbsp;</a></span>validate_matmul_input_shapes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_status.xhtml">Status</a> validate_matmul_input_shapes </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_tensor_shape.xhtml">TensorShape</a> &amp;&#160;</td>
          <td class="paramname"><em>lhs_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_tensor_shape.xhtml">TensorShape</a> &amp;&#160;</td>
          <td class="paramname"><em>rhs_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structarm__compute_1_1_mat_mul_kernel_info.xhtml">MatMulKernelInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>matmul_kernel_info</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Validate the input shapes of Matmul operation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">lhs_shape</td><td>Lhs tensor shape </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhs_shape</td><td>Rhs tensor shape </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">matmul_kernel_info</td><td>Matmul kernel info</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>true if the shapes and matmul kernel info matches </dd></dl>

<p class="definition">Definition at line <a class="el" href="_mat_mul_kernel_helpers_8cpp_source.xhtml#l00039">39</a> of file <a class="el" href="_mat_mul_kernel_helpers_8cpp_source.xhtml">MatMulKernelHelpers.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;{</div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">size_t</span> lhs_k = matmul_kernel_info.adj_lhs ? lhs_shape.y() : lhs_shape.x();</div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">size_t</span> rhs_k = matmul_kernel_info.adj_rhs ? rhs_shape.x() : rhs_shape.y();</div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160; </div>
<div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;    <a class="code" href="_error_8h.xhtml#a1c69762a42ab8add645d0a949b6f4b1f">ARM_COMPUTE_RETURN_ERROR_ON_MSG</a>(lhs_k != rhs_k, <span class="stringliteral">&quot;K dimension in Lhs and Rhs matrices must match.&quot;</span>);</div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;    <a class="code" href="_error_8h.xhtml#a1c69762a42ab8add645d0a949b6f4b1f">ARM_COMPUTE_RETURN_ERROR_ON_MSG</a>(lhs_shape.total_size() == 0, <span class="stringliteral">&quot;Lhs tensor can&#39;t be empty&quot;</span>);</div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;    <a class="code" href="_error_8h.xhtml#a1c69762a42ab8add645d0a949b6f4b1f">ARM_COMPUTE_RETURN_ERROR_ON_MSG</a>(rhs_shape.total_size() == 0, <span class="stringliteral">&quot;Rhs tensor can&#39;t be empty&quot;</span>);</div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160; </div>
<div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;    constexpr <span class="keywordtype">size_t</span> batch_dim_start = 2;</div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = batch_dim_start; i &lt; Coordinates::num_max_dimensions; ++i)</div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;    {</div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;        <a class="code" href="_error_8h.xhtml#a1c69762a42ab8add645d0a949b6f4b1f">ARM_COMPUTE_RETURN_ERROR_ON_MSG</a>(lhs_shape[i] != rhs_shape[i], <span class="stringliteral">&quot;Batch dimension broadcasting is not supported&quot;</span>);</div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;    }</div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160; </div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;    <span class="keywordflow">return</span> Status{};</div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="_kernel_descriptors_8h_source.xhtml#l00245">MatMulKernelInfo::adj_lhs</a>, <a class="el" href="_kernel_descriptors_8h_source.xhtml#l00246">MatMulKernelInfo::adj_rhs</a>, <a class="el" href="_error_8h_source.xhtml#l00245">ARM_COMPUTE_RETURN_ERROR_ON_MSG</a>, <a class="el" href="_dimensions_8h_source.xhtml#l00046">Dimensions&lt; int &gt;::num_max_dimensions</a>, <a class="el" href="_tensor_shape_8h_source.xhtml#l00175">TensorShape::total_size()</a>, <a class="el" href="_dimensions_8h_source.xhtml#l00086">Dimensions&lt; T &gt;::x()</a>, and <a class="el" href="_dimensions_8h_source.xhtml#l00091">Dimensions&lt; T &gt;::y()</a>.</p>

<p class="reference">Referenced by <a class="el" href="_cl_mat_mul_lowp_native_m_m_u_l_kernel_8cpp_source.xhtml#l00092">ClMatMulLowpNativeMMULKernel::validate()</a>, <a class="el" href="_cl_mat_mul_native_kernel_8cpp_source.xhtml#l00114">ClMatMulNativeKernel::validate()</a>, <a class="el" href="_cl_mat_mul_lowp_native_kernel_8cpp_source.xhtml#l00090">ClMatMulLowpNativeKernel::validate()</a>, and <a class="el" href="_cl_mat_mul_native_m_m_u_l_kernel_8cpp_source.xhtml#l00086">ClMatMulNativeMMULKernel::validate()</a>.</p>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<div class="ttc" id="anamespacearm__compute_xhtml_aa84c2eae36ca4b68fa36c226df6f94e7"><div class="ttname"><a href="namespacearm__compute.xhtml#aa84c2eae36ca4b68fa36c226df6f94e7">arm_compute::calculate_max_window</a></div><div class="ttdeci">Window calculate_max_window(const ValidRegion &amp;valid_region, const Steps &amp;steps, bool skip_border, BorderSize border_size)</div><div class="ttdef"><b>Definition:</b> <a href="_window_helpers_8cpp_source.xhtml#l00029">WindowHelpers.cpp:29</a></div></div>
<div class="ttc" id="anamespacearm__compute_1_1test_1_1validation_xhtml_adbf67dcee294e673cf796f1ed8aeb6a4"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#adbf67dcee294e673cf796f1ed8aeb6a4">arm_compute::test::validation::dst</a></div><div class="ttdeci">auto dst</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_p_2_d_f_t_8cpp_source.xhtml#l00170">DFT.cpp:170</a></div></div>
<div class="ttc" id="a_error_8h_xhtml_a6dc630a6ae9cc063b3924bcea8dee9d6"><div class="ttname"><a href="_error_8h.xhtml#a6dc630a6ae9cc063b3924bcea8dee9d6">ARM_COMPUTE_UNUSED</a></div><div class="ttdeci">#define ARM_COMPUTE_UNUSED(...)</div><div class="ttdoc">To avoid unused variables warnings.</div><div class="ttdef"><b>Definition:</b> <a href="_error_8h_source.xhtml#l00151">Error.h:151</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_ab237a0a375cf382d52b61653248d3d4a"><div class="ttname"><a href="namespacearm__compute.xhtml#ab237a0a375cf382d52b61653248d3d4a">arm_compute::ceil_to_multiple</a></div><div class="ttdeci">auto ceil_to_multiple(S value, T divisor) -&gt; decltype(((value+divisor - 1)/divisor) *divisor)</div><div class="ttdoc">Computes the smallest number larger or equal to value that is a multiple of divisor.</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2utils_2math_2_math_8h_source.xhtml#l00050">Math.h:50</a></div></div>
<div class="ttc" id="a_error_8h_xhtml_a1c69762a42ab8add645d0a949b6f4b1f"><div class="ttname"><a href="_error_8h.xhtml#a1c69762a42ab8add645d0a949b6f4b1f">ARM_COMPUTE_RETURN_ERROR_ON_MSG</a></div><div class="ttdeci">#define ARM_COMPUTE_RETURN_ERROR_ON_MSG(cond, msg)</div><div class="ttdoc">If the condition is true, an error is returned.</div><div class="ttdef"><b>Definition:</b> <a href="_error_8h_source.xhtml#l00245">Error.h:245</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_a7be62dcb9603165af78bca6f2ca8ec15"><div class="ttname"><a href="namespacearm__compute.xhtml#a7be62dcb9603165af78bca6f2ca8ec15">arm_compute::adjust_vec_size</a></div><div class="ttdeci">unsigned int adjust_vec_size(unsigned int vec_size, size_t dim0)</div><div class="ttdoc">Returns the adjusted vector size in case it is less than the input's first dimension,...</div><div class="ttdef"><b>Definition:</b> <a href="_adjust_vec_size_8h_source.xhtml#l00038">AdjustVecSize.h:38</a></div></div>
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacearm__compute.xhtml">arm_compute</a></li><li class="navelem"><a class="el" href="namespacearm__compute_1_1opencl.xhtml">opencl</a></li><li class="navelem"><a class="el" href="namespacearm__compute_1_1opencl_1_1kernels.xhtml">kernels</a></li>
    <li class="footer">Generated on Wed Feb 14 2024 11:15:06 for Compute Library by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.17 </li>
  </ul>
</div>
</body>
</html>
