<!-- HTML header for doxygen 1.8.15-->
<!-- Remember to use version doxygen 1.8.15 +-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="robots" content="NOINDEX, NOFOLLOW" /> <!-- Prevent indexing by search engines -->
<title>Compute Library: NERNNLayer Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <img alt="Compute Library" src="https://raw.githubusercontent.com/ARM-software/ComputeLibrary/gh-pages/ACL_logo.png" style="max-width: 100%;margin-top: 15px;margin-left: 10px"/>
  <td style="padding-left: 0.5em;">
   <div id="projectname">
   &#160;<span id="projectnumber">24.07</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('classarm__compute_1_1_n_e_r_n_n_layer.xhtml',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a>  </div>
  <div class="headertitle">
<div class="title">NERNNLayer Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Basic function to run <a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a>.  
 <a href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_n_e_r_n_n_layer_8h_source.xhtml">NERNNLayer.h</a>&gt;</code></p>
<div class="dynheader">
Collaboration diagram for NERNNLayer:</div>
<div class="dyncontent">
<div class="center"><iframe scrolling="no" frameborder="0" src="classarm__compute_1_1_n_e_r_n_n_layer__coll__graph.svg" width="116" height="112"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe>
</div>
<center><span class="legend">[<a target="top" href="graph_legend.xhtml">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a22580824d9d7f1d67c3db8ac601113b3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#a22580824d9d7f1d67c3db8ac601113b3">NERNNLayer</a> (std::shared_ptr&lt; <a class="el" href="classarm__compute_1_1_i_memory_manager.xhtml">IMemoryManager</a> &gt; memory_manager=nullptr)</td></tr>
<tr class="memdesc:a22580824d9d7f1d67c3db8ac601113b3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Default constructor.  <a href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#a22580824d9d7f1d67c3db8ac601113b3">More...</a><br /></td></tr>
<tr class="separator:a22580824d9d7f1d67c3db8ac601113b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab6231543c4071f67f7acd1b868017185"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#ab6231543c4071f67f7acd1b868017185">NERNNLayer</a> (const <a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a> &amp;)=delete</td></tr>
<tr class="memdesc:ab6231543c4071f67f7acd1b868017185"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prevent instances of this class from being copied (As this class contains pointers)  <a href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#ab6231543c4071f67f7acd1b868017185">More...</a><br /></td></tr>
<tr class="separator:ab6231543c4071f67f7acd1b868017185"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a00ca57617711b4ff918f5a1a6f207b23"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#a00ca57617711b4ff918f5a1a6f207b23">NERNNLayer</a> (<a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a> &amp;&amp;)=delete</td></tr>
<tr class="memdesc:a00ca57617711b4ff918f5a1a6f207b23"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prevent instances of this class from being moved (As this class contains pointers)  <a href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#a00ca57617711b4ff918f5a1a6f207b23">More...</a><br /></td></tr>
<tr class="separator:a00ca57617711b4ff918f5a1a6f207b23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae2d47df9fdf935549764571144c6c1c1"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#ae2d47df9fdf935549764571144c6c1c1">operator=</a> (const <a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a> &amp;)=delete</td></tr>
<tr class="memdesc:ae2d47df9fdf935549764571144c6c1c1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prevent instances of this class from being copied (As this class contains pointers)  <a href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#ae2d47df9fdf935549764571144c6c1c1">More...</a><br /></td></tr>
<tr class="separator:ae2d47df9fdf935549764571144c6c1c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2d44b100f05844ddff2d4da3e813236a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#a2d44b100f05844ddff2d4da3e813236a">operator=</a> (<a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a> &amp;&amp;)=delete</td></tr>
<tr class="memdesc:a2d44b100f05844ddff2d4da3e813236a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prevent instances of this class from being moved (As this class contains pointers)  <a href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#a2d44b100f05844ddff2d4da3e813236a">More...</a><br /></td></tr>
<tr class="separator:a2d44b100f05844ddff2d4da3e813236a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ca75767d8151217c3e5b28203acf7bd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#a9ca75767d8151217c3e5b28203acf7bd">~NERNNLayer</a> ()</td></tr>
<tr class="memdesc:a9ca75767d8151217c3e5b28203acf7bd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Default destructor.  <a href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#a9ca75767d8151217c3e5b28203acf7bd">More...</a><br /></td></tr>
<tr class="separator:a9ca75767d8151217c3e5b28203acf7bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a23ed39a3f37b8b100cec84427d55f9cf"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#a23ed39a3f37b8b100cec84427d55f9cf">configure</a> (const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *input, const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *weights, const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *recurrent_weights, const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *<a class="el" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>, <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *hidden_state, <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *output, <a class="el" href="classarm__compute_1_1_activation_layer_info.xhtml">ActivationLayerInfo</a> &amp;info)</td></tr>
<tr class="memdesc:a23ed39a3f37b8b100cec84427d55f9cf"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initialize the function.  <a href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#a23ed39a3f37b8b100cec84427d55f9cf">More...</a><br /></td></tr>
<tr class="separator:a23ed39a3f37b8b100cec84427d55f9cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad1717410afd0be936c6213a63c8005fb"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#ad1717410afd0be936c6213a63c8005fb">run</a> () override</td></tr>
<tr class="memdesc:ad1717410afd0be936c6213a63c8005fb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Run the kernels contained in the function.  <a href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#ad1717410afd0be936c6213a63c8005fb">More...</a><br /></td></tr>
<tr class="separator:ad1717410afd0be936c6213a63c8005fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9b93ef660fc3c5b4b19d3fc7b891b77"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#aa9b93ef660fc3c5b4b19d3fc7b891b77">prepare</a> () override</td></tr>
<tr class="memdesc:aa9b93ef660fc3c5b4b19d3fc7b891b77"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prepare the function for executing.  <a href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#aa9b93ef660fc3c5b4b19d3fc7b891b77">More...</a><br /></td></tr>
<tr class="separator:aa9b93ef660fc3c5b4b19d3fc7b891b77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classarm__compute_1_1_i_function"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classarm__compute_1_1_i_function')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classarm__compute_1_1_i_function.xhtml">IFunction</a></td></tr>
<tr class="memitem:ab921ecc3f3f6ae2b4bd61f3e1998d8c4 inherit pub_methods_classarm__compute_1_1_i_function"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_function.xhtml#ab921ecc3f3f6ae2b4bd61f3e1998d8c4">~IFunction</a> ()=default</td></tr>
<tr class="memdesc:ab921ecc3f3f6ae2b4bd61f3e1998d8c4 inherit pub_methods_classarm__compute_1_1_i_function"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destructor.  <a href="classarm__compute_1_1_i_function.xhtml#ab921ecc3f3f6ae2b4bd61f3e1998d8c4">More...</a><br /></td></tr>
<tr class="separator:ab921ecc3f3f6ae2b4bd61f3e1998d8c4 inherit pub_methods_classarm__compute_1_1_i_function"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:a25cb8dc27e1dcd3cf00e930ae01ba97e"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="classarm__compute_1_1_status.xhtml">Status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#a25cb8dc27e1dcd3cf00e930ae01ba97e">validate</a> (const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *input, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *weights, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *recurrent_weights, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *<a class="el" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *hidden_state, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *output, const <a class="el" href="classarm__compute_1_1_activation_layer_info.xhtml">ActivationLayerInfo</a> &amp;info)</td></tr>
<tr class="memdesc:a25cb8dc27e1dcd3cf00e930ae01ba97e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initialize the function.  <a href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#a25cb8dc27e1dcd3cf00e930ae01ba97e">More...</a><br /></td></tr>
<tr class="separator:a25cb8dc27e1dcd3cf00e930ae01ba97e"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Basic function to run <a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a>. </p>

<p class="definition">Definition at line <a class="el" href="_n_e_r_n_n_layer_8h_source.xhtml#l00040">40</a> of file <a class="el" href="_n_e_r_n_n_layer_8h_source.xhtml">NERNNLayer.h</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a22580824d9d7f1d67c3db8ac601113b3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a22580824d9d7f1d67c3db8ac601113b3">&#9670;&nbsp;</a></span>NERNNLayer() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a> </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classarm__compute_1_1_i_memory_manager.xhtml">IMemoryManager</a> &gt;&#160;</td>
          <td class="paramname"><em>memory_manager</em> = <code>nullptr</code></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Default constructor. </p>

<p class="definition">Definition at line <a class="el" href="_n_e_r_n_n_layer_8cpp_source.xhtml#l00040">40</a> of file <a class="el" href="_n_e_r_n_n_layer_8cpp_source.xhtml">NERNNLayer.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;    : _memory_group(std::move(memory_manager)),</div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;      _gemm_state_f(),</div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;      _add_f(),</div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;      _activation(),</div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;      _fully_connected(memory_manager),</div>
<div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;      _copy_f(),</div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;      _fully_connected_out(),</div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;      _gemm_output(),</div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;      _add_output(),</div>
<div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;      _is_prepared(<span class="keyword">false</span>)</div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;{</div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;}</div>
</div><!-- fragment -->
</div>
</div>
<a id="ab6231543c4071f67f7acd1b868017185"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab6231543c4071f67f7acd1b868017185">&#9670;&nbsp;</a></span>NERNNLayer() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a> </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a> &amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">delete</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Prevent instances of this class from being copied (As this class contains pointers) </p>

</div>
</div>
<a id="a00ca57617711b4ff918f5a1a6f207b23"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a00ca57617711b4ff918f5a1a6f207b23">&#9670;&nbsp;</a></span>NERNNLayer() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a> </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a> &amp;&amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">delete</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Prevent instances of this class from being moved (As this class contains pointers) </p>

</div>
</div>
<a id="a9ca75767d8151217c3e5b28203acf7bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9ca75767d8151217c3e5b28203acf7bd">&#9670;&nbsp;</a></span>~NERNNLayer()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">~<a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">default</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Default destructor. </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a23ed39a3f37b8b100cec84427d55f9cf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a23ed39a3f37b8b100cec84427d55f9cf">&#9670;&nbsp;</a></span>configure()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void configure </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>recurrent_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>hidden_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_activation_layer_info.xhtml">ActivationLayerInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>info</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Initialize the function. </p>
<p>Valid data layouts:</p><ul>
<li>NHWC</li>
<li>NCHW</li>
</ul>
<p>Valid data type configurations: </p><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">src0 </th><th class="markdownTableHeadLeft">src1 </th><th class="markdownTableHeadLeft">src2 </th><th class="markdownTableHeadLeft">src3 </th><th class="markdownTableHeadLeft">dst0 </th><th class="markdownTableHeadLeft">dst1  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">F16 </td><td class="markdownTableBodyLeft">F16 </td><td class="markdownTableBodyLeft">F16 </td><td class="markdownTableBodyLeft">F16 </td><td class="markdownTableBodyLeft">F16 </td><td class="markdownTableBodyLeft">F16  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">F32 </td><td class="markdownTableBodyLeft">F32 </td><td class="markdownTableBodyLeft">F32 </td><td class="markdownTableBodyLeft">F32 </td><td class="markdownTableBodyLeft">F32 </td><td class="markdownTableBodyLeft">F32  </td></tr>
</table>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">input</td><td>Input is a 2-D tensor of shape [input_size, batch_size]. Data types supported: F16/F32 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">weights</td><td>Weights tensor of shape [input_size, num_units] that multiplies the input. Data types supported: Same as <code>input</code> </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">recurrent_weights</td><td>Weights tensor of shape [num_units, num_units] that multiplies the current 'state'. Data types supported: Same as <code>input</code> </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>Bias vector of shape [num_units]. Data types supported: Same as <code>input</code> </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output</td><td>Output tensor of shape [num_units, batch_size]. Data types supported: Same as <code>input</code> </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">hidden_state</td><td>Output tensor of shape [num_units, batch_size]. Data types supported: Same as <code>input</code> </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">info</td><td>Activation layer parameter. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="_n_e_r_n_n_layer_8cpp_source.xhtml#l00089">89</a> of file <a class="el" href="_n_e_r_n_n_layer_8cpp_source.xhtml">NERNNLayer.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;{</div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;    <a class="code" href="arm__compute_2core_2_validate_8h.xhtml#a921b705e9e3e0fe928928447869e62a5">ARM_COMPUTE_ERROR_ON_NULLPTR</a>(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>, weights, recurrent_weights, <a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>, hidden_state, output);</div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;    <a class="code" href="_error_8h.xhtml#a938dcd406ce611ef5345ad2531cdb948">ARM_COMPUTE_ERROR_THROW_ON</a>(<a class="code" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#a25cb8dc27e1dcd3cf00e930ae01ba97e">NERNNLayer::validate</a>(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>-&gt;info(), weights-&gt;info(), recurrent_weights-&gt;info(),</div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;                                                    <a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>-&gt;info(), hidden_state-&gt;info(), output-&gt;info(), <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#ac57b92957968088a392021cac1d2076b">info</a>));</div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;    <a class="code" href="src_2common_2utils_2_log_8h.xhtml#a3ae35e22a098d589ff54ed85647ed87e">ARM_COMPUTE_LOG_PARAMS</a>(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>, weights, recurrent_weights, <a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>, hidden_state, output, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#ac57b92957968088a392021cac1d2076b">info</a>);</div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160; </div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">int</span>   <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#abb9f749a8ea92dda58cc0881b1450158">idx_height</a> = <a class="code" href="namespacearm__compute.xhtml#adfef6f05588c3d40195488620ab54b97">get_data_layout_dimension_index</a>(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>-&gt;info()-&gt;data_layout(), <a class="code" href="namespacearm__compute.xhtml#a74ce3f7420453d3446218ff3b7453e02ad770ba3ce18fa409965dfdf5e7c348e6">DataLayoutDimension::HEIGHT</a>);</div>
<div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;    TensorShape <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a45cde9abb508c62d67c3bb2b9bf566a5">shape</a>      = <a class="code" href="namespacearm__compute_1_1misc_1_1shape__calculator.xhtml#af98bc3ef5c65dbb63bc79700ccdd043b">misc::shape_calculator::compute_rnn_shape</a>(recurrent_weights-&gt;info(),</div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;                                                                       hidden_state-&gt;info()-&gt;dimension(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#abb9f749a8ea92dda58cc0881b1450158">idx_height</a>));</div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160; </div>
<div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;    _is_prepared = <span class="keyword">false</span>;</div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160; </div>
<div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;    <span class="comment">// Manage intermediate buffers and configure</span></div>
<div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;    _fully_connected_out.<a class="code" href="classarm__compute_1_1_tensor.xhtml#adbd0cf83a8e1b335a9bf405a8e5019fa">allocator</a>()-&gt;<a class="code" href="classarm__compute_1_1_tensor_allocator.xhtml#a3fc6adad84b23f10d54d5a7b6928f872">init</a>(TensorInfo(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a45cde9abb508c62d67c3bb2b9bf566a5">shape</a>, 1, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>-&gt;info()-&gt;data_type()));</div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;    _gemm_output.<a class="code" href="classarm__compute_1_1_tensor.xhtml#adbd0cf83a8e1b335a9bf405a8e5019fa">allocator</a>()-&gt;<a class="code" href="classarm__compute_1_1_tensor_allocator.xhtml#a3fc6adad84b23f10d54d5a7b6928f872">init</a>(TensorInfo(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a45cde9abb508c62d67c3bb2b9bf566a5">shape</a>, 1, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>-&gt;info()-&gt;data_type()));</div>
<div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160; </div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;    <span class="comment">// Manage intermediate buffers and configure</span></div>
<div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;    _memory_group.<a class="code" href="classarm__compute_1_1_memory_group.xhtml#a6fc0a49304c152c20a0f6df0634fb3cd">manage</a>(&amp;_fully_connected_out);</div>
<div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;    _fully_connected.<a class="code" href="classarm__compute_1_1_n_e_fully_connected_layer.xhtml#a515c4425ecd8385cf757e0a9187a1304">configure</a>(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>, weights, <a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>, &amp;_fully_connected_out);</div>
<div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160; </div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;    _memory_group.<a class="code" href="classarm__compute_1_1_memory_group.xhtml#a6fc0a49304c152c20a0f6df0634fb3cd">manage</a>(&amp;_gemm_output);</div>
<div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;    _gemm_state_f.<a class="code" href="classarm__compute_1_1_n_e_g_e_m_m.xhtml#a385241dcc5062af6ecac8bdafe01bb2a">configure</a>(hidden_state, recurrent_weights, <span class="keyword">nullptr</span>, &amp;_gemm_output, 1.f, 0.f);</div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160; </div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;    _add_output.<a class="code" href="classarm__compute_1_1_tensor.xhtml#adbd0cf83a8e1b335a9bf405a8e5019fa">allocator</a>()-&gt;<a class="code" href="classarm__compute_1_1_tensor_allocator.xhtml#a3fc6adad84b23f10d54d5a7b6928f872">init</a>(TensorInfo(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a45cde9abb508c62d67c3bb2b9bf566a5">shape</a>, 1, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>-&gt;info()-&gt;data_type()));</div>
<div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;    _memory_group.<a class="code" href="classarm__compute_1_1_memory_group.xhtml#a6fc0a49304c152c20a0f6df0634fb3cd">manage</a>(&amp;_add_output);</div>
<div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160; </div>
<div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;    _add_f.<a class="code" href="classarm__compute_1_1_n_e_arithmetic_addition.xhtml#aa6cd3281fb8cd7ee2a724ca5fcefb695">configure</a>(&amp;_fully_connected_out, &amp;_gemm_output, &amp;_add_output, <a class="code" href="namespacearm__compute.xhtml#a82b8ac759c804bc1fb4e2d21e178fb6fa4729d95f983955f0d93a30179deb2b86">ConvertPolicy::SATURATE</a>);</div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160; </div>
<div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;    _fully_connected_out.<a class="code" href="classarm__compute_1_1_tensor.xhtml#adbd0cf83a8e1b335a9bf405a8e5019fa">allocator</a>()-&gt;<a class="code" href="classarm__compute_1_1_tensor_allocator.xhtml#a6e509c2a177b0b29e9e2369535094dee">allocate</a>();</div>
<div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;    _gemm_output.<a class="code" href="classarm__compute_1_1_tensor.xhtml#adbd0cf83a8e1b335a9bf405a8e5019fa">allocator</a>()-&gt;<a class="code" href="classarm__compute_1_1_tensor_allocator.xhtml#a6e509c2a177b0b29e9e2369535094dee">allocate</a>();</div>
<div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160; </div>
<div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;    _activation.<a class="code" href="classarm__compute_1_1_n_e_activation_layer.xhtml#adfb5ef37594fc9371c4a2b95e3d5e31b">configure</a>(&amp;_add_output, hidden_state, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#ac57b92957968088a392021cac1d2076b">info</a>);</div>
<div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;    _add_output.<a class="code" href="classarm__compute_1_1_tensor.xhtml#adbd0cf83a8e1b335a9bf405a8e5019fa">allocator</a>()-&gt;<a class="code" href="classarm__compute_1_1_tensor_allocator.xhtml#a6e509c2a177b0b29e9e2369535094dee">allocate</a>();</div>
<div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160; </div>
<div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;    _copy_f.<a class="code" href="classarm__compute_1_1_n_e_copy.xhtml#a9daf8026e68559806afe7d0aa12693d6">configure</a>(hidden_state, output);</div>
<div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="src_2runtime_2_tensor_allocator_8cpp_source.xhtml#l00133">TensorAllocator::allocate()</a>, <a class="el" href="src_2runtime_2_tensor_8cpp_source.xhtml#l00047">Tensor::allocator()</a>, <a class="el" href="arm__compute_2core_2_validate_8h_source.xhtml#l00159">ARM_COMPUTE_ERROR_ON_NULLPTR</a>, <a class="el" href="_error_8h_source.xhtml#l00455">ARM_COMPUTE_ERROR_THROW_ON</a>, <a class="el" href="src_2common_2utils_2_log_8h_source.xhtml#l00035">ARM_COMPUTE_LOG_PARAMS</a>, <a class="el" href="working__space_8hpp_source.xhtml#l00322">bias</a>, <a class="el" href="_shape_calculator_8h_source.xhtml#l00970">arm_compute::misc::shape_calculator::compute_rnn_shape()</a>, <a class="el" href="_n_e_copy_8cpp_source.xhtml#l00048">NECopy::configure()</a>, <a class="el" href="_n_e_arithmetic_addition_8cpp_source.xhtml#l00058">NEArithmeticAddition::configure()</a>, <a class="el" href="_n_e_g_e_m_m_8cpp_source.xhtml#l00065">NEGEMM::configure()</a>, <a class="el" href="_n_e_activation_layer_8cpp_source.xhtml#l00048">NEActivationLayer::configure()</a>, <a class="el" href="_n_e_fully_connected_layer_8cpp_source.xhtml#l00066">NEFullyConnectedLayer::configure()</a>, <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml#a178f0d3d87f959e00a743328d95359d2">ITensorInfo::dimension()</a>, <a class="el" href="_helpers_8inl_source.xhtml#l00201">arm_compute::get_data_layout_dimension_index()</a>, <a class="el" href="namespacearm__compute.xhtml#a74ce3f7420453d3446218ff3b7453e02ad770ba3ce18fa409965dfdf5e7c348e6">arm_compute::HEIGHT</a>, <a class="el" href="validation_2_n_e_o_n_2_scale_8cpp_source.xhtml#l00263">arm_compute::test::validation::idx_height</a>, <a class="el" href="classarm__compute_1_1_i_tensor.xhtml#a0e95dc1e53c361348314873b168ae237">ITensor::info()</a>, <a class="el" href="namespacearm__compute_1_1test_1_1validation.xhtml#ac57b92957968088a392021cac1d2076b">arm_compute::test::validation::info</a>, <a class="el" href="src_2runtime_2_tensor_allocator_8cpp_source.xhtml#l00106">TensorAllocator::init()</a>, <a class="el" href="_c_l_2_l_s_t_m_layer_quantized_8cpp_source.xhtml#l00486">arm_compute::test::validation::input</a>, <a class="el" href="_memory_group_8h_source.xhtml#l00076">MemoryGroup::manage()</a>, <a class="el" href="namespacearm__compute.xhtml#a82b8ac759c804bc1fb4e2d21e178fb6fa4729d95f983955f0d93a30179deb2b86">arm_compute::SATURATE</a>, <a class="el" href="_c_p_p_2_d_f_t_8cpp_source.xhtml#l00115">arm_compute::test::validation::shape</a>, and <a class="el" href="_n_e_r_n_n_layer_8cpp_source.xhtml#l00054">NERNNLayer::validate()</a>.</p>

</div>
</div>
<a id="ae2d47df9fdf935549764571144c6c1c1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae2d47df9fdf935549764571144c6c1c1">&#9670;&nbsp;</a></span>operator=() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a>&amp; operator= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a> &amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">delete</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Prevent instances of this class from being copied (As this class contains pointers) </p>

</div>
</div>
<a id="a2d44b100f05844ddff2d4da3e813236a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2d44b100f05844ddff2d4da3e813236a">&#9670;&nbsp;</a></span>operator=() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a>&amp; operator= </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a> &amp;&amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">delete</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Prevent instances of this class from being moved (As this class contains pointers) </p>

</div>
</div>
<a id="aa9b93ef660fc3c5b4b19d3fc7b891b77"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa9b93ef660fc3c5b4b19d3fc7b891b77">&#9670;&nbsp;</a></span>prepare()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void prepare </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Prepare the function for executing. </p>
<p>Any one off pre-processing step required by the function is handled here</p>
<dl class="section note"><dt>Note</dt><dd>Prepare stage might not need all the function's buffers' backing memory to be available in order to execute </dd></dl>

<p>Reimplemented from <a class="el" href="classarm__compute_1_1_i_function.xhtml#a820f7291c24155a2980512fae45aac26">IFunction</a>.</p>

<p class="definition">Definition at line <a class="el" href="_n_e_r_n_n_layer_8cpp_source.xhtml#l00150">150</a> of file <a class="el" href="_n_e_r_n_n_layer_8cpp_source.xhtml">NERNNLayer.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;{</div>
<div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;    <span class="keywordflow">if</span> (!_is_prepared)</div>
<div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;    {</div>
<div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;        _fully_connected.<a class="code" href="classarm__compute_1_1_n_e_fully_connected_layer.xhtml#aa9b93ef660fc3c5b4b19d3fc7b891b77">prepare</a>();</div>
<div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;        _gemm_state_f.<a class="code" href="classarm__compute_1_1_n_e_g_e_m_m.xhtml#aa9b93ef660fc3c5b4b19d3fc7b891b77">prepare</a>();</div>
<div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160; </div>
<div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;        _is_prepared = <span class="keyword">true</span>;</div>
<div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;    }</div>
<div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="_n_e_g_e_m_m_8cpp_source.xhtml#l00138">NEGEMM::prepare()</a>, and <a class="el" href="_n_e_fully_connected_layer_8cpp_source.xhtml#l00134">NEFullyConnectedLayer::prepare()</a>.</p>

<p class="reference">Referenced by <a class="el" href="_n_e_r_n_n_layer_8cpp_source.xhtml#l00133">NERNNLayer::run()</a>.</p>

</div>
</div>
<a id="ad1717410afd0be936c6213a63c8005fb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad1717410afd0be936c6213a63c8005fb">&#9670;&nbsp;</a></span>run()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void run </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Run the kernels contained in the function. </p>
<p>For CPU kernels:</p><ul>
<li>Multi-threading is used for the kernels which are parallelisable.</li>
<li>By default std::thread::hardware_concurrency() threads are used.</li>
</ul>
<dl class="section note"><dt>Note</dt><dd><a class="el" href="classarm__compute_1_1_c_p_p_scheduler.xhtml#ae64eebaa07f4d2da6cc2ba538c3cb095">CPPScheduler::set_num_threads()</a> can be used to manually set the number of threads</dd></dl>
<p>For OpenCL kernels:</p><ul>
<li>All the kernels are enqueued on the queue associated with <a class="el" href="classarm__compute_1_1_c_l_scheduler.xhtml" title="Provides global access to a CL context and command queue.">CLScheduler</a>.</li>
<li>The queue is then flushed.</li>
</ul>
<dl class="section note"><dt>Note</dt><dd>The function will not block until the kernels are executed. It is the user's responsibility to wait. </dd>
<dd>
Will call <a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#aa9b93ef660fc3c5b4b19d3fc7b891b77" title="Prepare the function for executing.">prepare()</a> on first run if hasn't been done </dd></dl>

<p>Implements <a class="el" href="classarm__compute_1_1_i_function.xhtml#a18954417d3124a8095783ea13dc6d00b">IFunction</a>.</p>

<p class="definition">Definition at line <a class="el" href="_n_e_r_n_n_layer_8cpp_source.xhtml#l00133">133</a> of file <a class="el" href="_n_e_r_n_n_layer_8cpp_source.xhtml">NERNNLayer.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;{</div>
<div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;    <a class="code" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#aa9b93ef660fc3c5b4b19d3fc7b891b77">prepare</a>();</div>
<div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160; </div>
<div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;    MemoryGroupResourceScope scope_mg(_memory_group);</div>
<div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160; </div>
<div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;    _fully_connected.<a class="code" href="classarm__compute_1_1_n_e_fully_connected_layer.xhtml#ad1717410afd0be936c6213a63c8005fb">run</a>();</div>
<div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160; </div>
<div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;    _gemm_state_f.<a class="code" href="classarm__compute_1_1_n_e_g_e_m_m.xhtml#ad1717410afd0be936c6213a63c8005fb">run</a>();</div>
<div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160; </div>
<div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;    _add_f.<a class="code" href="classarm__compute_1_1_n_e_arithmetic_addition.xhtml#ad1717410afd0be936c6213a63c8005fb">run</a>();</div>
<div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;    _activation.<a class="code" href="classarm__compute_1_1_n_e_activation_layer.xhtml#ad1717410afd0be936c6213a63c8005fb">run</a>();</div>
<div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160; </div>
<div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;    <span class="comment">// copy hidden out to output</span></div>
<div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;    _copy_f.<a class="code" href="classarm__compute_1_1_n_e_copy.xhtml#ad1717410afd0be936c6213a63c8005fb">run</a>();</div>
<div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="_n_e_r_n_n_layer_8cpp_source.xhtml#l00150">NERNNLayer::prepare()</a>, <a class="el" href="_n_e_copy_8cpp_source.xhtml#l00066">NECopy::run()</a>, <a class="el" href="_n_e_activation_layer_8cpp_source.xhtml#l00065">NEActivationLayer::run()</a>, <a class="el" href="_n_e_arithmetic_addition_8cpp_source.xhtml#l00071">NEArithmeticAddition::run()</a>, <a class="el" href="_n_e_g_e_m_m_8cpp_source.xhtml#l00130">NEGEMM::run()</a>, and <a class="el" href="_n_e_fully_connected_layer_8cpp_source.xhtml#l00123">NEFullyConnectedLayer::run()</a>.</p>

</div>
</div>
<a id="a25cb8dc27e1dcd3cf00e930ae01ba97e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a25cb8dc27e1dcd3cf00e930ae01ba97e">&#9670;&nbsp;</a></span>validate()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_status.xhtml">Status</a> validate </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>recurrent_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>hidden_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_activation_layer_info.xhtml">ActivationLayerInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>info</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Initialize the function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">input</td><td>Input is a 2-D tensor of shape [input_size, batch_size]. Data types supported: F16/F32 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">weights</td><td>Weights tensor of shape [input_size, num_units] that multiplies the input. Data types supported: Same as <code>input</code> </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">recurrent_weights</td><td>Weights tensor of shape [num_units, num_units] that multiplies the current 'state'. Data types supported: Same as <code>input</code> </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>Bias vector of shape [num_units]. Data types supported: Same as <code>input</code> </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">output</td><td>Output tensor of shape [num_units, batch_size]. Data types supported: Same as <code>input</code> </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">hidden_state</td><td>Output tensor of shape [num_units, batch_size]. Data types supported: Same as <code>input</code> </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">info</td><td>Activation layer parameter.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a status </dd></dl>

<p class="definition">Definition at line <a class="el" href="_n_e_r_n_n_layer_8cpp_source.xhtml#l00054">54</a> of file <a class="el" href="_n_e_r_n_n_layer_8cpp_source.xhtml">NERNNLayer.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;{</div>
<div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;    <a class="code" href="arm__compute_2core_2_validate_8h.xhtml#aff911654521523937ff24372a870b89f">ARM_COMPUTE_RETURN_ERROR_ON_NULLPTR</a>(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>, weights, recurrent_weights, <a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>, hidden_state, output);</div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;    <a class="code" href="arm__compute_2core_2_validate_8h.xhtml#aef783de4ec01874dbec6054a5868aea2">ARM_COMPUTE_RETURN_ERROR_ON_DATA_TYPE_NOT_IN</a>(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>, <a class="code" href="namespacearm__compute.xhtml#ad8ed01ff3ff33333d8e19db4d2818bb6a56d8353718e6fdc78b8d69078a2cdb94">DataType::F16</a>, <a class="code" href="namespacearm__compute.xhtml#ad8ed01ff3ff33333d8e19db4d2818bb6a44ad4ef5a76e6aa6fb3e3fa079a54fda">DataType::F32</a>);</div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160; </div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">int</span> <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#ac354c23c8e4921ea8a8ad07e1a1d3fe5">idx_width</a>  = <a class="code" href="namespacearm__compute.xhtml#adfef6f05588c3d40195488620ab54b97">get_data_layout_dimension_index</a>(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>-&gt;data_layout(), <a class="code" href="namespacearm__compute.xhtml#a74ce3f7420453d3446218ff3b7453e02a49da85b69bc6285eeee286ca49fa7195">DataLayoutDimension::WIDTH</a>);</div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">int</span> <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#abb9f749a8ea92dda58cc0881b1450158">idx_height</a> = <a class="code" href="namespacearm__compute.xhtml#adfef6f05588c3d40195488620ab54b97">get_data_layout_dimension_index</a>(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>-&gt;data_layout(), <a class="code" href="namespacearm__compute.xhtml#a74ce3f7420453d3446218ff3b7453e02ad770ba3ce18fa409965dfdf5e7c348e6">DataLayoutDimension::HEIGHT</a>);</div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;    <a class="code" href="_error_8h.xhtml#a206d6e247e0957ac3dee45d27756fc25">ARM_COMPUTE_RETURN_ERROR_ON</a>(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>-&gt;dimension(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#ac354c23c8e4921ea8a8ad07e1a1d3fe5">idx_width</a>) != weights-&gt;dimension(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#ac354c23c8e4921ea8a8ad07e1a1d3fe5">idx_width</a>));</div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;    <a class="code" href="_error_8h.xhtml#a206d6e247e0957ac3dee45d27756fc25">ARM_COMPUTE_RETURN_ERROR_ON</a>(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>-&gt;num_dimensions() != 2);</div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;    <a class="code" href="_error_8h.xhtml#a206d6e247e0957ac3dee45d27756fc25">ARM_COMPUTE_RETURN_ERROR_ON</a>(weights-&gt;dimension(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#abb9f749a8ea92dda58cc0881b1450158">idx_height</a>) != recurrent_weights-&gt;dimension(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#ac354c23c8e4921ea8a8ad07e1a1d3fe5">idx_width</a>));</div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;    <a class="code" href="_error_8h.xhtml#a206d6e247e0957ac3dee45d27756fc25">ARM_COMPUTE_RETURN_ERROR_ON</a>(recurrent_weights-&gt;dimension(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#ac354c23c8e4921ea8a8ad07e1a1d3fe5">idx_width</a>) != recurrent_weights-&gt;dimension(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#abb9f749a8ea92dda58cc0881b1450158">idx_height</a>));</div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;    <a class="code" href="_error_8h.xhtml#a206d6e247e0957ac3dee45d27756fc25">ARM_COMPUTE_RETURN_ERROR_ON</a>(<a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>-&gt;num_dimensions() != 1);</div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;    <a class="code" href="_error_8h.xhtml#a206d6e247e0957ac3dee45d27756fc25">ARM_COMPUTE_RETURN_ERROR_ON</a>(<a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>-&gt;dimension(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#ac354c23c8e4921ea8a8ad07e1a1d3fe5">idx_width</a>) != weights-&gt;dimension(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#abb9f749a8ea92dda58cc0881b1450158">idx_height</a>));</div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;    <a class="code" href="_error_8h.xhtml#a206d6e247e0957ac3dee45d27756fc25">ARM_COMPUTE_RETURN_ERROR_ON</a>(hidden_state-&gt;dimension(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#ac354c23c8e4921ea8a8ad07e1a1d3fe5">idx_width</a>) != weights-&gt;dimension(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#abb9f749a8ea92dda58cc0881b1450158">idx_height</a>));</div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;    <a class="code" href="_error_8h.xhtml#a206d6e247e0957ac3dee45d27756fc25">ARM_COMPUTE_RETURN_ERROR_ON</a>(hidden_state-&gt;dimension(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#abb9f749a8ea92dda58cc0881b1450158">idx_height</a>) != <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>-&gt;dimension(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#abb9f749a8ea92dda58cc0881b1450158">idx_height</a>));</div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;    <a class="code" href="arm__compute_2core_2_validate_8h.xhtml#a1da797d2762c1cdbb73bfc83136c3a38">ARM_COMPUTE_RETURN_ERROR_ON_MISMATCHING_DIMENSIONS</a>(output-&gt;tensor_shape(), hidden_state-&gt;tensor_shape());</div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160; </div>
<div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;    <span class="keyword">auto</span> shape_info =</div>
<div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;        TensorInfo(<a class="code" href="namespacearm__compute_1_1misc_1_1shape__calculator.xhtml#af98bc3ef5c65dbb63bc79700ccdd043b">misc::shape_calculator::compute_rnn_shape</a>(recurrent_weights, hidden_state-&gt;dimension(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#abb9f749a8ea92dda58cc0881b1450158">idx_height</a>)), 1,</div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;                   <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>-&gt;data_type());</div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160; </div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;    <a class="code" href="_error_8h.xhtml#a8a1e1c105f0bdaf37db408c7cfcb77a4">ARM_COMPUTE_RETURN_ON_ERROR</a>(<a class="code" href="classarm__compute_1_1_n_e_fully_connected_layer.xhtml#a0364e410dbd9c0d7f95536203002f81f">NEFullyConnectedLayer::validate</a>(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">input</a>, weights, <a class="code" href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a>, &amp;shape_info));</div>
<div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;    <a class="code" href="_error_8h.xhtml#a8a1e1c105f0bdaf37db408c7cfcb77a4">ARM_COMPUTE_RETURN_ON_ERROR</a>(</div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;        <a class="code" href="classarm__compute_1_1_n_e_arithmetic_addition.xhtml#a5d4d1bdc6b902a7075b6850977a9ba7c">NEArithmeticAddition::validate</a>(&amp;shape_info, &amp;shape_info, &amp;shape_info, <a class="code" href="namespacearm__compute.xhtml#a82b8ac759c804bc1fb4e2d21e178fb6fa4729d95f983955f0d93a30179deb2b86">ConvertPolicy::SATURATE</a>));</div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;    <a class="code" href="_error_8h.xhtml#a8a1e1c105f0bdaf37db408c7cfcb77a4">ARM_COMPUTE_RETURN_ON_ERROR</a>(<a class="code" href="classarm__compute_1_1_n_e_activation_layer.xhtml#aa37e2d0b4cd4f835bfa2a2df4a0bdd2c">NEActivationLayer::validate</a>(&amp;shape_info, &amp;shape_info, <a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#ac57b92957968088a392021cac1d2076b">info</a>));</div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160; </div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;    <span class="keywordflow">return</span> Status{};</div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="_error_8h_source.xhtml#l00298">ARM_COMPUTE_RETURN_ERROR_ON</a>, <a class="el" href="arm__compute_2core_2_validate_8h_source.xhtml#l00838">ARM_COMPUTE_RETURN_ERROR_ON_DATA_TYPE_NOT_IN</a>, <a class="el" href="arm__compute_2core_2_validate_8h_source.xhtml#l00294">ARM_COMPUTE_RETURN_ERROR_ON_MISMATCHING_DIMENSIONS</a>, <a class="el" href="arm__compute_2core_2_validate_8h_source.xhtml#l00161">ARM_COMPUTE_RETURN_ERROR_ON_NULLPTR</a>, <a class="el" href="_error_8h_source.xhtml#l00205">ARM_COMPUTE_RETURN_ON_ERROR</a>, <a class="el" href="working__space_8hpp_source.xhtml#l00322">bias</a>, <a class="el" href="_shape_calculator_8h_source.xhtml#l00970">arm_compute::misc::shape_calculator::compute_rnn_shape()</a>, <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml#a178f0d3d87f959e00a743328d95359d2">ITensorInfo::dimension()</a>, <a class="el" href="namespacearm__compute.xhtml#ad8ed01ff3ff33333d8e19db4d2818bb6a56d8353718e6fdc78b8d69078a2cdb94">arm_compute::F16</a>, <a class="el" href="namespacearm__compute.xhtml#ad8ed01ff3ff33333d8e19db4d2818bb6a44ad4ef5a76e6aa6fb3e3fa079a54fda">arm_compute::F32</a>, <a class="el" href="_helpers_8inl_source.xhtml#l00201">arm_compute::get_data_layout_dimension_index()</a>, <a class="el" href="namespacearm__compute.xhtml#a74ce3f7420453d3446218ff3b7453e02ad770ba3ce18fa409965dfdf5e7c348e6">arm_compute::HEIGHT</a>, <a class="el" href="validation_2_n_e_o_n_2_scale_8cpp_source.xhtml#l00263">arm_compute::test::validation::idx_height</a>, <a class="el" href="validation_2_n_e_o_n_2_scale_8cpp_source.xhtml#l00262">arm_compute::test::validation::idx_width</a>, <a class="el" href="namespacearm__compute_1_1test_1_1validation.xhtml#ac57b92957968088a392021cac1d2076b">arm_compute::test::validation::info</a>, <a class="el" href="_c_l_2_l_s_t_m_layer_quantized_8cpp_source.xhtml#l00486">arm_compute::test::validation::input</a>, <a class="el" href="namespacearm__compute.xhtml#a82b8ac759c804bc1fb4e2d21e178fb6fa4729d95f983955f0d93a30179deb2b86">arm_compute::SATURATE</a>, <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml#a7c66505457d00ece3aa4b34cab80757d">ITensorInfo::tensor_shape()</a>, <a class="el" href="_n_e_arithmetic_addition_8cpp_source.xhtml#l00049">NEArithmeticAddition::validate()</a>, <a class="el" href="_n_e_activation_layer_8cpp_source.xhtml#l00060">NEActivationLayer::validate()</a>, <a class="el" href="_n_e_fully_connected_layer_8cpp_source.xhtml#l00113">NEFullyConnectedLayer::validate()</a>, and <a class="el" href="namespacearm__compute.xhtml#a74ce3f7420453d3446218ff3b7453e02a49da85b69bc6285eeee286ca49fa7195">arm_compute::WIDTH</a>.</p>

<p class="reference">Referenced by <a class="el" href="_n_e_r_n_n_layer_8cpp_source.xhtml#l00089">NERNNLayer::configure()</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>arm_compute/runtime/NEON/functions/<a class="el" href="_n_e_r_n_n_layer_8h_source.xhtml">NERNNLayer.h</a></li>
<li>src/runtime/NEON/functions/<a class="el" href="_n_e_r_n_n_layer_8cpp_source.xhtml">NERNNLayer.cpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<div class="ttc" id="aclassarm__compute_1_1_n_e_arithmetic_addition_xhtml_aa6cd3281fb8cd7ee2a724ca5fcefb695"><div class="ttname"><a href="classarm__compute_1_1_n_e_arithmetic_addition.xhtml#aa6cd3281fb8cd7ee2a724ca5fcefb695">arm_compute::NEArithmeticAddition::configure</a></div><div class="ttdeci">void configure(const ITensor *input1, const ITensor *input2, ITensor *output, ConvertPolicy policy, const ActivationLayerInfo &amp;act_info=ActivationLayerInfo())</div><div class="ttdoc">Initialise the kernel's inputs, output and conversion policy.</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_arithmetic_addition_8cpp_source.xhtml#l00058">NEArithmeticAddition.cpp:58</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_g_e_m_m_xhtml_ad1717410afd0be936c6213a63c8005fb"><div class="ttname"><a href="classarm__compute_1_1_n_e_g_e_m_m.xhtml#ad1717410afd0be936c6213a63c8005fb">arm_compute::NEGEMM::run</a></div><div class="ttdeci">void run() override</div><div class="ttdoc">Run the kernels contained in the function.</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_g_e_m_m_8cpp_source.xhtml#l00130">NEGEMM.cpp:130</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_memory_group_xhtml_a6fc0a49304c152c20a0f6df0634fb3cd"><div class="ttname"><a href="classarm__compute_1_1_memory_group.xhtml#a6fc0a49304c152c20a0f6df0634fb3cd">arm_compute::MemoryGroup::manage</a></div><div class="ttdeci">void manage(IMemoryManageable *obj) override</div><div class="ttdoc">Sets a object to be managed by the given memory group.</div><div class="ttdef"><b>Definition:</b> <a href="_memory_group_8h_source.xhtml#l00076">MemoryGroup.h:76</a></div></div>
<div class="ttc" id="anamespacearm__compute_1_1test_1_1validation_xhtml_abb9f749a8ea92dda58cc0881b1450158"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#abb9f749a8ea92dda58cc0881b1450158">arm_compute::test::validation::idx_height</a></div><div class="ttdeci">const int idx_height</div><div class="ttdef"><b>Definition:</b> <a href="validation_2_n_e_o_n_2_scale_8cpp_source.xhtml#l00263">Scale.cpp:263</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_tensor_allocator_xhtml_a3fc6adad84b23f10d54d5a7b6928f872"><div class="ttname"><a href="classarm__compute_1_1_tensor_allocator.xhtml#a3fc6adad84b23f10d54d5a7b6928f872">arm_compute::TensorAllocator::init</a></div><div class="ttdeci">void init(const TensorAllocator &amp;allocator, const Coordinates &amp;coords, TensorInfo &amp;sub_info)</div><div class="ttdoc">Shares the same backing memory with another tensor allocator, while the tensor info might be differen...</div><div class="ttdef"><b>Definition:</b> <a href="src_2runtime_2_tensor_allocator_8cpp_source.xhtml#l00106">TensorAllocator.cpp:106</a></div></div>
<div class="ttc" id="anamespacearm__compute_1_1test_1_1validation_xhtml_ac354c23c8e4921ea8a8ad07e1a1d3fe5"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#ac354c23c8e4921ea8a8ad07e1a1d3fe5">arm_compute::test::validation::idx_width</a></div><div class="ttdeci">const int idx_width</div><div class="ttdef"><b>Definition:</b> <a href="validation_2_n_e_o_n_2_scale_8cpp_source.xhtml#l00262">Scale.cpp:262</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_a74ce3f7420453d3446218ff3b7453e02a49da85b69bc6285eeee286ca49fa7195"><div class="ttname"><a href="namespacearm__compute.xhtml#a74ce3f7420453d3446218ff3b7453e02a49da85b69bc6285eeee286ca49fa7195">arm_compute::DataLayoutDimension::WIDTH</a></div><div class="ttdeci">@ WIDTH</div><div class="ttdoc">width</div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_g_e_m_m_xhtml_a385241dcc5062af6ecac8bdafe01bb2a"><div class="ttname"><a href="classarm__compute_1_1_n_e_g_e_m_m.xhtml#a385241dcc5062af6ecac8bdafe01bb2a">arm_compute::NEGEMM::configure</a></div><div class="ttdeci">void configure(const ITensor *a, const ITensor *b, const ITensor *c, ITensor *d, float alpha, float beta, const GEMMInfo &amp;gemm_info=GEMMInfo())</div><div class="ttdoc">Initialise the kernel's inputs, output.</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_g_e_m_m_8cpp_source.xhtml#l00065">NEGEMM.cpp:65</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_r_n_n_layer_xhtml_aa9b93ef660fc3c5b4b19d3fc7b891b77"><div class="ttname"><a href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#aa9b93ef660fc3c5b4b19d3fc7b891b77">arm_compute::NERNNLayer::prepare</a></div><div class="ttdeci">void prepare() override</div><div class="ttdoc">Prepare the function for executing.</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_r_n_n_layer_8cpp_source.xhtml#l00150">NERNNLayer.cpp:150</a></div></div>
<div class="ttc" id="a_error_8h_xhtml_a8a1e1c105f0bdaf37db408c7cfcb77a4"><div class="ttname"><a href="_error_8h.xhtml#a8a1e1c105f0bdaf37db408c7cfcb77a4">ARM_COMPUTE_RETURN_ON_ERROR</a></div><div class="ttdeci">#define ARM_COMPUTE_RETURN_ON_ERROR(status)</div><div class="ttdoc">Checks if a status contains an error and returns it.</div><div class="ttdef"><b>Definition:</b> <a href="_error_8h_source.xhtml#l00205">Error.h:205</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_activation_layer_xhtml_aa37e2d0b4cd4f835bfa2a2df4a0bdd2c"><div class="ttname"><a href="classarm__compute_1_1_n_e_activation_layer.xhtml#aa37e2d0b4cd4f835bfa2a2df4a0bdd2c">arm_compute::NEActivationLayer::validate</a></div><div class="ttdeci">static Status validate(const ITensorInfo *input, const ITensorInfo *output, const ActivationLayerInfo &amp;act_info)</div><div class="ttdoc">[NEActivationLayer snippet]</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_activation_layer_8cpp_source.xhtml#l00060">NEActivationLayer.cpp:60</a></div></div>
<div class="ttc" id="aarm__compute_2core_2_validate_8h_xhtml_a921b705e9e3e0fe928928447869e62a5"><div class="ttname"><a href="arm__compute_2core_2_validate_8h.xhtml#a921b705e9e3e0fe928928447869e62a5">ARM_COMPUTE_ERROR_ON_NULLPTR</a></div><div class="ttdeci">#define ARM_COMPUTE_ERROR_ON_NULLPTR(...)</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2_validate_8h_source.xhtml#l00159">Validate.h:159</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_fully_connected_layer_xhtml_aa9b93ef660fc3c5b4b19d3fc7b891b77"><div class="ttname"><a href="classarm__compute_1_1_n_e_fully_connected_layer.xhtml#aa9b93ef660fc3c5b4b19d3fc7b891b77">arm_compute::NEFullyConnectedLayer::prepare</a></div><div class="ttdeci">void prepare() override</div><div class="ttdoc">Prepare the function for executing.</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_fully_connected_layer_8cpp_source.xhtml#l00134">NEFullyConnectedLayer.cpp:134</a></div></div>
<div class="ttc" id="anamespacearm__compute_1_1test_1_1validation_xhtml_a45cde9abb508c62d67c3bb2b9bf566a5"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#a45cde9abb508c62d67c3bb2b9bf566a5">arm_compute::test::validation::shape</a></div><div class="ttdeci">shape</div><div class="ttdef"><b>Definition:</b> <a href="_c_p_p_2_d_f_t_8cpp_source.xhtml#l00115">DFT.cpp:115</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_activation_layer_xhtml_adfb5ef37594fc9371c4a2b95e3d5e31b"><div class="ttname"><a href="classarm__compute_1_1_n_e_activation_layer.xhtml#adfb5ef37594fc9371c4a2b95e3d5e31b">arm_compute::NEActivationLayer::configure</a></div><div class="ttdeci">void configure(ITensor *input, ITensor *output, ActivationLayerInfo activation_info)</div><div class="ttdoc">[NEActivationLayer snippet]</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_activation_layer_8cpp_source.xhtml#l00048">NEActivationLayer.cpp:48</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_tensor_xhtml_adbd0cf83a8e1b335a9bf405a8e5019fa"><div class="ttname"><a href="classarm__compute_1_1_tensor.xhtml#adbd0cf83a8e1b335a9bf405a8e5019fa">arm_compute::Tensor::allocator</a></div><div class="ttdeci">TensorAllocator * allocator()</div><div class="ttdoc">Return a pointer to the tensor's allocator.</div><div class="ttdef"><b>Definition:</b> <a href="src_2runtime_2_tensor_8cpp_source.xhtml#l00047">Tensor.cpp:47</a></div></div>
<div class="ttc" id="a_error_8h_xhtml_a938dcd406ce611ef5345ad2531cdb948"><div class="ttname"><a href="_error_8h.xhtml#a938dcd406ce611ef5345ad2531cdb948">ARM_COMPUTE_ERROR_THROW_ON</a></div><div class="ttdeci">#define ARM_COMPUTE_ERROR_THROW_ON(status)</div><div class="ttdef"><b>Definition:</b> <a href="_error_8h_source.xhtml#l00455">Error.h:455</a></div></div>
<div class="ttc" id="anamespacearm__compute_1_1misc_1_1shape__calculator_xhtml_af98bc3ef5c65dbb63bc79700ccdd043b"><div class="ttname"><a href="namespacearm__compute_1_1misc_1_1shape__calculator.xhtml#af98bc3ef5c65dbb63bc79700ccdd043b">arm_compute::misc::shape_calculator::compute_rnn_shape</a></div><div class="ttdeci">TensorShape compute_rnn_shape(const ITensorInfo *input, const unsigned int batch_size)</div><div class="ttdoc">Calculate the RNN shape of a tensor.</div><div class="ttdef"><b>Definition:</b> <a href="_shape_calculator_8h_source.xhtml#l00970">ShapeCalculator.h:970</a></div></div>
<div class="ttc" id="aarm__compute_2core_2_validate_8h_xhtml_aef783de4ec01874dbec6054a5868aea2"><div class="ttname"><a href="arm__compute_2core_2_validate_8h.xhtml#aef783de4ec01874dbec6054a5868aea2">ARM_COMPUTE_RETURN_ERROR_ON_DATA_TYPE_NOT_IN</a></div><div class="ttdeci">#define ARM_COMPUTE_RETURN_ERROR_ON_DATA_TYPE_NOT_IN(t,...)</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2_validate_8h_source.xhtml#l00838">Validate.h:838</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_a74ce3f7420453d3446218ff3b7453e02ad770ba3ce18fa409965dfdf5e7c348e6"><div class="ttname"><a href="namespacearm__compute.xhtml#a74ce3f7420453d3446218ff3b7453e02ad770ba3ce18fa409965dfdf5e7c348e6">arm_compute::DataLayoutDimension::HEIGHT</a></div><div class="ttdeci">@ HEIGHT</div><div class="ttdoc">height</div></div>
<div class="ttc" id="a_error_8h_xhtml_a206d6e247e0957ac3dee45d27756fc25"><div class="ttname"><a href="_error_8h.xhtml#a206d6e247e0957ac3dee45d27756fc25">ARM_COMPUTE_RETURN_ERROR_ON</a></div><div class="ttdeci">#define ARM_COMPUTE_RETURN_ERROR_ON(cond)</div><div class="ttdoc">If the condition is true, an error is returned.</div><div class="ttdef"><b>Definition:</b> <a href="_error_8h_source.xhtml#l00298">Error.h:298</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_fully_connected_layer_xhtml_a515c4425ecd8385cf757e0a9187a1304"><div class="ttname"><a href="classarm__compute_1_1_n_e_fully_connected_layer.xhtml#a515c4425ecd8385cf757e0a9187a1304">arm_compute::NEFullyConnectedLayer::configure</a></div><div class="ttdeci">void configure(const ITensor *input, const ITensor *weights, const ITensor *biases, ITensor *output, FullyConnectedLayerInfo fc_info=FullyConnectedLayerInfo(), const WeightsInfo &amp;weights_info=WeightsInfo())</div><div class="ttdoc">Set the input and output tensors.</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_fully_connected_layer_8cpp_source.xhtml#l00066">NEFullyConnectedLayer.cpp:66</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_arithmetic_addition_xhtml_ad1717410afd0be936c6213a63c8005fb"><div class="ttname"><a href="classarm__compute_1_1_n_e_arithmetic_addition.xhtml#ad1717410afd0be936c6213a63c8005fb">arm_compute::NEArithmeticAddition::run</a></div><div class="ttdeci">void run() override</div><div class="ttdoc">Run the kernels contained in the function.</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_arithmetic_addition_8cpp_source.xhtml#l00071">NEArithmeticAddition.cpp:71</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_a82b8ac759c804bc1fb4e2d21e178fb6fa4729d95f983955f0d93a30179deb2b86"><div class="ttname"><a href="namespacearm__compute.xhtml#a82b8ac759c804bc1fb4e2d21e178fb6fa4729d95f983955f0d93a30179deb2b86">arm_compute::ConvertPolicy::SATURATE</a></div><div class="ttdeci">@ SATURATE</div><div class="ttdoc">Saturate.</div></div>
<div class="ttc" id="aworking__space_8hpp_xhtml_a1fb7b822a92dd3ab6e7ab15c67b0ff9e"><div class="ttname"><a href="working__space_8hpp.xhtml#a1fb7b822a92dd3ab6e7ab15c67b0ff9e">bias</a></div><div class="ttdeci">const int32_t * bias</div><div class="ttdef"><b>Definition:</b> <a href="working__space_8hpp_source.xhtml#l00322">working_space.hpp:322</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_fully_connected_layer_xhtml_ad1717410afd0be936c6213a63c8005fb"><div class="ttname"><a href="classarm__compute_1_1_n_e_fully_connected_layer.xhtml#ad1717410afd0be936c6213a63c8005fb">arm_compute::NEFullyConnectedLayer::run</a></div><div class="ttdeci">void run() override</div><div class="ttdoc">Run the kernels contained in the function.</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_fully_connected_layer_8cpp_source.xhtml#l00123">NEFullyConnectedLayer.cpp:123</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_arithmetic_addition_xhtml_a5d4d1bdc6b902a7075b6850977a9ba7c"><div class="ttname"><a href="classarm__compute_1_1_n_e_arithmetic_addition.xhtml#a5d4d1bdc6b902a7075b6850977a9ba7c">arm_compute::NEArithmeticAddition::validate</a></div><div class="ttdeci">static Status validate(const ITensorInfo *input1, const ITensorInfo *input2, const ITensorInfo *output, ConvertPolicy policy, const ActivationLayerInfo &amp;act_info=ActivationLayerInfo())</div><div class="ttdoc">Static function to check if given info will lead to a valid configuration of NEArithmeticAddition.</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_arithmetic_addition_8cpp_source.xhtml#l00049">NEArithmeticAddition.cpp:49</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_adfef6f05588c3d40195488620ab54b97"><div class="ttname"><a href="namespacearm__compute.xhtml#adfef6f05588c3d40195488620ab54b97">arm_compute::get_data_layout_dimension_index</a></div><div class="ttdeci">size_t get_data_layout_dimension_index(const DataLayout &amp;data_layout, const DataLayoutDimension &amp;data_layout_dimension)</div><div class="ttdoc">Get the index of the given dimension.</div><div class="ttdef"><b>Definition:</b> <a href="_helpers_8inl_source.xhtml#l00201">Helpers.inl:201</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_copy_xhtml_a9daf8026e68559806afe7d0aa12693d6"><div class="ttname"><a href="classarm__compute_1_1_n_e_copy.xhtml#a9daf8026e68559806afe7d0aa12693d6">arm_compute::NECopy::configure</a></div><div class="ttdeci">void configure(ITensor *input, ITensor *output)</div><div class="ttdoc">Initialise the function's source and destination.</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_copy_8cpp_source.xhtml#l00048">NECopy.cpp:48</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_tensor_allocator_xhtml_a6e509c2a177b0b29e9e2369535094dee"><div class="ttname"><a href="classarm__compute_1_1_tensor_allocator.xhtml#a6e509c2a177b0b29e9e2369535094dee">arm_compute::TensorAllocator::allocate</a></div><div class="ttdeci">void allocate() override</div><div class="ttdoc">Allocate size specified by TensorInfo of CPU memory.</div><div class="ttdef"><b>Definition:</b> <a href="src_2runtime_2_tensor_allocator_8cpp_source.xhtml#l00133">TensorAllocator.cpp:133</a></div></div>
<div class="ttc" id="aarm__compute_2core_2_validate_8h_xhtml_a1da797d2762c1cdbb73bfc83136c3a38"><div class="ttname"><a href="arm__compute_2core_2_validate_8h.xhtml#a1da797d2762c1cdbb73bfc83136c3a38">ARM_COMPUTE_RETURN_ERROR_ON_MISMATCHING_DIMENSIONS</a></div><div class="ttdeci">#define ARM_COMPUTE_RETURN_ERROR_ON_MISMATCHING_DIMENSIONS(...)</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2_validate_8h_source.xhtml#l00294">Validate.h:294</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_ad8ed01ff3ff33333d8e19db4d2818bb6a56d8353718e6fdc78b8d69078a2cdb94"><div class="ttname"><a href="namespacearm__compute.xhtml#ad8ed01ff3ff33333d8e19db4d2818bb6a56d8353718e6fdc78b8d69078a2cdb94">arm_compute::DataType::F16</a></div><div class="ttdeci">@ F16</div><div class="ttdoc">16-bit floating-point number</div></div>
<div class="ttc" id="aarm__compute_2core_2_validate_8h_xhtml_aff911654521523937ff24372a870b89f"><div class="ttname"><a href="arm__compute_2core_2_validate_8h.xhtml#aff911654521523937ff24372a870b89f">ARM_COMPUTE_RETURN_ERROR_ON_NULLPTR</a></div><div class="ttdeci">#define ARM_COMPUTE_RETURN_ERROR_ON_NULLPTR(...)</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2_validate_8h_source.xhtml#l00161">Validate.h:161</a></div></div>
<div class="ttc" id="anamespacearm__compute_xhtml_ad8ed01ff3ff33333d8e19db4d2818bb6a44ad4ef5a76e6aa6fb3e3fa079a54fda"><div class="ttname"><a href="namespacearm__compute.xhtml#ad8ed01ff3ff33333d8e19db4d2818bb6a44ad4ef5a76e6aa6fb3e3fa079a54fda">arm_compute::DataType::F32</a></div><div class="ttdeci">@ F32</div><div class="ttdoc">32-bit floating-point number</div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_copy_xhtml_ad1717410afd0be936c6213a63c8005fb"><div class="ttname"><a href="classarm__compute_1_1_n_e_copy.xhtml#ad1717410afd0be936c6213a63c8005fb">arm_compute::NECopy::run</a></div><div class="ttdeci">void run() override</div><div class="ttdoc">Run the kernels contained in the function.</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_copy_8cpp_source.xhtml#l00066">NECopy.cpp:66</a></div></div>
<div class="ttc" id="anamespacearm__compute_1_1test_1_1validation_xhtml_ac57b92957968088a392021cac1d2076b"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#ac57b92957968088a392021cac1d2076b">arm_compute::test::validation::info</a></div><div class="ttdeci">ScaleKernelInfo info(interpolation_policy, default_border_mode, PixelValue(), sampling_policy, false)</div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_activation_layer_xhtml_ad1717410afd0be936c6213a63c8005fb"><div class="ttname"><a href="classarm__compute_1_1_n_e_activation_layer.xhtml#ad1717410afd0be936c6213a63c8005fb">arm_compute::NEActivationLayer::run</a></div><div class="ttdeci">void run() override</div><div class="ttdoc">Run the kernels contained in the function.</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_activation_layer_8cpp_source.xhtml#l00065">NEActivationLayer.cpp:65</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_fully_connected_layer_xhtml_a0364e410dbd9c0d7f95536203002f81f"><div class="ttname"><a href="classarm__compute_1_1_n_e_fully_connected_layer.xhtml#a0364e410dbd9c0d7f95536203002f81f">arm_compute::NEFullyConnectedLayer::validate</a></div><div class="ttdeci">static Status validate(const ITensorInfo *input, const ITensorInfo *weights, const ITensorInfo *biases, const ITensorInfo *output, FullyConnectedLayerInfo fc_info=FullyConnectedLayerInfo(), const WeightsInfo &amp;weights_info=WeightsInfo())</div><div class="ttdoc">Static function to check if given info will lead to a valid configuration of NEFullyConnectedLayer.</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_fully_connected_layer_8cpp_source.xhtml#l00113">NEFullyConnectedLayer.cpp:113</a></div></div>
<div class="ttc" id="asrc_2common_2utils_2_log_8h_xhtml_a3ae35e22a098d589ff54ed85647ed87e"><div class="ttname"><a href="src_2common_2utils_2_log_8h.xhtml#a3ae35e22a098d589ff54ed85647ed87e">ARM_COMPUTE_LOG_PARAMS</a></div><div class="ttdeci">#define ARM_COMPUTE_LOG_PARAMS(...)</div><div class="ttdef"><b>Definition:</b> <a href="src_2common_2utils_2_log_8h_source.xhtml#l00035">Log.h:35</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_g_e_m_m_xhtml_aa9b93ef660fc3c5b4b19d3fc7b891b77"><div class="ttname"><a href="classarm__compute_1_1_n_e_g_e_m_m.xhtml#aa9b93ef660fc3c5b4b19d3fc7b891b77">arm_compute::NEGEMM::prepare</a></div><div class="ttdeci">void prepare() override</div><div class="ttdoc">Prepare the function for executing.</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_g_e_m_m_8cpp_source.xhtml#l00138">NEGEMM.cpp:138</a></div></div>
<div class="ttc" id="anamespacearm__compute_1_1test_1_1validation_xhtml_a8fcf2ddd9a1d58b1b280f5c0aed71845"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#a8fcf2ddd9a1d58b1b280f5c0aed71845">arm_compute::test::validation::input</a></div><div class="ttdeci">auto input</div><div class="ttdef"><b>Definition:</b> <a href="_c_l_2_l_s_t_m_layer_quantized_8cpp_source.xhtml#l00486">LSTMLayerQuantized.cpp:486</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_r_n_n_layer_xhtml_a25cb8dc27e1dcd3cf00e930ae01ba97e"><div class="ttname"><a href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml#a25cb8dc27e1dcd3cf00e930ae01ba97e">arm_compute::NERNNLayer::validate</a></div><div class="ttdeci">static Status validate(const ITensorInfo *input, const ITensorInfo *weights, const ITensorInfo *recurrent_weights, const ITensorInfo *bias, const ITensorInfo *hidden_state, const ITensorInfo *output, const ActivationLayerInfo &amp;info)</div><div class="ttdoc">Initialize the function.</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_r_n_n_layer_8cpp_source.xhtml#l00054">NERNNLayer.cpp:54</a></div></div>
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacearm__compute.xhtml">arm_compute</a></li><li class="navelem"><a class="el" href="classarm__compute_1_1_n_e_r_n_n_layer.xhtml">NERNNLayer</a></li>
    <li class="footer">Generated on Fri Jul 26 2024 12:08:32 for Compute Library by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.17 </li>
  </ul>
</div>
</body>
</html>
