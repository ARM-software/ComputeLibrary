<!-- HTML header for doxygen 1.8.15-->
<!-- Remember to use version doxygen 1.8.15 +-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="robots" content="NOINDEX, NOFOLLOW" /> <!-- Prevent indexing by search engines -->
<title>Compute Library: Advanced</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <img alt="Compute Library" src="https://raw.githubusercontent.com/ARM-software/ComputeLibrary/gh-pages/ACL_logo.png" style="max-width: 100%;margin-top: 15px;margin-left: 10px"/>
  <td style="padding-left: 0.5em;">
   <div id="projectname">
   &#160;<span id="projectnumber">23.02.1</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('advanced.xhtml','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Advanced </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#S1_8_cl_tuner">OpenCL Tuner</a><ul><li class="level2"><a href="#S1_8_1_cl_tuner_how_to">How to use it</a></li>
</ul>
</li>
<li class="level1"><a href="#Security">Concerns</a><ul><li class="level2"><a href="#A">process running under the same uid could read another process memory</a></li>
<li class="level2"><a href="#Malicious">users could alter Compute Library related files</a></li>
<li class="level2"><a href="#Various">concerns</a></li>
</ul>
</li>
</ul>
</div>
<div class="textblock"><h1><a class="anchor" id="S1_8_cl_tuner"></a>
OpenCL Tuner</h1>
<p>The OpenCL tuner, a.k.a. <a class="el" href="classarm__compute_1_1_c_l_tuner.xhtml" title="Basic implementation of the OpenCL tuner interface. ">CLTuner</a>, is a module of Arm Compute Library that can improve the performance of the OpenCL kernels tuning the Local-Workgroup-Size (LWS). The optimal LWS for each unique OpenCL kernel configuration is stored in a table. This table can be either imported or exported from/to a file. The OpenCL tuner runs the same OpenCL kernel for a range of local workgroup sizes and keeps the local workgroup size of the fastest run to use in subsequent calls to the kernel. It supports three modes of tuning with different trade-offs between the time taken to tune and the kernel execution time achieved using the best LWS found. In the Exhaustive mode, it searches all the supported values of LWS. This mode takes the longest time to tune and is the most likely to find the optimal LWS. Normal mode searches a subset of LWS values to yield a good approximation of the optimal LWS. It takes less time to tune than Exhaustive mode. Rapid mode takes the shortest time to tune and finds an LWS value that is at least as good or better than the default LWS value. The mode affects only the search for the optimal LWS and has no effect when the LWS value is imported from a file. In order for the performance numbers to be meaningful you must disable the GPU power management and set it to a fixed frequency for the entire duration of the tuning phase.</p>
<p>If you wish to know more about LWS and the important role on improving the GPU cache utilization, we suggest having a look at the presentation "Even Faster CNNs: Exploring the New Class of Winograd Algorithms available at the following link:</p>
<p><a href="https://www.embedded-vision.com/platinum-members/arm/embedded-vision-training/videos/pages/may-2018-embedded-vision-summit-iodice">https://www.embedded-vision.com/platinum-members/arm/embedded-vision-training/videos/pages/may-2018-embedded-vision-summit-iodice</a></p>
<p>Tuning a network from scratch can be long and affect considerably the execution time for the first run of your network. It is recommended for this reason to store the <a class="el" href="classarm__compute_1_1_c_l_tuner.xhtml" title="Basic implementation of the OpenCL tuner interface. ">CLTuner</a>'s result in a file to amortize this time when you either re-use the same network or the functions with the same configurations. The tuning is performed only once for each OpenCL kernel.</p>
<p><a class="el" href="classarm__compute_1_1_c_l_tuner.xhtml" title="Basic implementation of the OpenCL tuner interface. ">CLTuner</a> looks for the optimal LWS for each unique OpenCL kernel configuration. Since a function (i.e. Convolution Layer, Pooling Layer, Fully Connected Layer ...) can be called multiple times but with different parameters, we associate an "id" (called "config_id") to each kernel to distinguish the unique configurations. </p><pre class="fragment">#Example: 2 unique Matrix Multiply configurations
</pre> <div class="fragment"><div class="line">TensorShape a0 = TensorShape(32,32);</div><div class="line">TensorShape b0 = TensorShape(32,32);</div><div class="line">TensorShape c0 = TensorShape(32,32);</div><div class="line">TensorShape a1 = TensorShape(64,64);</div><div class="line">TensorShape b1 = TensorShape(64,64);</div><div class="line">TensorShape c1 = TensorShape(64,64);</div><div class="line"></div><div class="line"><a class="code" href="namespacearm__compute_1_1detail.xhtml#a2c0ee4eb5bed32d6fb8358d113995aa4af20fc369b14cb5d40e695dab98bcb742">Tensor</a> a0_tensor;</div><div class="line"><a class="code" href="namespacearm__compute_1_1detail.xhtml#a2c0ee4eb5bed32d6fb8358d113995aa4af20fc369b14cb5d40e695dab98bcb742">Tensor</a> b0_tensor;</div><div class="line"><a class="code" href="namespacearm__compute_1_1detail.xhtml#a2c0ee4eb5bed32d6fb8358d113995aa4af20fc369b14cb5d40e695dab98bcb742">Tensor</a> c0_tensor;</div><div class="line"><a class="code" href="namespacearm__compute_1_1detail.xhtml#a2c0ee4eb5bed32d6fb8358d113995aa4af20fc369b14cb5d40e695dab98bcb742">Tensor</a> a1_tensor;</div><div class="line"><a class="code" href="namespacearm__compute_1_1detail.xhtml#a2c0ee4eb5bed32d6fb8358d113995aa4af20fc369b14cb5d40e695dab98bcb742">Tensor</a> b1_tensor;</div><div class="line"><a class="code" href="namespacearm__compute_1_1detail.xhtml#a2c0ee4eb5bed32d6fb8358d113995aa4af20fc369b14cb5d40e695dab98bcb742">Tensor</a> c1_tensor;</div><div class="line"></div><div class="line">a0_tensor.allocator()-&gt;init(TensorInfo(a0, 1, <a class="code" href="namespacearm__compute.xhtml#ab4e88c89b3b7ea1735996cc4def22d58a44ad4ef5a76e6aa6fb3e3fa079a54fda">DataType::F32</a>));</div><div class="line">b0_tensor.allocator()-&gt;init(TensorInfo(b0, 1, <a class="code" href="namespacearm__compute.xhtml#ab4e88c89b3b7ea1735996cc4def22d58a44ad4ef5a76e6aa6fb3e3fa079a54fda">DataType::F32</a>));</div><div class="line">c0_tensor.allocator()-&gt;init(TensorInfo(c0, 1, <a class="code" href="namespacearm__compute.xhtml#ab4e88c89b3b7ea1735996cc4def22d58a44ad4ef5a76e6aa6fb3e3fa079a54fda">DataType::F32</a>));</div><div class="line">a1_tensor.allocator()-&gt;init(TensorInfo(a1, 1, <a class="code" href="namespacearm__compute.xhtml#ab4e88c89b3b7ea1735996cc4def22d58a44ad4ef5a76e6aa6fb3e3fa079a54fda">DataType::F32</a>));</div><div class="line">b1_tensor.allocator()-&gt;init(TensorInfo(b1, 1, <a class="code" href="namespacearm__compute.xhtml#ab4e88c89b3b7ea1735996cc4def22d58a44ad4ef5a76e6aa6fb3e3fa079a54fda">DataType::F32</a>));</div><div class="line">c1_tensor.allocator()-&gt;init(TensorInfo(c1 1, <a class="code" href="namespacearm__compute.xhtml#ab4e88c89b3b7ea1735996cc4def22d58a44ad4ef5a76e6aa6fb3e3fa079a54fda">DataType::F32</a>));</div><div class="line"></div><div class="line">CLGEMM gemm0;</div><div class="line">CLGEMM gemm1;</div><div class="line"></div><div class="line"><span class="comment">// Configuration 0</span></div><div class="line">gemm0.configure(&amp;a0, &amp;b0, <span class="keyword">nullptr</span>, &amp;c0, 1.0f, 0.0f);</div><div class="line"></div><div class="line"><span class="comment">// Configuration 1</span></div><div class="line">gemm1.configure(&amp;a1, &amp;b1, <span class="keyword">nullptr</span>, &amp;c1, 1.0f, 0.0f);</div></div><!-- fragment --><h2><a class="anchor" id="S1_8_1_cl_tuner_how_to"></a>
How to use it</h2>
<p>All the graph examples in the Compute Library's folder "examples" and the arm_compute_benchmark accept an argument to enable the OpenCL tuner and an argument to export/import the LWS values to/from a file </p><pre class="fragment">#Enable CL tuner
./graph_mobilenet --enable-tuner â€“-target=CL
./arm_compute_benchmark --enable-tuner

#Export/Import to/from a file
./graph_mobilenet --enable-tuner --target=CL --tuner-file=acl_tuner.csv
./arm_compute_benchmark --enable-tuner --tuner-file=acl_tuner.csv
</pre><p>If you are importing the <a class="el" href="classarm__compute_1_1_c_l_tuner.xhtml" title="Basic implementation of the OpenCL tuner interface. ">CLTuner</a>'results from a file, the new tuned LWS values will be appended to it.</p>
<p>Either you are benchmarking the graph examples or the test cases in the arm_compute_benchmark remember to: </p><pre class="fragment">-# Disable the power management
-# Keep the GPU frequency constant
-# Run multiple times the network (i.e. 10).
</pre><p>If you are not using the graph API or the benchmark infrastructure you will need to manually pass a <a class="el" href="classarm__compute_1_1_c_l_tuner.xhtml" title="Basic implementation of the OpenCL tuner interface. ">CLTuner</a> object to <a class="el" href="classarm__compute_1_1_c_l_scheduler.xhtml" title="Provides global access to a CL context and command queue. ">CLScheduler</a> before configuring any function.</p>
<div class="fragment"><div class="line">CLTuner tuner;</div><div class="line"></div><div class="line"><span class="comment">// Setup Scheduler</span></div><div class="line"><a class="code" href="classarm__compute_1_1_c_l_scheduler.xhtml#a9b58d0eb9a2af8e6d7908695e1557d6c">CLScheduler::get</a>().<a class="code" href="classarm__compute_1_1_c_l_scheduler.xhtml#a56d8f451f6b30093a49f1b4978681b07">default_init</a>(&amp;tuner);</div></div><!-- fragment --><p>After the first run, the <a class="el" href="classarm__compute_1_1_c_l_tuner.xhtml" title="Basic implementation of the OpenCL tuner interface. ">CLTuner</a>'s results can be exported to a file using the method "save_to_file()".</p><ul>
<li>tuner.save_to_file("results.csv");</li>
</ul>
<p>This file can be also imported using the method "load_from_file("results.csv")".</p><ul>
<li>tuner.load_from_file("results.csv");</li>
</ul>
<h1><a class="anchor" id="Security"></a>
Concerns</h1>
<p>Here are some security concerns that may affect Compute Library.</p>
<h2><a class="anchor" id="A"></a>
process running under the same uid could read another process memory</h2>
<p>Processes running under same user ID (UID) may be able to read each other memory and running state. Hence, This can lead to information disclosure and sensitive data can be leaked, such as the weights of the model currently executing. This mainly affects Linux systems and it's the responsibility of the system owner to make processes secure against this vulnerability. Moreover, the YAMA security kernel module can be used to detect and stop such a trial of hacking, it can be selected at the kernel compile time by CONFIG_SECURITY_YAMA and configured during runtime changing the ptrace_scope in /proc/sys/kernel/yama.</p>
<p>Please refer to: <a href="https://www.kernel.org/doc/html/v4.15/admin-guide/LSM/Yama.html">https://www.kernel.org/doc/html/v4.15/admin-guide/LSM/Yama.html</a> for more information on this regard.</p>
<h2><a class="anchor" id="Malicious"></a>
users could alter Compute Library related files</h2>
<p>Extra care must be taken in order to reduce the posibility of a user altering sensitive files. <a class="el" href="classarm__compute_1_1_c_l_tuner.xhtml" title="Basic implementation of the OpenCL tuner interface. ">CLTuner</a> files should be protected by arbitrary writes since this can lead Compute Library to crash or waste all system's resources.</p>
<h2><a class="anchor" id="Various"></a>
concerns</h2>
<p>Sensitive applications that use Compute Library should consider posible attack vectors such as shared library hooking, information leakage from the underlying OpenCL driver or previous excecution and running arbitrary networks that consume all the available resources on the system, leading to denial of service. </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Thu Mar 16 2023 12:24:55 for Compute Library by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
