<!-- HTML header for doxygen 1.8.15-->
<!-- Remember to use version doxygen 1.8.15 +-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="robots" content="NOINDEX, NOFOLLOW" /> <!-- Prevent indexing by search engines -->
<title>Compute Library: How to Build and Run Examples</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <img alt="Compute Library" src="https://raw.githubusercontent.com/ARM-software/ComputeLibrary/gh-pages/ACL_logo.png" style="max-width: 100%;margin-top: 15px;margin-left: 10px"/>
  <td style="padding-left: 0.5em;">
   <div id="projectname">
   &#160;<span id="projectnumber">22.08</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('how_to_build.xhtml','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">How to Build and Run Examples </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#S1_1_build_options">Build options</a></li>
<li class="level1"><a href="#S1_2_linux">Building for Linux</a><ul><li class="level2"><a href="#S1_2_1_library">How to build the library ?</a></li>
<li class="level2"><a href="#S1_2_2_examples">How to manually build the examples ?</a></li>
<li class="level2"><a href="#S1_2_3_sve">Build for SVE or SVE2</a></li>
</ul>
</li>
<li class="level1"><a href="#S1_3_android">Building for Android</a><ul><li class="level2"><a href="#S1_3_1_library">How to build the library ?</a></li>
<li class="level2"><a href="#S1_3_2_examples">How to manually build the examples ?</a></li>
</ul>
</li>
<li class="level1"><a href="#S1_4_macos">Building for macOS</a></li>
<li class="level1"><a href="#S1_5_bare_metal">Building for bare metal</a><ul><li class="level2"><a href="#S1_5_1_library">How to build the library ?</a></li>
<li class="level2"><a href="#S1_5_2_examples">How to manually build the examples ?</a></li>
</ul>
</li>
<li class="level1"><a href="#S1_6_windows_host">Building on a Windows host system (cross-compile)</a><ul><li class="level2"><a href="#S1_6_1_ubuntu_on_windows">Bash on Ubuntu on Windows (cross-compile)</a></li>
<li class="level2"><a href="#S1_6_2_cygwin">Cygwin (cross-compile)</a></li>
<li class="level2"><a href="#S1_6_3_WoA">Windows on ARM (native build)</a></li>
</ul>
</li>
<li class="level1"><a href="#S1_7_cl_requirements">OpenCL DDK Requirements</a><ul><li class="level2"><a href="#S1_7_1_cl_hard_requirements">Hard Requirements</a></li>
<li class="level2"><a href="#S1_7_2_cl_performance_requirements">Performance improvements</a></li>
</ul>
</li>
</ul>
</div>
<div class="textblock"><h1><a class="anchor" id="S1_1_build_options"></a>
Build options</h1>
<p>scons 2.3 or above is required to build the library. To see the build options available simply run <code>scons -h</code></p>
<h1><a class="anchor" id="S1_2_linux"></a>
Building for Linux</h1>
<h2><a class="anchor" id="S1_2_1_library"></a>
How to build the library ?</h2>
<p>For Linux, the library was successfully built and tested using the following Linaro GCC toolchain:</p>
<ul>
<li>gcc-linaro-6.3.1-2017.05-x86_64_arm-linux-gnueabihf</li>
<li>gcc-linaro-6.3.1-2017.05-x86_64_aarch64-linux-gnu</li>
</ul>
<p>To cross-compile the library in debug mode, with Arm® Neon™ only support, for Linux 32bit: </p><pre class="fragment">scons Werror=1 -j8 debug=1 neon=1 opencl=0 os=linux arch=armv7a
</pre><p>To cross-compile the library in asserts mode, with OpenCL only support, for Linux 64bit: </p><pre class="fragment">scons Werror=1 -j8 debug=0 asserts=1 neon=0 opencl=1 embed_kernels=1 os=linux arch=armv8a
</pre><p>You can also compile the library natively on an Arm device by using <b>build=native</b>: </p><pre class="fragment">scons Werror=1 -j8 debug=0 neon=1 opencl=0 os=linux arch=armv8a build=native
scons Werror=1 -j8 debug=0 neon=1 opencl=0 os=linux arch=armv7a build=native
</pre><dl class="section note"><dt>Note</dt><dd>g++ for Arm is mono-arch, therefore if you want to compile for Linux 32bit on a Linux 64bit platform you will have to use a cross compiler.</dd></dl>
<p>For example on a 64bit Debian based system you would have to install <b>g++-arm-linux-gnueabihf</b> </p><pre class="fragment">apt-get install g++-arm-linux-gnueabihf
</pre><p>Then run </p><pre class="fragment">scons Werror=1 -j8 debug=0 neon=1 opencl=0 os=linux arch=armv7a build=cross_compile
</pre><p>or simply remove the build parameter as build=cross_compile is the default value: </p><pre class="fragment">scons Werror=1 -j8 debug=0 neon=1 opencl=0 os=linux arch=armv7a
</pre><h2><a class="anchor" id="S1_2_2_examples"></a>
How to manually build the examples ?</h2>
<p>The examples get automatically built by scons as part of the build process of the library described above. This section just describes how you can build and link your own application against our library.</p>
<dl class="section note"><dt>Note</dt><dd>The following command lines assume the <a class="el" href="namespacearm__compute.xhtml" title="Copyright (c) 2017-2022 Arm Limited. ">arm_compute</a> libraries are present in the current directory or in the system library path. If this is not the case you can specify the location of the pre-built libraries with the compiler option -L. When building the OpenCL example the commands below assume that the CL headers are located in the include folder where the command is executed.</dd></dl>
<p>To cross compile a Arm® Neon™ example for Linux 32bit: </p><pre class="fragment">arm-linux-gnueabihf-g++ examples/neon_cnn.cpp utils/Utils.cpp -I. -Iinclude -std=c++14 -mfpu=neon -L. -larm_compute -larm_compute_core -o neon_cnn
</pre><p>To cross compile a Arm® Neon™ example for Linux 64bit: </p><pre class="fragment">aarch64-linux-gnu-g++ examples/neon_cnn.cpp utils/Utils.cpp -I. -Iinclude -std=c++14 -L. -larm_compute -larm_compute_core -o neon_cnn
</pre><p>(notice the only difference with the 32 bit command is that we don't need the -mfpu option and the compiler's name is different)</p>
<p>To cross compile an OpenCL example for Linux 32bit: </p><pre class="fragment">arm-linux-gnueabihf-g++ examples/cl_sgemm.cpp utils/Utils.cpp -I. -Iinclude -std=c++14 -mfpu=neon -L. -larm_compute -larm_compute_core -o cl_sgemm -DARM_COMPUTE_CL
</pre><p>To cross compile an OpenCL example for Linux 64bit: </p><pre class="fragment">aarch64-linux-gnu-g++ examples/cl_sgemm.cpp utils/Utils.cpp -I. -Iinclude -std=c++14 -L. -larm_compute -larm_compute_core -o cl_sgemm -DARM_COMPUTE_CL
</pre><p>(notice the only difference with the 32 bit command is that we don't need the -mfpu option and the compiler's name is different)</p>
<p>To cross compile the examples with the Graph API, such as <a class="el" href="graph__lenet_8cpp.xhtml">graph_lenet.cpp</a>, you need to link the examples against arm_compute_graph.so too.</p>
<p>i.e. to cross compile the "graph_lenet" example for Linux 32bit: </p><pre class="fragment">arm-linux-gnueabihf-g++ examples/graph_lenet.cpp utils/Utils.cpp utils/GraphUtils.cpp utils/CommonGraphOptions.cpp -I. -Iinclude -std=c++14 -mfpu=neon -L. -larm_compute_graph -larm_compute -larm_compute_core -Wl,--allow-shlib-undefined -o graph_lenet
</pre><p>i.e. to cross compile the "graph_lenet" example for Linux 64bit: </p><pre class="fragment">aarch64-linux-gnu-g++ examples/graph_lenet.cpp utils/Utils.cpp utils/GraphUtils.cpp utils/CommonGraphOptions.cpp -I. -Iinclude -std=c++14 -L. -larm_compute_graph -larm_compute -larm_compute_core -Wl,--allow-shlib-undefined -o graph_lenet
</pre><p>(notice the only difference with the 32 bit command is that we don't need the -mfpu option and the compiler's name is different)</p>
<dl class="section note"><dt>Note</dt><dd>If compiling using static libraries, this order must be followed when linking: arm_compute_graph_static, <a class="el" href="namespacearm__compute.xhtml" title="Copyright (c) 2017-2022 Arm Limited. ">arm_compute</a>, arm_compute_core</dd></dl>
<p>To compile natively (i.e directly on an Arm device) for Arm® Neon™ for Linux 32bit: </p><pre class="fragment">g++ examples/neon_cnn.cpp utils/Utils.cpp -I. -Iinclude -std=c++14 -mfpu=neon -larm_compute -larm_compute_core -o neon_cnn
</pre><p>To compile natively (i.e directly on an Arm device) for Arm® Neon™ for Linux 64bit: </p><pre class="fragment">g++ examples/neon_cnn.cpp utils/Utils.cpp -I. -Iinclude -std=c++14 -larm_compute -larm_compute_core -o neon_cnn
</pre><p>(notice the only difference with the 32 bit command is that we don't need the -mfpu option)</p>
<p>To compile natively (i.e directly on an Arm device) for OpenCL for Linux 32bit or Linux 64bit: </p><pre class="fragment">g++ examples/cl_sgemm.cpp utils/Utils.cpp -I. -Iinclude -std=c++14 -larm_compute -larm_compute_core -o cl_sgemm -DARM_COMPUTE_CL
</pre><p>To compile natively the examples with the Graph API, such as <a class="el" href="graph__lenet_8cpp.xhtml">graph_lenet.cpp</a>, you need to link the examples against arm_compute_graph.so too.</p>
<p>i.e. to natively compile the "graph_lenet" example for Linux 32bit: </p><pre class="fragment">g++ examples/graph_lenet.cpp utils/Utils.cpp utils/GraphUtils.cpp utils/CommonGraphOptions.cpp -I. -Iinclude -std=c++14 -mfpu=neon -L. -larm_compute_graph -larm_compute -larm_compute_core -Wl,--allow-shlib-undefined -o graph_lenet
</pre><p>i.e. to natively compile the "graph_lenet" example for Linux 64bit: </p><pre class="fragment">g++ examples/graph_lenet.cpp utils/Utils.cpp utils/GraphUtils.cpp utils/CommonGraphOptions.cpp -I. -Iinclude -std=c++14 -L. -larm_compute_graph -larm_compute -larm_compute_core -Wl,--allow-shlib-undefined -o graph_lenet
</pre><p>(notice the only difference with the 32 bit command is that we don't need the -mfpu option)</p>
<dl class="section note"><dt>Note</dt><dd>If compiling using static libraries, this order must be followed when linking: arm_compute_graph_static, <a class="el" href="namespacearm__compute.xhtml" title="Copyright (c) 2017-2022 Arm Limited. ">arm_compute</a>, arm_compute_core</dd>
<dd>
These two commands assume libarm_compute.so is available in your library path, if not add the path to it using -L (e.g. -Llib/linux-armv8a-neon-cl-asserts/) </dd>
<dd>
You might need to export the path to OpenCL library as well in your LD_LIBRARY_PATH if Compute Library was built with OpenCL enabled.</dd></dl>
<p>To run the built executable simply run: </p><pre class="fragment">LD_LIBRARY_PATH=build ./neon_cnn
</pre><p>or </p><pre class="fragment">LD_LIBRARY_PATH=build ./cl_sgemm
</pre><dl class="section note"><dt>Note</dt><dd>Examples accept different types of arguments, to find out what they are run the example with <em>&ndash;help</em> as an argument. If no arguments are specified then random values will be used to execute the graph.</dd></dl>
<p>For example: </p><pre class="fragment">LD_LIBRARY_PATH=. ./graph_lenet --help
</pre><p>Below is a list of the common parameters among the graph examples : </p><div class="fragment"><div class="line"><span class="comment">/* Common graph parameters</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> * --help             : Print the example&#39;s help message.</span></div><div class="line"><span class="comment"> * --threads          : The number of threads to be used by the example during execution.</span></div><div class="line"><span class="comment"> * --target           : Execution target to be used by the examples. Supported target options: Neon, CL, CLVK.</span></div><div class="line"><span class="comment"> * --type             : Data type to be used by the examples. Supported data type options: QASYMM8, F16, F32.</span></div><div class="line"><span class="comment"> * --layout           : Data layout to be used by the examples. Supported data layout options : NCHW, NHWC.</span></div><div class="line"><span class="comment"> * --enable-tuner     : Toggle option to enable the OpenCL dynamic tuner.</span></div><div class="line"><span class="comment"> * --enable-cl-cache  : Toggle option to load the prebuilt opencl kernels from a cache file.</span></div><div class="line"><span class="comment"> * --fast-math        : Toggle option to enable the fast math option.</span></div><div class="line"><span class="comment"> * --data             : Path that contains the trainable parameter files of graph layers.</span></div><div class="line"><span class="comment"> * --image            : Image to load and operate on. Image types supported: PPM, JPEG, NPY.</span></div><div class="line"><span class="comment"> * --labels           : File that contains the labels that classify upon.</span></div><div class="line"><span class="comment"> * --validation-file  : File that contains a list of image names with their corresponding label id (e.g. image0.jpg 5).</span></div><div class="line"><span class="comment"> *                      This is used to run the graph over a number of images and report top-1 and top-5 metrics.</span></div><div class="line"><span class="comment"> * --validation-path  : The path where the validation images specified in the validation file reside.</span></div><div class="line"><span class="comment"> * --validation-range : The range of the images to validate from the validation file (e.g 0,9).</span></div><div class="line"><span class="comment"> *                      If not specified all the images will be validated.</span></div><div class="line"><span class="comment"> * --tuner-file       : The file to store the OpenCL dynamic tuner tuned parameters.</span></div><div class="line"><span class="comment"> * --tuner-mode       : Select tuner mode. Supported modes: Exhaustive,Normal,Rapid</span></div><div class="line"><span class="comment"> *                      * Exhaustive: slowest but produces the most performant LWS configuration.</span></div><div class="line"><span class="comment"> *                      * Normal: slow but produces the LWS configurations on par with Exhaustive most of the time.</span></div><div class="line"><span class="comment"> *                      * Rapid: fast but produces less performant LWS configurations</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> * Note that data, image and labels options should be provided to perform an inference run on an image.</span></div><div class="line"><span class="comment"> * Note that validation-file and validation-path should be provided to perform a graph accuracy estimation.</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> * Example execution commands:</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> * Execute a single inference given an image and a file containing the correspondence between label ids and human readable labels:</span></div><div class="line"><span class="comment"> * ./graph_vgg16 --data=data/ --target=cl --layout=nhwc --image=kart.jpeg --labels=imagenet1000_clsid_to_human.txt</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> * Perform a graph validation on a list of images:</span></div><div class="line"><span class="comment"> * ./graph_vgg16 --data=data/ --target=neon --threads=4 --layout=nchw --validation-file=val.txt --validation-path=ilsvrc_test_images/</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> * File formats:</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> * Validation file should be a plain file containing the names of the images followed by the correct label id.</span></div><div class="line"><span class="comment"> * For example:</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> * image0.jpeg 882</span></div><div class="line"><span class="comment"> * image1.jpeg 34</span></div><div class="line"><span class="comment"> * image2.jpeg 354</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> * Labels file should be a plain file where each line is the respective human readable label (counting starts from 0).</span></div><div class="line"><span class="comment"> * For example:</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> * 0: label0_name            label0_name</span></div><div class="line"><span class="comment"> * 1: label1_name     or     label1_name</span></div><div class="line"><span class="comment"> * 2: label2_name            label2_name</span></div><div class="line"><span class="comment"> */</span></div></div><!-- fragment --> <h2><a class="anchor" id="S1_2_3_sve"></a>
Build for SVE or SVE2</h2>
<p>In order to build for SVE or SVE2 you need a compiler that supports them. You can find more information in the following these links:</p><ol type="1">
<li>GCC: <a href="https://developer.arm.com/tools-and-software/open-source-software/developer-tools/gnu-toolchain/sve-support">https://developer.arm.com/tools-and-software/open-source-software/developer-tools/gnu-toolchain/sve-support</a></li>
<li>LLVM: <a href="https://developer.arm.com/tools-and-software/open-source-software/developer-tools/llvm-toolchain/sve-support">https://developer.arm.com/tools-and-software/open-source-software/developer-tools/llvm-toolchain/sve-support</a></li>
</ol>
<dl class="section note"><dt>Note</dt><dd>You the need to indicate the toolchains using the scons "toolchain_prefix" parameter.</dd></dl>
<p>An example build command with SVE is: </p><pre class="fragment">    scons arch=armv8.2-a-sve os=linux build_dir=arm64 -j55 standalone=0 opencl=0 openmp=0 validation_tests=1 neon=1 cppthreads=1 toolchain_prefix=aarch64-none-linux-gnu-
</pre><h1><a class="anchor" id="S1_3_android"></a>
Building for Android</h1>
<p>For Android, the library was successfully built and tested using Google's standalone toolchains:</p><ul>
<li>clang++ from NDK r20b for armv8a</li>
<li>clang++ from NDK r20b for armv8.2-a with FP16 support</li>
</ul>
<p>For NDK r18 or older, here is a guide to <a href="https://developer.android.com/ndk/guides/standalone_toolchain.html">create your Android standalone toolchains from the NDK</a>:</p><ul>
<li>Download the NDK r18b from here: <a href="https://developer.android.com/ndk/downloads/index.html">https://developer.android.com/ndk/downloads/index.html</a> to directory $NDK</li>
<li>Make sure you have Python 2.7 installed on your machine.</li>
<li><p class="startli">Generate the 32 and/or 64 toolchains by running the following commands to your toolchain directory $MY_TOOLCHAINS:</p>
<p class="startli">$NDK/build/tools/make_standalone_toolchain.py &ndash;arch arm64 &ndash;install-dir $MY_TOOLCHAINS/aarch64-linux-android-ndk-r18b &ndash;stl libc++ &ndash;api 21</p>
<p class="startli">$NDK/build/tools/make_standalone_toolchain.py &ndash;arch arm &ndash;install-dir $MY_TOOLCHAINS/arm-linux-android-ndk-r18b &ndash;stl libc++ &ndash;api 21</p>
</li>
</ul>
<p>For NDK r19 or newer, you can directly <a href="https://developer.android.com/ndk/downloads">Download</a> the NDK package for your development platform, without the need to launch the make_standalone_toolchain.py script. You can find all the prebuilt binaries inside $NDK/toolchains/llvm/prebuilt/$OS_ARCH/bin/.</p>
<dl class="section attention"><dt>Attention</dt><dd>The building script will look for a binary named "aarch64-linux-android-clang++", while the prebuilt binaries will have their API version as a suffix to their filename (e.g. "aarch64-linux-android21-clang++"). You can instruct scons to use the correct version by using a combination of the toolchain_prefix and the "CC" "CXX" environment variables. </dd>
<dd>
For this particular example, you can specify: <pre class="fragment">CC=clang CXX=clang++ scons toolchain_prefix=aarch64-linux-android21-
</pre></dd>
<dd>
or: <pre class="fragment">CC=aarch64-linux-android21-clang CXX=aarch64-linux-android21-clang++ scons toolchain_prefix=""
</pre></dd></dl>
<dl class="section attention"><dt>Attention</dt><dd>We used to use gnustl but as of NDK r17 it is deprecated so we switched to libc++ </dd></dl>
<dl class="section note"><dt>Note</dt><dd>Make sure to add the toolchains to your PATH: <pre class="fragment">export PATH=$PATH:$MY_TOOLCHAINS/aarch64-linux-android-ndk-r18b/bin:$MY_TOOLCHAINS/arm-linux-android-ndk-r18b/bin
</pre></dd></dl>
<h2><a class="anchor" id="S1_3_1_library"></a>
How to build the library ?</h2>
<p>To cross-compile the library in debug mode, with Arm® Neon™ only support, for Android 32bit: </p><pre class="fragment">CXX=clang++ CC=clang scons Werror=1 -j8 debug=1 neon=1 opencl=0 os=android arch=armv7a
</pre><p>To cross-compile the library in asserts mode, with OpenCL only support, for Android 64bit: </p><pre class="fragment">CXX=clang++ CC=clang scons Werror=1 -j8 debug=0 asserts=1 neon=0 opencl=1 embed_kernels=1 os=android arch=armv8a
</pre><h2><a class="anchor" id="S1_3_2_examples"></a>
How to manually build the examples ?</h2>
<p>The examples get automatically built by scons as part of the build process of the library described above. This section just describes how you can build and link your own application against our library.</p>
<dl class="section note"><dt>Note</dt><dd>The following command lines assume the <a class="el" href="namespacearm__compute.xhtml" title="Copyright (c) 2017-2022 Arm Limited. ">arm_compute</a> libraries are present in the current directory or in the system library path. If this is not the case you can specify the location of the pre-built libraries with the compiler option -L. When building the OpenCL example the commands below assume that the CL headers are located in the include folder where the command is executed.</dd></dl>
<p>Once you've got your Android standalone toolchain built and added to your path you can do the following:</p>
<p>To cross compile a Arm® Neon™ example: </p><pre class="fragment">#32 bit:
arm-linux-androideabi-clang++ examples/neon_cnn.cpp utils/Utils.cpp -I. -Iinclude -std=c++14 -larm_compute-static -larm_compute_core-static -L. -o neon_cnn_arm -static-libstdc++ -pie
#64 bit:
aarch64-linux-android-clang++ examples/neon_cnn.cpp utils/Utils.cpp -I. -Iinclude -std=c++14 -larm_compute-static -larm_compute_core-static -L. -o neon_cnn_aarch64 -static-libstdc++ -pie
</pre><p>To cross compile an OpenCL example: </p><pre class="fragment">#32 bit:
arm-linux-androideabi-clang++ examples/cl_sgemm.cpp utils/Utils.cpp -I. -Iinclude -std=c++14 -larm_compute-static -larm_compute_core-static -L. -o cl_sgemm_arm -static-libstdc++ -pie -DARM_COMPUTE_CL
#64 bit:
aarch64-linux-android-clang++ examples/cl_sgemm.cpp utils/Utils.cpp -I. -Iinclude -std=c++14 -larm_compute-static -larm_compute_core-static -L. -o cl_sgemm_aarch64 -static-libstdc++ -pie -DARM_COMPUTE_CL
</pre><p>To cross compile the examples with the Graph API, such as <a class="el" href="graph__lenet_8cpp.xhtml">graph_lenet.cpp</a>, you need to link the library arm_compute_graph also. </p><pre class="fragment">#32 bit:
arm-linux-androideabi-clang++ examples/graph_lenet.cpp utils/Utils.cpp utils/GraphUtils.cpp utils/CommonGraphOptions.cpp -I. -Iinclude -std=c++14 -Wl,--whole-archive -larm_compute_graph-static -Wl,--no-whole-archive -larm_compute-static -larm_compute_core-static -L. -o graph_lenet_arm -static-libstdc++ -pie -DARM_COMPUTE_CL
#64 bit:
aarch64-linux-android-clang++ examples/graph_lenet.cpp utils/Utils.cpp utils/GraphUtils.cpp utils/CommonGraphOptions.cpp -I. -Iinclude -std=c++14 -Wl,--whole-archive -larm_compute_graph-static -Wl,--no-whole-archive -larm_compute-static -larm_compute_core-static -L. -o graph_lenet_aarch64 -static-libstdc++ -pie -DARM_COMPUTE_CL
</pre><dl class="section note"><dt>Note</dt><dd>Due to some issues in older versions of the Arm® Mali™ OpenCL DDK (&lt;= r13p0), we recommend to link <a class="el" href="namespacearm__compute.xhtml" title="Copyright (c) 2017-2022 Arm Limited. ">arm_compute</a> statically on Android. </dd>
<dd>
When linked statically the arm_compute_graph library currently needs the &ndash;whole-archive linker flag in order to work properly</dd></dl>
<p>Then you need to do is upload the executable and the shared library to the device using ADB: </p><pre class="fragment">adb push neon_cnn_arm /data/local/tmp/
adb push cl_sgemm_arm /data/local/tmp/
adb push gc_absdiff_arm /data/local/tmp/
adb shell chmod 777 -R /data/local/tmp/
</pre><p>And finally to run the example: </p><pre class="fragment">adb shell /data/local/tmp/neon_cnn_arm
adb shell /data/local/tmp/cl_sgemm_arm
adb shell /data/local/tmp/gc_absdiff_arm
</pre><p>For 64bit: </p><pre class="fragment">adb push neon_cnn_aarch64 /data/local/tmp/
adb push cl_sgemm_aarch64 /data/local/tmp/
adb push gc_absdiff_aarch64 /data/local/tmp/
adb shell chmod 777 -R /data/local/tmp/
</pre><p>And finally to run the example: </p><pre class="fragment">adb shell /data/local/tmp/neon_cnn_aarch64
adb shell /data/local/tmp/cl_sgemm_aarch64
adb shell /data/local/tmp/gc_absdiff_aarch64
</pre><dl class="section note"><dt>Note</dt><dd>Examples accept different types of arguments, to find out what they are run the example with <em>&ndash;help</em> as an argument. If no arguments are specified then random values will be used to execute the graph.</dd></dl>
<p>For example: adb shell /data/local/tmp/graph_lenet &ndash;help</p>
<p>In this case the first argument of LeNet (like all the graph examples) is the target (i.e 0 to run on Neon™, 1 to run on OpenCL if available, 2 to run on OpenCL using the <a class="el" href="classarm__compute_1_1_c_l_tuner.xhtml" title="Basic implementation of the OpenCL tuner interface. ">CLTuner</a>), the second argument is the path to the folder containing the npy files for the weights and finally the third argument is the number of batches to run.</p>
<h1><a class="anchor" id="S1_4_macos"></a>
Building for macOS</h1>
<p>The library was successfully natively built for Apple Silicon under macOS 11.1 using clang v12.0.0.</p>
<p>To natively compile the library with accelerated CPU support: </p><pre class="fragment">scons Werror=1 -j8 neon=1 opencl=0 os=macos arch=armv8a build=native
</pre><dl class="section note"><dt>Note</dt><dd>Initial support disables feature discovery through HWCAPS and thread scheduling affinity controls</dd></dl>
<h1><a class="anchor" id="S1_5_bare_metal"></a>
Building for bare metal</h1>
<p>For bare metal, the library was successfully built using linaro's latest (gcc-linaro-6.3.1-2017.05) bare metal toolchains:</p><ul>
<li>arm-eabi for armv7a</li>
<li>aarch64-elf for armv8a</li>
</ul>
<p>Download linaro for <a href="https://releases.linaro.org/components/toolchain/binaries/6.3-2017.05/arm-eabi/">armv7a</a> and <a href="https://releases.linaro.org/components/toolchain/binaries/6.3-2017.05/aarch64-elf/">armv8a</a>.</p>
<dl class="section note"><dt>Note</dt><dd>Make sure to add the toolchains to your PATH: export PATH=$PATH:$MY_TOOLCHAINS/gcc-linaro-6.3.1-2017.05-x86_64_aarch64-elf/bin:$MY_TOOLCHAINS/gcc-linaro-6.3.1-2017.05-x86_64_arm-eabi/bin</dd></dl>
<h2><a class="anchor" id="S1_5_1_library"></a>
How to build the library ?</h2>
<p>To cross-compile the library with Arm® Neon™ support for baremetal armv8a: </p><pre class="fragment">scons Werror=1 -j8 debug=0 neon=1 opencl=0 os=bare_metal arch=armv8a build=cross_compile cppthreads=0 openmp=0 standalone=1
</pre><h2><a class="anchor" id="S1_5_2_examples"></a>
How to manually build the examples ?</h2>
<p>Examples are disabled when building for bare metal. If you want to build the examples you need to provide a custom bootcode depending on the target architecture and link against the compute library. More information about bare metal bootcode can be found <a href="http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dai0527a/index.html">here</a>.</p>
<h1><a class="anchor" id="S1_6_windows_host"></a>
Building on a Windows host system (cross-compile)</h1>
<p>Using <code>scons</code> directly from the Windows command line is known to cause problems. The reason seems to be that if <code>scons</code> is setup for cross-compilation it gets confused about Windows style paths (using backslashes). Thus it is recommended to follow one of the options outlined below.</p>
<h2><a class="anchor" id="S1_6_1_ubuntu_on_windows"></a>
Bash on Ubuntu on Windows (cross-compile)</h2>
<p>The best and easiest option is to use <a href="https://msdn.microsoft.com/en-gb/commandline/wsl/about">Ubuntu on Windows</a>. This feature is still marked as <em>beta</em> and thus might not be available. However, if it is building the library is as simple as opening a <em>Bash on Ubuntu on Windows</em> shell and following the general guidelines given above.</p>
<h2><a class="anchor" id="S1_6_2_cygwin"></a>
Cygwin (cross-compile)</h2>
<p>If the Windows subsystem for Linux is not available <a href="https://www.cygwin.com/">Cygwin</a> can be used to install and run <code>scons</code>, the minimum Cygwin version must be 3.0.7 or later. In addition to the default packages installed by Cygwin <code>scons</code> has to be selected in the installer. (<code>git</code> might also be useful but is not strictly required if you already have got the source code of the library.) Linaro provides pre-built versions of <a href="http://releases.linaro.org/components/toolchain/binaries/">GCC cross-compilers</a> that can be used from the Cygwin terminal. When building for Android the compiler is included in the Android standalone toolchain. After everything has been set up in the Cygwin terminal the general guide on building the library can be followed.</p>
<h2><a class="anchor" id="S1_6_3_WoA"></a>
Windows on ARM (native build)</h2>
<pre class="fragment">Native builds on Windows are experimental and some features from the library interacting with the OS are missing.
</pre><p>It's possible to build Compute Library natively on a windows system running on ARM.</p>
<p>Windows on ARM(WoA) systems provide compatibility emulating x86 binaries on aarch64. Unfortunately Visual Studio 2022 does not work on aarch64 systems because it's an x86_64bit application and these binaries cannot be exectuted on WoA yet.</p>
<p>Because we cannot use Visual Studio to build Compute Library we have to set up a native standalone toolchain to compile C++ code for arm64 on Windows.</p>
<p>Native arm64 toolchain installation for WoA:</p><ul>
<li>LLVM+Clang-12 which can be downloaded from: <a href="https://github.com/llvm/llvm-project/releases/download/llvmorg-12.0.0/LLVM-12.0.0-woa64.exe">https://github.com/llvm/llvm-project/releases/download/llvmorg-12.0.0/LLVM-12.0.0-woa64.exe</a></li>
<li>Arm64 VC Runtime which can be downloaded from <a href="https://aka.ms/vs/17/release/vc_redist.arm64.exe">https://aka.ms/vs/17/release/vc_redist.arm64.exe</a></li>
<li>While full VS22 cannot be installed on WoA, we can install some components<ol type="1">
<li>Desktop development with C++ and all Arm64 components for Visual Studio, refer to: <a href="https://developer.arm.com/documentation/102528/0100/Install-Visual-Studio">https://developer.arm.com/documentation/102528/0100/Install-Visual-Studio</a></li>
<li>VS22 build tools: <a href="https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2022">https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2022</a></li>
</ol>
</li>
</ul>
<p>There are some additional tools we need to install to build Compute Library:</p>
<ul>
<li>git <a href="https://git-scm.com/download/win">https://git-scm.com/download/win</a></li>
<li>python 3 <a href="https://www.python.org/downloads/windows/">https://www.python.org/downloads/windows/</a></li>
<li>scons can be installed with pip install scons</li>
</ul>
<p>In order to use clang to build windows binaries natively we have to initialize the environment variables from VS22 correctly so that the compiler could find the arm64 C++ libraries. This can be done by pressing the key windows + r and running the command: </p><pre class="fragment">cmd /k "C:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Auxiliary\Build\vcvarsx86_arm64.bat"
</pre><p>To build Compute Library type: </p><pre class="fragment"> scons opencl=0 neon=1 os=windows examples=0 validation_tests=1 benchmark_examples=0 build=native arch=armv8a Werror=0 exceptions=1 standalone=1
</pre><h1><a class="anchor" id="S1_7_cl_requirements"></a>
OpenCL DDK Requirements</h1>
<h2><a class="anchor" id="S1_7_1_cl_hard_requirements"></a>
Hard Requirements</h2>
<p>Compute Library requires OpenCL 1.1 and above with support of non uniform workgroup sizes, which is officially supported in the Arm® Mali™ OpenCL DDK r8p0 and above as an extension (respective extension flag is <em>-cl-arm-non-uniform-work-group-size</em>).</p>
<p>Enabling 16-bit floating point calculations require <em>cl_khr_fp16</em> extension to be supported. All Arm® Mali™ GPUs with compute capabilities have native support for half precision floating points.</p>
<h2><a class="anchor" id="S1_7_2_cl_performance_requirements"></a>
Performance improvements</h2>
<p>Integer dot product built-in function extensions (and therefore optimized kernels) are available with Arm® Mali™ OpenCL DDK r22p0 and above for the following GPUs : G71, G76. The relevant extensions are <em>cl_arm_integer_dot_product_int8</em>, <em>cl_arm_integer_dot_product_accumulate_int8</em> and <em>cl_arm_integer_dot_product_accumulate_int16</em>.</p>
<p>OpenCL kernel level debugging can be simplified with the use of printf, this requires the <em>cl_arm_printf</em> extension to be supported.</p>
<p>SVM allocations are supported for all the underlying allocations in Compute Library. To enable this OpenCL 2.0 and above is a requirement. </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Thu Aug 18 2022 12:57:44 for Compute Library by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
